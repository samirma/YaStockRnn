{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "from data_util import *\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import model as model_util\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, GlobalMaxPool1D, Bidirectional, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import autokeras as ak\n",
    "import kerastuner\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed():\n",
    "    seed_value= 100\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "path = \"./data/\"\n",
    "model_path = path + \"stock.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39066, 26) (39066,) | (3683, 26) (3683,)\n",
      "Counter({0: 19533, 1: 1971}) | Counter({0: 19533, 1: 19533}) | Counter({0: 3317, 1: 366})\n"
     ]
    }
   ],
   "source": [
    "trainX_raw, trainY_raw = load_data(\"btceur\", \"train\", path)\n",
    "valX_raw, valY_raw = load_data(\"btceur\", \"Val\", path)\n",
    "\n",
    "trainX_balanced, trainY_balanced = get_balanced_set(trainX_raw, trainY_raw)\n",
    "\n",
    "valX, valY = valX_raw, valY_raw\n",
    "\n",
    "normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "normalizer.adapt(trainX_raw)\n",
    "\n",
    "\n",
    "print(\"{} {} | {} {}\".format(trainX_balanced.shape, trainY_balanced.shape, valX.shape, valY.shape))\n",
    "\n",
    "print(\"{} | {} | {}\".format(Counter(trainY_raw), Counter(trainY_balanced), Counter(valY)))\n",
    "\n",
    "\n",
    "features = trainX_raw.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "def show_feature_importances(tree):\n",
    "    title = 'Feature Importance:'\n",
    "    figsize = (15, 5)\n",
    "\n",
    "    feat_imp = pd.DataFrame({'Importance':tree.feature_importances_})    \n",
    "    feat_imp['feature'] = [i for i in range(features[-1])]\n",
    "    feat_imp.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    feat_imp = feat_imp\n",
    "\n",
    "    feat_imp.sort_values(by='Importance', inplace=True)\n",
    "    feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "    feat_imp.plot.barh(title=title, figsize=figsize)\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(tree, trainX, trainY):\n",
    "    tree.fit(trainX, trainY)\n",
    "    print(f'Train Accuracy: {tree.score(trainX, trainY)}')\n",
    "    print(f'Val Accuracy: {tree.score(valX, valY)}')\n",
    "    y_pred = tree.predict(valX)\n",
    "    print(confusion_matrix(valY, y_pred))\n",
    "    print(f1_score(valY, y_pred))\n",
    "\n",
    "def eval_tree(tree, trainX, trainY, valX, valY):\n",
    "    print(tree)\n",
    "\n",
    "    param_grid = [\n",
    "        {'n_estimators': [10,40, 50, 60, 100],\n",
    "        'max_depth': [4, 5, 6, 10],\n",
    "        'max_features': [4,6,8,10]\n",
    "        }\n",
    "    ]\n",
    "    grid_search = GridSearchCV(tree, param_grid, cv = 5, scoring = 'accuracy', verbose = 1)\n",
    "    grid_search.fit(trainX, trainY)\n",
    "    \n",
    "    show_confusion_matrix(tree, trainX, trainY)\n",
    "    show_feature_importances(tree)\n",
    "    \n",
    "    \n",
    "\n",
    "estimators = 300\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "tress = [\n",
    "        RandomForestClassifier(random_state=5)\n",
    "        ,DecisionTreeClassifier(min_samples_leaf=600)\n",
    "        ,ExtraTreesClassifier(n_estimators=estimators)\n",
    "        ,GradientBoostingClassifier(n_estimators=estimators, learning_rate=1.0,  max_depth=1000, random_state=0)\n",
    "        ,GaussianNB()\n",
    "        ,linear_model.Ridge(alpha=.5)\n",
    "        ,RidgeClassifier(alpha=.5)\n",
    "        ,AdaBoostClassifier(n_estimators=estimators)\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00074: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffeb5c10a30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GridSearchCV\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "\n",
    "def get_model_test(features = features, \n",
    "              layers = 1, \n",
    "              units = 5, \n",
    "              optimizer=\"Adam\",\n",
    "              init='glorot_uniform',\n",
    "              normalizer = normalizer):\n",
    "    \n",
    "    reset_seed()\n",
    "    inputX = Input(shape=features)\n",
    "    \n",
    "    x = normalizer(inputX)\n",
    "    #x = inputX\n",
    "    \n",
    "    for lay in range(int(layers)):\n",
    "        x = Dense(units, kernel_initializer=init, activation='relu')(x)\n",
    "        \n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer=init, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(1, kernel_initializer=init, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inputX], outputs=x)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "norm = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "norm.adapt(trainX_balanced)\n",
    "\n",
    "params = dict(\n",
    "      optimizer=\"Nadam\", \n",
    "      layers = 6,\n",
    "      units = 60,\n",
    "      features = features,\n",
    "      init='glorot_uniform',\n",
    "      normalizer = norm\n",
    "  )\n",
    "\n",
    "my_model = KerasClassifier(build_fn=get_model_test, \n",
    "                           verbose=0, \n",
    "                           callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                                #monitor='val_precision', \n",
    "                                monitor='val_accuracy', \n",
    "                                verbose=1,\n",
    "                                patience=30,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)],\n",
    "                           epochs=100,\n",
    "                           **params,\n",
    "                    validation_data=(valX, valY))\n",
    "\n",
    "my_model.fit(trainX_balanced, trainY_balanced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perm = PermutationImportance(my_model, random_state=10).fit(trainX_balanced, trainY_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2648\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 18\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2411\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 10\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2376\n",
       "                \n",
       "                    &plusmn; 0.0031\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 24\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2343\n",
       "                \n",
       "                    &plusmn; 0.0037\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 9\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.10%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2260\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 17\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.18%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2245\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 7\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2225\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2157\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2154\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2059\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 12\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2021\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 11\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2002\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 8\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1954\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1929\n",
       "                \n",
       "                    &plusmn; 0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1924\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.22%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1888\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1879\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1772\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1634\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1607\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Col: 23\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.90%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 6 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [ \"Col: {}\".format(i) for i in range(features)]\n",
    "list = arr\n",
    "eli5.show_weights(perm, feature_names = list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    my_model, \n",
    "    trainX_balanced, \n",
    "    trainY_balanced, \n",
    "    n_repeats=5, \n",
    "    random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest_importances = pd.Series(result.importances_mean, index=arr)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 22 13 25 15 14 23  6  2  1 16  3 20  0  8 11 12 21  5  4  7 17  9 24\n",
      " 10 18]\n"
     ]
    }
   ],
   "source": [
    "print(result.importances_mean.argsort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_remove(col):\n",
    "    remove = result.importances_mean.argsort()[:col]\n",
    "    removed = np.delete(trainX_balanced , remove, 1)\n",
    "    removed_val = np.delete(valX , remove, 1)\n",
    "    \n",
    "    norm = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "    norm.adapt(removed)\n",
    "\n",
    "    params = dict(\n",
    "          optimizer=\"Nadam\", \n",
    "          layers = 6,\n",
    "          units = 60,\n",
    "          features = removed.shape[-1],\n",
    "          init='glorot_uniform',\n",
    "          normalizer = norm\n",
    "      )\n",
    "\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                                    #monitor='val_precision', \n",
    "                                    monitor='val_prc', \n",
    "                                    verbose=0,\n",
    "                                    patience=30,\n",
    "                                    mode='max',\n",
    "                                    restore_best_weights=True)]\n",
    "    \n",
    "    model_tmp = KerasClassifier(build_fn=get_model_test, \n",
    "                               verbose=0, \n",
    "                               callbacks=callbacks,\n",
    "                               epochs=100,\n",
    "                               **params,\n",
    "                        validation_data=(removed_val, valY))\n",
    "\n",
    "\n",
    "    #print(\"{} {}\".format(removed.shape, removed[index]))\n",
    "\n",
    "    model_tmp.fit(removed, trainY_balanced)\n",
    "    print(model_tmp.score(removed, trainY_balanced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0\n",
      "0.6397122740745544\n",
      "Testing: 1\n",
      "0.7078021764755249\n",
      "Testing: 2\n",
      "0.7106178998947144\n",
      "Testing: 3\n",
      "0.6338248252868652\n",
      "Testing: 4\n",
      "0.7048072218894958\n",
      "Testing: 5\n",
      "0.7164030075073242\n",
      "Testing: 6\n",
      "0.6437823176383972\n",
      "Testing: 7\n",
      "0.6440638899803162\n",
      "Testing: 8\n",
      "0.7207034230232239\n",
      "Testing: 9\n",
      "0.6353350877761841\n",
      "Testing: 10\n",
      "0.6394819021224976\n",
      "Testing: 11\n",
      "0.6476987600326538\n",
      "Testing: 12\n",
      "0.7246454954147339\n",
      "Testing: 13\n",
      "0.642246425151825\n",
      "Testing: 14\n",
      "0.6412481665611267\n",
      "Testing: 15\n",
      "0.6452670097351074\n",
      "Testing: 16\n",
      "0.6300363540649414\n",
      "Testing: 17\n",
      "0.6901653409004211\n",
      "Testing: 18\n",
      "0.6639789342880249\n",
      "Testing: 19\n",
      "0.6241489052772522\n",
      "Testing: 20\n",
      "0.6193621158599854\n",
      "Testing: 21\n",
      "0.6192085146903992\n",
      "Testing: 22\n",
      "0.6518712043762207\n",
      "Testing: 23\n",
      "0.8433164358139038\n",
      "Testing: 24\n",
      "0.6970767378807068\n",
      "Testing: 25\n",
      "0.5339937806129456\n"
     ]
    }
   ],
   "source": [
    "#print(my_model.score(trainX_balanced, trainY_balanced))\n",
    "\n",
    "for i in range(features):\n",
    "    print(\"Testing: {}\".format(i))\n",
    "    test_remove(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metric(history, metric): \n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_{}\".format(metric)])\n",
    "    plt.title(metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "#show_metric(history, \"loss\")\n",
    "#show_metric(history, \"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a3c171e34be4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mplot_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('True Negatives: ', cm[0][0])\n",
    "    print('True Positives: ', cm[1][1])\n",
    "\n",
    "    print('False Positives: ', cm[0][1])\n",
    "    print('False Negatives: ', cm[1][0])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "baseline_results = model.evaluate(valX, valY, verbose=1)\n",
    "\n",
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(valY, model.predict(valX))\n",
    "print(test_predictions_baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model \n",
    "\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, GlobalMaxPool1D, Bidirectional, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    " \n",
    "#Model \n",
    "\n",
    "dim = 100\n",
    "\n",
    "def add_deep_layers(x, dropout, units):\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def get_model(features, layers, units):\n",
    "    reset_seed()\n",
    "    inputX = Input(shape=features)\n",
    "    \n",
    "    x = normalizer(inputX)\n",
    "    \n",
    "    for lay in range(int(layers)):\n",
    "        x = add_deep_layers(x, 0.2, units)\n",
    "    \n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inputX], outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_model_rnn(seqs, features, units, dropout, lays, lays_seq):\n",
    "    inputX = Input(shape=(seqs, features))\n",
    "    \n",
    "    x = inputX\n",
    "    x = normalizer(inputX)\n",
    "    \n",
    "    for lay in range(int(lays_seq)):\n",
    "        x = LSTM(units=units, return_sequences=True)(x)\n",
    "    \n",
    "    #x = Bidirectional(LSTM(dim, return_sequences=False))(x)\n",
    "    x = LSTM(dim, return_sequences=False)(x)\n",
    "    \n",
    "    for lay in range(int(lays)):\n",
    "        x = add_deep_layers(x, dropout, units)\n",
    "        \n",
    "    x = Dense(20, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=[inputX], outputs=x)\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        #optimizer=ranger,\n",
    "        optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.00001, rho=0.95, epsilon=1e-07),\n",
    "        #optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model = load_model(filepath = \"drive/My Drive/model/stock.h5\")\n",
    "\n",
    "#!rm \"drive/My Drive/model/encoder.h5\"\n",
    "\n",
    "def get_simple():\n",
    "    model = Sequential()\n",
    "    reset_seed()\n",
    "    model.add(InputLayer(input_shape=features))\n",
    "    model.add(normalizer)\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def autokeras_class(max_trials = 30):\n",
    "    clf = ak.StructuredDataClassifier(overwrite=True, \n",
    "                                  max_trials=max_trials,\n",
    "                                  metrics=METRICS,\n",
    "                                  objective=kerastuner.Objective(\"val_prc\", direction=\"max\"),\n",
    "                                  project_name = \"AutoKeras\",\n",
    "                                  #tuner='random',\n",
    "                                 )\n",
    "    return clf\n",
    "\n",
    "def autokeras_time_class(max_trials = 30):\n",
    "    predict_from = 1\n",
    "    predict_until = 10\n",
    "    lookback = 0\n",
    "\n",
    "    return ak.TimeseriesForecaster(\n",
    "                              max_trials=max_trials,\n",
    "                              metrics=METRICS,\n",
    "                                  objective=kerastuner.Objective(\"val_prc\", direction=\"max\"),\n",
    "                              project_name = \"AutoKeras Time\",\n",
    "                              #tuner='random',\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 40\n",
    "a = [[i, i] for i in range(max)]\n",
    "\n",
    "\n",
    "def gen_y(i):\n",
    "    if (i > 35):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "b = [gen_y(i) for i in range(max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = create_dataset(a, b, time_steps=3, null_value = 0)\n",
    "\n",
    "print(xx.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "counter = Counter(yy)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))\n",
    "\n",
    "x_balanced, y_balanced = get_balanced_set_seq(xx, yy)\n",
    "\n",
    "print(x_balanced.shape)\n",
    "print(y_balanced.shape)\n",
    "\n",
    "counter = Counter(y_balanced)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_balanced) \n",
    "\n",
    "index = -4\n",
    "#print(x_balanced[index][-1][-1]) \n",
    "#print(y_balanced[index])\n",
    "\n",
    "for i in range(len(x_balanced)):\n",
    "    xx = x_balanced[i][-1][-1]\n",
    "    if (xx < 35):\n",
    "        print(\"{}) {} - {}\".format(i, xx, y_balanced[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "x_, y_ = create_dataset(trainX, trainY, time_steps=20, null_value = 0)\n",
    "\n",
    "print(x_.shape)\n",
    "print(y_.shape)\n",
    "\n",
    "counter = Counter(y_)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))\n",
    "\n",
    "x_balanced, y_balanced = get_balanced_set_seq(x_, y_)\n",
    "\n",
    "print(x_balanced.shape)\n",
    "print(y_balanced.shape)\n",
    "\n",
    "counter = Counter(y_balanced)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
