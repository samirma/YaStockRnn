{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "WbTLRASrfYo8",
    "outputId": "d981f8fa-dbba-4528-976b-316d52cc0efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "!pip install -q tensorflow_gpu==2.0.0-beta1 tensorflow-datasets matplotlib tqdm tensorflow_hub scipy\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator, pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext tensorboard\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BqYtLhBEiI18",
    "outputId": "e394e2f8-3d65-4cdf-a7e0-9f26a7a33642"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431169"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DataGenerator(random=False, first_index=10)\n",
    "dt.rewind()\n",
    "dt.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "ZWOEMA_Vrqm6"
   },
   "outputs": [],
   "source": [
    "# integer encode input data\n",
    "def onehot_encoded (integer_encoded, char_to_int = 2):\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    letter = [0 for _ in range(char_to_int)]\n",
    "    letter[integer_encoded] = 1\n",
    "    onehot_encoded.append(letter)\n",
    "    \n",
    "    return onehot_encoded[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GG09kYk6z5wv"
   },
   "outputs": [],
   "source": [
    "last_price = 0\n",
    "last_time = 0\n",
    "should_buy = 0\n",
    "should_sell = 0\n",
    "\n",
    "def get_date(state):\n",
    "    timestamp = int(state[\"timestamp\"])\n",
    "    return datetime.fromtimestamp(timestamp)\n",
    "\n",
    "\n",
    "def get_parse_state(raw_state, last_price, last_time):\n",
    "    list = []\n",
    "    price = raw_state[\"price\"]\n",
    "        \n",
    "    list.append(raw_state[\"amount\"])\n",
    "\n",
    "    def prepare_orders(orders, price, multi):\n",
    "        amount = float(orders[0][1])\n",
    "        for order in orders:\n",
    "            list.append((float(order[0])/price) * multi)\n",
    "            list.append(float(order[1])/amount)\n",
    "\n",
    "    history_step = 5\n",
    "    bids = raw_state[\"bids\"][:history_step]\n",
    "    asks = raw_state[\"asks\"][:history_step]\n",
    "    prepare_orders(bids, price, 1)\n",
    "    prepare_orders(asks, price, -1)\n",
    "\n",
    "    if last_price != 0:\n",
    "        list.extend([price/last_price])\n",
    "    else:\n",
    "        list.extend([0])\n",
    "        \n",
    "    current_timestamp = int(raw_state['timestamp'])\n",
    "    if last_time != 0:\n",
    "        list.extend([current_timestamp / last_time])\n",
    "    else:\n",
    "        list.extend([0])\n",
    "    #list = []\n",
    "    #list.extend([raw_state['timestamp']])\n",
    "    #print(current_timestamp)\n",
    "    return list\n",
    "\n",
    "def get_future_state(df, sec=120): # 2 min in future\n",
    "    state_timestamp = int(dt.get_from_index(dt.index-1)['timestamp'])\n",
    "    timestamp_limit = state_timestamp + sec\n",
    "    #print(\"Current timestamp\", state_timestamp, \" ==== \", timestamp_limit)\n",
    "    index = 0\n",
    "    timestamp = 0\n",
    "    while timestamp < timestamp_limit:\n",
    "        index += 3\n",
    "        state = dt.get_from_index(dt.index + index)\n",
    "        timestamp = int(state['timestamp'])\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def get_state(raw_state):\n",
    "    global last_price\n",
    "    global last_time\n",
    "    global should_buy\n",
    "    global should_sell\n",
    "    \n",
    "    list = get_parse_state(raw_state, last_price, last_time)\n",
    "\n",
    "    furure_state = get_future_state(dt)\n",
    "    future_price = furure_state[\"price\"]\n",
    "    \n",
    "    current_price = raw_state[\"price\"]\n",
    "    current_timestamp = int(raw_state['timestamp'])\n",
    "    \n",
    "    best_bid = float(furure_state[\"bids\"][0][0]) \n",
    "    is_value_incresed = best_bid >= (current_price + 0.2)\n",
    "\n",
    "    if is_value_incresed:\n",
    "        should_buy += 1\n",
    "        #print (current_price, \" ==== \", (current_price + 0.2), \" ===== \", furure_state)\n",
    "        y = onehot_encoded(0)\n",
    "    else:\n",
    "        #print (current_price, \" ==== \", (current_price + 0.2), \" ===== \", furure_state)\n",
    "        should_sell += 1\n",
    "        y = onehot_encoded(1)\n",
    "           \n",
    "    #print (y)\n",
    "    #print (get_date(raw_state), \" ==== \", get_date(furure_state))\n",
    "    \n",
    "    last_price = current_price\n",
    "    last_time = current_timestamp\n",
    "    return [list, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "1WLYGpGzwqj0",
    "outputId": "7f417e6c-5c3e-4993-ce47-8936692bddd6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 387152/387152 [06:35<00:00, 978.94it/s] \n",
      "100%|██████████| 43016/43016 [01:00<00:00, 712.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387152, 23)\n",
      "(387152, 2)\n",
      "(43016, 23)\n",
      "(43016, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dt.rewind()\n",
    "\n",
    "def get_set(data_count):\n",
    "  trainX = []\n",
    "  trainY = []\n",
    "  for i in tqdm(range(data_count)):\n",
    "      state = dt.next()\n",
    "      state = get_state(state)\n",
    "      trainX.append(state[0])\n",
    "      trainY.append(state[1])\n",
    "  trainX = np.array(trainX)\n",
    "  trainY = np.array(trainY)\n",
    "  return trainX, trainY\n",
    "\n",
    "data_count = dt.steps - 1000\n",
    "\n",
    "#data_count = 10000\n",
    "\n",
    "val_percentage = 0.1\n",
    "\n",
    "trainX, trainY = get_set(int(data_count*(1-val_percentage)))\n",
    "\n",
    "valX, valY = get_set(int(data_count*val_percentage))\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "\n",
    "print(valX.shape)\n",
    "print(valY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2vRFxrhCB946",
    "outputId": "06cff5be-01ed-413b-f7f4-86f3e9f99034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 1512\n"
     ]
    }
   ],
   "source": [
    "# define generator\n",
    "n_input = 100\n",
    "def get_gen(set_x, set_y):\n",
    "  return TimeseriesGenerator(set_x, set_y, length=n_input, batch_size=128*2)\n",
    "\n",
    "train_generator = get_gen(trainX, trainY)\n",
    "\n",
    "val_generator = get_gen(valX, valY)\n",
    "\n",
    "# number of samples\n",
    "print('Samples: %d' % len(train_generator))\n",
    "\n",
    "x, y = train_generator[0]\n",
    "\n",
    "features = x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mc7U6kNeMg_s"
   },
   "outputs": [],
   "source": [
    "inputX = Input(shape=(n_input,features))\n",
    "\n",
    "def add_deep_layers(input_layer):\n",
    "    x = Dense(100)(input_layer)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x_shorcut = x\n",
    "    x = Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = layers.add([x, x_shorcut])\n",
    "    return x\n",
    "\n",
    "x = add_deep_layers(LSTM(features*40)(inputX))\n",
    "x = add_deep_layers(x)\n",
    "x = add_deep_layers(x)\n",
    "x = add_deep_layers(x)\n",
    "x = Dense(100)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "x = Dense(100)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[inputX], outputs=x)\n",
    "\n",
    "\n",
    "filepath = \"stock.h5\"\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(lr=0.001, epsilon=1e-6),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP3mVyjILNn"
   },
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "id": "WpKkcu78jHtY",
    "outputId": "3ee1433b-b4d3-4baa-bee0-7c15bccb25d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 17:11:49.927427 140588483127104 deprecation.py:323] From /home/samir/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6309 - accuracy: 0.6725\n",
      "Epoch 00001: loss improved from inf to 0.63086, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6433s 4s/step - loss: 0.6308 - accuracy: 0.6726 - val_loss: 0.5987 - val_accuracy: 0.7182\n",
      "Epoch 2/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6246 - accuracy: 0.6735\n",
      "Epoch 00002: loss improved from 0.63086 to 0.62454, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6409s 4s/step - loss: 0.6245 - accuracy: 0.6735 - val_loss: 0.6004 - val_accuracy: 0.7182\n",
      "Epoch 3/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6220 - accuracy: 0.6738\n",
      "Epoch 00003: loss improved from 0.62454 to 0.62196, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6409s 4s/step - loss: 0.6219 - accuracy: 0.6739 - val_loss: 0.5986 - val_accuracy: 0.7182\n",
      "Epoch 4/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6202 - accuracy: 0.6736\n",
      "Epoch 00004: loss improved from 0.62196 to 0.62016, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6409s 4s/step - loss: 0.6202 - accuracy: 0.6737 - val_loss: 0.5981 - val_accuracy: 0.7182\n",
      "Epoch 5/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6183 - accuracy: 0.6744\n",
      "Epoch 00005: loss improved from 0.62016 to 0.61836, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6404s 4s/step - loss: 0.6184 - accuracy: 0.6744 - val_loss: 0.6003 - val_accuracy: 0.7181\n",
      "Epoch 6/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6176 - accuracy: 0.6735\n",
      "Epoch 00006: loss improved from 0.61836 to 0.61752, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6402s 4s/step - loss: 0.6175 - accuracy: 0.6736 - val_loss: 0.5989 - val_accuracy: 0.7182\n",
      "Epoch 7/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6161 - accuracy: 0.6744\n",
      "Epoch 00007: loss improved from 0.61752 to 0.61625, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6405s 4s/step - loss: 0.6162 - accuracy: 0.6742 - val_loss: 0.6008 - val_accuracy: 0.7179\n",
      "Epoch 8/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6153 - accuracy: 0.6732\n",
      "Epoch 00008: loss improved from 0.61625 to 0.61533, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6429s 4s/step - loss: 0.6153 - accuracy: 0.6731 - val_loss: 0.6008 - val_accuracy: 0.7180\n",
      "Epoch 9/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6130 - accuracy: 0.6744\n",
      "Epoch 00009: loss improved from 0.61533 to 0.61294, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6424s 4s/step - loss: 0.6129 - accuracy: 0.6745 - val_loss: 0.6041 - val_accuracy: 0.7184\n",
      "Epoch 10/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6124 - accuracy: 0.6744\n",
      "Epoch 00010: loss improved from 0.61294 to 0.61243, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6413s 4s/step - loss: 0.6124 - accuracy: 0.6744 - val_loss: 0.5988 - val_accuracy: 0.7182\n",
      "Epoch 11/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6119 - accuracy: 0.6734\n",
      "Epoch 00011: loss improved from 0.61243 to 0.61191, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6403s 4s/step - loss: 0.6119 - accuracy: 0.6735 - val_loss: 0.6049 - val_accuracy: 0.7179\n",
      "Epoch 12/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6102 - accuracy: 0.6748\n",
      "Epoch 00012: loss improved from 0.61191 to 0.61026, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6402s 4s/step - loss: 0.6102 - accuracy: 0.6747 - val_loss: 0.6013 - val_accuracy: 0.7180\n",
      "Epoch 13/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6094 - accuracy: 0.6738\n",
      "Epoch 00013: loss improved from 0.61026 to 0.60958, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6411s 4s/step - loss: 0.6096 - accuracy: 0.6737 - val_loss: 0.5993 - val_accuracy: 0.7182\n",
      "Epoch 14/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6069 - accuracy: 0.6762\n",
      "Epoch 00014: loss improved from 0.60958 to 0.60700, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6414s 4s/step - loss: 0.6070 - accuracy: 0.6761 - val_loss: 0.6043 - val_accuracy: 0.7165\n",
      "Epoch 15/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6074 - accuracy: 0.6738\n",
      "Epoch 00015: loss did not improve from 0.60700\n",
      "1511/1511 [==============================] - 6417s 4s/step - loss: 0.6075 - accuracy: 0.6737 - val_loss: 0.6004 - val_accuracy: 0.7182\n",
      "Epoch 16/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6044 - accuracy: 0.6763\n",
      "Epoch 00016: loss improved from 0.60700 to 0.60430, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6421s 4s/step - loss: 0.6043 - accuracy: 0.6764 - val_loss: 0.6025 - val_accuracy: 0.7173\n",
      "Epoch 17/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6060 - accuracy: 0.6740\n",
      "Epoch 00017: loss did not improve from 0.60430\n",
      "1511/1511 [==============================] - 6415s 4s/step - loss: 0.6058 - accuracy: 0.6742 - val_loss: 0.6028 - val_accuracy: 0.7177\n",
      "Epoch 18/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6036 - accuracy: 0.6760\n",
      "Epoch 00018: loss improved from 0.60430 to 0.60362, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6420s 4s/step - loss: 0.6036 - accuracy: 0.6760 - val_loss: 0.6031 - val_accuracy: 0.7164\n",
      "Epoch 19/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6015 - accuracy: 0.6775\n",
      "Epoch 00019: loss improved from 0.60362 to 0.60152, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6411s 4s/step - loss: 0.6015 - accuracy: 0.6775 - val_loss: 0.6032 - val_accuracy: 0.7167\n",
      "Epoch 20/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.6006 - accuracy: 0.6774\n",
      "Epoch 00020: loss improved from 0.60152 to 0.60063, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6432s 4s/step - loss: 0.6006 - accuracy: 0.6773 - val_loss: 0.6037 - val_accuracy: 0.7145\n",
      "Epoch 21/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.5988 - accuracy: 0.6781\n",
      "Epoch 00021: loss improved from 0.60063 to 0.59884, saving model to stock.h5\n",
      "1511/1511 [==============================] - 6431s 4s/step - loss: 0.5988 - accuracy: 0.6780 - val_loss: 0.6052 - val_accuracy: 0.7126\n",
      "Epoch 22/35\n",
      "1510/1511 [============================>.] - ETA: 4s - loss: 0.5997 - accuracy: 0.6775\n",
      "Epoch 00022: loss did not improve from 0.59884\n",
      "1511/1511 [==============================] - 6429s 4s/step - loss: 0.5997 - accuracy: 0.6775 - val_loss: 0.6058 - val_accuracy: 0.7155\n",
      "Epoch 23/35\n",
      "1263/1511 [========================>.....] - ETA: 16:53 - loss: 0.5933 - accuracy: 0.6827"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             load_weights_on_restart=True)\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data=val_generator, \n",
    "                              validation_steps=len(val_generator)-1,\n",
    "                              steps_per_epoch=len(train_generator)-1, \n",
    "                              epochs=35, verbose=1, \n",
    "                              callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Py04DHTvEqyD"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'], history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkEcOQ1yHRdu"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['accuracy'], history.history['val_accuracy'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdVwTPStI27s"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print (datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stock_rnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
