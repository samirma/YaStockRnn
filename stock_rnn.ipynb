{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import model as model_util\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalMaxPool1D, Bidirectional, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator, pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#%load_ext tensorboard\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed():\n",
    "    seed_value= 0\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(883497, 40)\n",
      "(883497,)\n",
      "Validation\n",
      "(2658, 40)\n",
      "(2658,)\n",
      "positiveX (121739, 40)\n",
      "negativeX (761758, 40)\n",
      "(883497, 40)\n",
      "(883497,)\n",
      "(2658, 40)\n",
      "(2658,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "path = \"drive/My Drive/model/\"\n",
    "path = \"./\"\n",
    "\n",
    "trainX = np.load(path + \"train\" + \"X.npy\")\n",
    "trainY = np.load(path + \"train\" + \"Y.npy\")\n",
    "print(\"Train\")\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "valX = np.load(path + \"val\" + \"X.npy\")\n",
    "valY = np.load(path + \"val\" + \"Y.npy\")\n",
    "print(\"Validation\")\n",
    "print(valX.shape)\n",
    "print(valY.shape)\n",
    "\n",
    "def get_balanced_set(X, Y):\n",
    "    positiveX = [X[0]]\n",
    "    positiveY = [Y[0]]\n",
    "    negativeX = [X[0]]\n",
    "    negativeY = [Y[0]]\n",
    "\n",
    "    for i in tqdm(range(1, len(X)-1)):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        if (y == 1):\n",
    "            positiveX.append(x)\n",
    "            positiveY.append(y)\n",
    "        else:\n",
    "            negativeX.append(x)\n",
    "            negativeY.append(y)\n",
    "   \n",
    "    positiveX = np.array(positiveX)\n",
    "    positiveY = np.array(positiveY)\n",
    "    negativeX = np.array(negativeX)\n",
    "    negativeY = np.array(negativeY)\n",
    "    \n",
    "    negative_num = len(positiveY)\n",
    "    start_index = random.randint(0,(len(negativeX) - negative_num))\n",
    "    end_index = start_index + negative_num\n",
    "    \n",
    "    print(start_index)\n",
    "    print(end_index)\n",
    "    \n",
    "    trainX = np.concatenate((positiveX, negativeX[start_index:end_index]), axis=0)\n",
    "    trainY = np.concatenate((positiveY, negativeY[start_index:end_index]), axis=0)\n",
    "    return trainX, trainY, positiveX, positiveY, negativeX, negativeY\n",
    "\n",
    "\n",
    "#trainX, trainY, positiveX, positiveY, negativeX, negativeY = get_balanced_set(trainX, trainY)\n",
    "\n",
    "#valX, valY, positiveX_, positiveY_, negativeX_, negativeY_ = get_balanced_set(valX, valY)\n",
    "\n",
    "\n",
    "print(\"positiveX {0}\".format(positiveX.shape))\n",
    "print(\"negativeX {0}\".format(negativeX.shape))\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(valX.shape)\n",
    "print(valY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 1726\n",
      "(512, 80, 40)\n",
      "(512, 80, 40)\n"
     ]
    }
   ],
   "source": [
    "# define generator\n",
    "n_input = 80\n",
    "\n",
    "class CustomGen(TimeseriesGenerator):\n",
    "    def __getitem__(self, idx):\n",
    "        x,y = super().__getitem__(idx)\n",
    "        return x, x\n",
    "\n",
    "def get_gen(set_x, set_y, shuffle=True, batch_size=512):\n",
    "    return CustomGen(set_x, set_y, length=n_input, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_generator = get_gen(trainX, trainY, shuffle=True)\n",
    "\n",
    "val_generator = get_gen(negativeX_, negativeX_, shuffle=False)\n",
    "\n",
    "# number of samples\n",
    "print('Samples: %d' % len(train_generator))\n",
    "\n",
    "x, y = train_generator[0]\n",
    "\n",
    "x_, y_ = val_generator[0]\n",
    "\n",
    "features = x.shape[2]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.layers import RepeatVector, TimeDistributed, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "\n",
    "from tensorflow.keras import Model, Sequential, regularizers\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "dim = 20\n",
    "\n",
    "def add_deep_layers(input_layer, units = features):\n",
    "    x = Dense(units, activation='elu', kernel_regularizer=regularizers.l2(0.0001))(input_layer)\n",
    "    x = Dense(units, activation='elu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
    "    x = Dense(units, activation='elu', kernel_regularizer=regularizers.l2(0.0001))(x)\n",
    "    return x\n",
    "\n",
    "def get_model(seqs, features):\n",
    "    reset_seed()\n",
    "    inputX = Input(shape=(seqs,features))\n",
    "    x = Dense(features, activation='elu')(inputX)\n",
    "    x = Bidirectional(LSTM(units=features, return_sequences=True, activation='relu'))(x)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = Dense(30, activation='elu')(x)\n",
    "    x = Dense(30, activation='elu')(x)\n",
    "    x = Dense(30, activation='elu')(x)\n",
    "    x = Dense(30, activation='elu')(x)\n",
    "    x = Bidirectional(LSTM(30, activation='elu', return_sequences=False))(x)\n",
    "    x = Dense(30, activation='elu')(x)\n",
    "    x = Dense(dim, activation='elu', name= \"encoder\")(x)\n",
    "    \n",
    "    encoder = x\n",
    "\n",
    "    # Decoder\n",
    "    x = RepeatVector(seqs, name= \"dencoder\")(encoder)\n",
    "    x = Bidirectional(LSTM(dim, return_sequences=True, activation='elu'))(x)\n",
    "    x = add_deep_layers(x, dim)\n",
    "    x = add_deep_layers(x, (features+dim)/2)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = add_deep_layers(x, features)\n",
    "    x = Dense(features, activation='elu')(x)\n",
    "    x = TimeDistributed(Dense(features, activation='elu'))(x)\n",
    "    x = Dense(features)(x)\n",
    "\n",
    "    model = Model(inputs=[inputX], outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "def load_model(filepath = \"drive/My Drive/model/stock.h5\"):\n",
    "    model_loaded = tf.keras.models.load_model(filepath)\n",
    "    return model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = get_model(n_input, features)\n",
    "#model = load_model(filepath = \"drive/My Drive/model/stock.h5\")\n",
    "#model.summary()\n",
    "\n",
    "#!rm \"encoder.h5\"\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=True),\n",
    "                  loss='mean_squared_logarithmic_error',\n",
    "                  #loss='mean_squared_error',\n",
    "                  #loss='mean_absolute_error',\n",
    "                  #loss='squared_hinge'\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`load_weights_on_restart` argument is deprecated. Please use `model.load_weights()` for loading weights before the start of `model.fit()`.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1725 steps\n",
      "Epoch 1/10\n",
      " 121/1725 [=>............................] - ETA: 13:15 - loss: 8.6154 - accuracy: 0.0336"
     ]
    }
   ],
   "source": [
    "\n",
    "filepath_encoder = \"encoder.h5\"\n",
    "\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath_encoder, monitor='loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             load_weights_on_restart=True)\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    #x, x,\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator)-1, \n",
    "    epochs=10, \n",
    "    verbose=1, \n",
    "    callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(history): \n",
    "  plt.plot(history.history['loss'])\n",
    "  #plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "show_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(history):\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  #plt.plot(history.history['val_loss'])\n",
    "  plt.title('accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "show_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.losses import mean_squared_logarithmic_error, mean_squared_error\n",
    "\n",
    "def error(y_true, y_pred):\n",
    "    return np.mean(mean_squared_logarithmic_error(y_true, y_pred))\n",
    "\n",
    "def show_result(modell):\n",
    "    pred = modell.predict(x_)\n",
    "    score1 = error(pred,x_)\n",
    "    print(f\"Out of Sample Score (RMSE): {score1}\")\n",
    "    pred = modell.predict(x)\n",
    "    score2 = error(pred,x)\n",
    "    print(f\"Insample Normal Score (RMSE): {score2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Sample Score (RMSE): 5.585374476245208\n",
      "Insample Normal Score (RMSE): 6.573929674782894\n"
     ]
    }
   ],
   "source": [
    "show_result(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "posX_, posY_ = get_gen(positiveX_, positiveX_, shuffle=True, batch_size=len(positiveX_))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Underway Score (RMSE): 6.11366899507781\n"
     ]
    }
   ],
   "source": [
    "x_attack = posX_\n",
    "pred = model.predict(x_attack)\n",
    "score3 = error(pred,x_attack)\n",
    "print(f\"Attack Underway Score (RMSE): {score3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_attack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error(model.predict(np.array([test])), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = model\n",
    "encoder = Model(inputs=model_loaded.input, outputs=model_loaded.get_layer('encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.predict(np.array([x_attack[20]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array([test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveY_[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
