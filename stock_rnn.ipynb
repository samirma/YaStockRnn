{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "from data_util import *\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import model as model_util\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed():\n",
    "    seed_value= 0\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "path = \"./data/\"\n",
    "model_path = path + \"stock.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, positiveX, positiveY, negativeX, negativeY = load_data(\"\", \"train\", path, balanced = True)\n",
    "valX, valY, positiveX_, positiveY_, negativeX_, negativeY_ = load_data(\"\", \"Val\", path, balanced = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10\n",
    "seqs = 30\n",
    "dropout = 0.1\n",
    "lays = 5\n",
    "lays_seq = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 6576\n",
      "(420854, 30, 35)\n",
      "(420854, 2)\n",
      "Feature: 35\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/\n",
    "# define generator\n",
    "batch_size = 512\n",
    "\n",
    "train_generator = get_gen(trainX, trainY, shuffle=False, time_steps = seqs)\n",
    "\n",
    "val_generator = get_gen(valX, valY, shuffle=False, time_steps = seqs)\n",
    "\n",
    "x_train, y_train = create_dataset(trainX, trainY, seqs)\n",
    "\n",
    "x_val, y_val = create_dataset(valX, valY, seqs)\n",
    "\n",
    "\n",
    "# number of samples\n",
    "print('Samples: %d' % len(train_generator))\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "features = x_train.shape[-1]\n",
    "\n",
    "print(\"Feature: {}\".format(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 35)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[90].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`load_weights_on_restart` argument is deprecated. Please use `model.load_weights()` for loading weights before the start of `model.fit()`.\n",
      "Training on: 420854 val 14934\n",
      "Epoch 1/100\n",
      "822/822 [==============================] - 67s 75ms/step - loss: 0.7273 - accuracy: 0.5000 - val_loss: 0.7965 - val_accuracy: 0.1170\n",
      "Epoch 2/100\n",
      "822/822 [==============================] - 60s 73ms/step - loss: 0.7236 - accuracy: 0.5009 - val_loss: 0.7851 - val_accuracy: 0.1323\n",
      "Epoch 3/100\n",
      "822/822 [==============================] - 60s 72ms/step - loss: 0.7197 - accuracy: 0.5010 - val_loss: 0.7744 - val_accuracy: 0.1507\n",
      "Epoch 4/100\n",
      "822/822 [==============================] - 59s 72ms/step - loss: 0.7165 - accuracy: 0.5007 - val_loss: 0.7642 - val_accuracy: 0.1684\n",
      "Epoch 5/100\n",
      "822/822 [==============================] - 60s 72ms/step - loss: 0.7139 - accuracy: 0.5001 - val_loss: 0.7554 - val_accuracy: 0.1866\n",
      "Epoch 6/100\n",
      "168/822 [=====>........................] - ETA: 45s - loss: 0.7130 - accuracy: 0.4994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-df27c707ffff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_regular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on: {} val {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.summary()\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "use_regular = True #@param {type:\"boolean\"}\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             load_weights_on_restart=True)\n",
    "\n",
    "callbacks_list = []\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "if (use_regular):\n",
    "    print(\"Training on: {} val {}\".format(len(y_train), len(y_val)))\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "else:\n",
    "    print(\"Training on: {} val {}\".format(len(train_generator)*batch_size, len(val_generator)))\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        validation_data = val_generator,\n",
    "        steps_per_epoch = len(train_generator),\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(history): \n",
    "    plt.plot(history.history['loss'])\n",
    "    if (history.history['val_loss']):\n",
    "        plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "show_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    if (history.history['val_accuracy']):\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "show_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model_loaded = load_model(filepath = filepath_encoder)\n",
    "model_loaded = model\n",
    "\n",
    "to_int = np.vectorize(lambda x: int(round(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posX_, posY_ = create_dataset(positiveX_, positiveY_, seqs)\n",
    "negX_, negY_ = create_dataset(negativeX_, negativeY_, seqs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_loaded.predict(negX_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_final = to_int(model_loaded.predict(posX_))\n",
    "neg_final = to_int(model_loaded.predict(negX_))\n",
    "\n",
    "\n",
    "pos_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded.evaluate(posX_, posY_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(list):\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    for x in list:\n",
    "        if (x == 1):\n",
    "            pos_count += 1\n",
    "        else:\n",
    "            neg_count += 1\n",
    "    print(\"Pos: {} Neg {}\".format(pos_count, neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pos\")\n",
    "check(pos_final)\n",
    "print(\"Neg\")\n",
    "check(neg_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded.predict(posX_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded.predict(negX_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = model\n",
    "valX, valY, positiveX_, positiveY_, negativeX_, negativeY_ = load_data(\"btcusd\", \"Val\", path, False)\n",
    "model_loaded.evaluate(get_gen(valX, valY, shuffle=False, time_steps = seqs)) \n",
    "\n",
    "valX, valY, positiveX_, positiveY_, negativeX_, negativeY_ = load_data(\"ethusd\", \"Val\", path, False)\n",
    "model_loaded.evaluate(get_gen(valX, valY, shuffle=False, time_steps = seqs)) \n",
    "\n",
    "valX, valY, positiveX_, positiveY_, negativeX_, negativeY_ = load_data(\"btcusd17\", \"Val\", path, False)\n",
    "model_loaded.evaluate(get_gen(valX, valY, shuffle=False, time_steps = seqs)) \n",
    "\n",
    "valX, valY, positiveX_, positiveY_, negativeX_, negativeY_ = load_data(\"btcusdAug19\", \"Val\", path, False)\n",
    "model_loaded.evaluate(get_gen(valX, valY, shuffle=False, time_steps = seqs)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "Y = list()\n",
    "X = [x+1 for x in range(200)]\n",
    "Y = [y for y in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = get_gen(X, Y, shuffle=True, batch_size=20)\n",
    "\n",
    "x, y = create_dataset(X, Y, seqs)\n",
    "\n",
    "index = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model \n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalMaxPool1D, Bidirectional, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    " \n",
    "\n",
    "#dim = 600\n",
    "att = 15\n",
    "\n",
    "def add_attention(x, d_model = 512):\n",
    "    query = tf.keras.layers.Dense(d_model)(x)  \n",
    "    value = tf.keras.layers.Dense(d_model)(x)\n",
    "    key = tf.keras.layers.Dense(d_model)(x)\n",
    "    attention = tf.keras.layers.Attention()([query, value, key]) \n",
    "    x = tf.keras.layers.Add()([x, attention])\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def add_deep_layers(input_layer, units = dim):\n",
    "    x = Dense(units)(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(units, activation='tanh')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(units, activation='swish')(x)\n",
    "    return x\n",
    "\n",
    "def get_model(seqs, features):\n",
    "    reset_seed()\n",
    "    inputX = Input(shape=(\n",
    "        seqs,\n",
    "        features\n",
    "        )\n",
    "    )\n",
    "    x = inputX\n",
    "    x = add_attention(x, features)\n",
    "    x = LSTM(units=att, return_sequences=True)(x)\n",
    "    x = add_deep_layers(x, dim)\n",
    "    x = LSTM(dim, return_sequences=False)(x)\n",
    "    x = add_deep_layers(x, dim)\n",
    "    x = add_deep_layers(x, dim)\n",
    "    x = add_deep_layers(x, dim)\n",
    "    x = add_deep_layers(x, dim)\n",
    "    x = add_deep_layers(x, 20)\n",
    "    x = Dense(10)(x)\n",
    "    x = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inputX], outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "def load_model(filepath = \"stock.h5\"):\n",
    "    model_loaded = tf.keras.models.load_model(filepath)\n",
    "    return model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 30, 35)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30, 35)       1260        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 30, 35)       1260        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30, 35)       1260        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 30, 35)       0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 30, 35)       0           input_3[0][0]                    \n",
      "                                                                 attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 30, 35)       70          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 30, 15)       3060        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30, 10)       160         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 30, 10)       40          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 10)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 30, 10)       110         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 10)       0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 30, 10)       110         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 10)           840         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           110         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 10)           40          dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 10)           110         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 10)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 10)           110         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 10)           110         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10)           40          dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 10)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           110         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 10)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10)           110         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 10)           110         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10)           40          dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 10)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 10)           110         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 10)           0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 10)           110         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 10)           110         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10)           40          dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 10)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 10)           110         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 10)           0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 10)           110         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 20)           220         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 20)           80          dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 20)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 20)           420         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 20)           0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 20)           420         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 10)           210         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 2)            22          dense_27[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 11,022\n",
      "Trainable params: 10,882\n",
      "Non-trainable params: 140\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#model = load_model(filepath = \"drive/My Drive/model/stock.h5\")\n",
    "\n",
    "#!rm \"drive/My Drive/model/encoder.h5\"\n",
    "\n",
    "model = get_model(seqs, features)\n",
    "\n",
    "#radam = tfa.optimizers.RectifiedAdam()\n",
    "#ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "\n",
    "model.compile(\n",
    "    #optimizer=ranger,\n",
    "    optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm \"stock.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
