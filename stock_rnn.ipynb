{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "WbTLRASrfYo8",
    "outputId": "d981f8fa-dbba-4528-976b-316d52cc0efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "!pip install -q tensorflow_gpu==2.0.0-beta1 tensorflow-datasets matplotlib tqdm tensorflow_hub scipy\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator, pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext tensorboard\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BqYtLhBEiI18",
    "outputId": "e394e2f8-3d65-4cdf-a7e0-9f26a7a33642"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426116"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DataGenerator(random=False, first_index=10)\n",
    "dt.rewind()\n",
    "dt.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "ZWOEMA_Vrqm6"
   },
   "outputs": [],
   "source": [
    "# integer encode input data\n",
    "def onehot_encoded (integer_encoded, char_to_int = 2):\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    letter = [0 for _ in range(char_to_int)]\n",
    "    letter[integer_encoded] = 1\n",
    "    onehot_encoded.append(letter)\n",
    "    \n",
    "    return onehot_encoded[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GG09kYk6z5wv"
   },
   "outputs": [],
   "source": [
    "last_price = 0\n",
    "last_time = 0\n",
    "should_buy = 0\n",
    "should_sell = 0\n",
    "\n",
    "def get_date(state):\n",
    "    timestamp = int(state[\"timestamp\"])\n",
    "    return datetime.fromtimestamp(timestamp)\n",
    "\n",
    "\n",
    "def get_parse_state(raw_state, last_price, last_time):\n",
    "    list = []\n",
    "    price = raw_state[\"price\"]\n",
    "        \n",
    "    list.append(raw_state[\"amount\"])\n",
    "\n",
    "    def prepare_orders(orders, price, multi):\n",
    "        amount = float(orders[0][1])\n",
    "        for order in orders:\n",
    "            list.append((float(order[0])/price) * multi)\n",
    "            list.append(float(order[1])/amount)\n",
    "\n",
    "    history_step = 5\n",
    "    bids = raw_state[\"bids\"][:history_step]\n",
    "    asks = raw_state[\"asks\"][:history_step]\n",
    "    prepare_orders(bids, price, 1)\n",
    "    prepare_orders(asks, price, -1)\n",
    "\n",
    "    if last_price != 0:\n",
    "        list.extend([price/last_price])\n",
    "    else:\n",
    "        list.extend([0])\n",
    "        \n",
    "    current_timestamp = int(raw_state['timestamp'])\n",
    "    if last_time != 0:\n",
    "        list.extend([current_timestamp / last_time])\n",
    "    else:\n",
    "        list.extend([0])\n",
    "    #list = []\n",
    "    #list.extend([raw_state['timestamp']])\n",
    "    #print(current_timestamp)\n",
    "    return list\n",
    "\n",
    "def get_future_state(df, sec=120): # 2 min in future\n",
    "    state_timestamp = int(dt.get_from_index(dt.index-1)['timestamp'])\n",
    "    timestamp_limit = state_timestamp + sec\n",
    "    #print(\"Current timestamp\", state_timestamp, \" ==== \", timestamp_limit)\n",
    "    index = 0\n",
    "    timestamp = 0\n",
    "    while timestamp < timestamp_limit:\n",
    "        index += 3\n",
    "        state = dt.get_from_index(dt.index + index)\n",
    "        timestamp = int(state['timestamp'])\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def get_state(raw_state):\n",
    "    global last_price\n",
    "    global last_time\n",
    "    global should_buy\n",
    "    global should_sell\n",
    "    \n",
    "    list = get_parse_state(raw_state, last_price, last_time)\n",
    "\n",
    "    furure_state = get_future_state(dt)\n",
    "    future_price = furure_state[\"price\"]\n",
    "    \n",
    "    current_price = raw_state[\"price\"]\n",
    "    current_timestamp = int(raw_state['timestamp'])\n",
    "    \n",
    "    best_bid = float(furure_state[\"bids\"][0][0]) \n",
    "    is_value_incresed = best_bid >= (current_price + 0.2)\n",
    "\n",
    "    if is_value_incresed:\n",
    "        should_buy += 1\n",
    "        #print (current_price, \" ==== \", (current_price + 0.2), \" ===== \", furure_state)\n",
    "        y = onehot_encoded(0)\n",
    "    else:\n",
    "        #print (current_price, \" ==== \", (current_price + 0.2), \" ===== \", furure_state)\n",
    "        should_sell += 1\n",
    "        y = onehot_encoded(1)\n",
    "           \n",
    "    #print (y)\n",
    "    #print (get_date(raw_state), \" ==== \", get_date(furure_state))\n",
    "    \n",
    "    last_price = current_price\n",
    "    last_time = current_timestamp\n",
    "    return [list, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "1WLYGpGzwqj0",
    "outputId": "7f417e6c-5c3e-4993-ce47-8936692bddd6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:07<00:00, 1147.58it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1237.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 23)\n",
      "(9000, 2)\n",
      "(1000, 23)\n",
      "(1000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dt.rewind()\n",
    "\n",
    "def get_set(data_count):\n",
    "  trainX = []\n",
    "  trainY = []\n",
    "  for i in tqdm(range(data_count)):\n",
    "      state = dt.next()\n",
    "      state = get_state(state)\n",
    "      trainX.append(state[0])\n",
    "      trainY.append(state[1])\n",
    "  trainX = np.array(trainX)\n",
    "  trainY = np.array(trainY)\n",
    "  return trainX, trainY\n",
    "\n",
    "data_count = dt.steps - 1000\n",
    "\n",
    "data_count = 10000\n",
    "\n",
    "val_percentage = 0.1\n",
    "\n",
    "trainX, trainY = get_set(int(data_count*(1-val_percentage)))\n",
    "\n",
    "valX, valY = get_set(int(data_count*val_percentage))\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "\n",
    "print(valX.shape)\n",
    "print(valY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2vRFxrhCB946",
    "outputId": "06cff5be-01ed-413b-f7f4-86f3e9f99034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 35\n"
     ]
    }
   ],
   "source": [
    "# define generator\n",
    "n_input = 200\n",
    "def get_gen(set_x, set_y):\n",
    "  return TimeseriesGenerator(set_x, set_y, length=n_input, batch_size=128*2)\n",
    "\n",
    "train_generator = get_gen(trainX, trainY)\n",
    "\n",
    "val_generator = get_gen(valX, valY)\n",
    "\n",
    "# number of samples\n",
    "print('Samples: %d' % len(train_generator))\n",
    "\n",
    "x, y = train_generator[0]\n",
    "\n",
    "features = x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mc7U6kNeMg_s"
   },
   "outputs": [],
   "source": [
    "inputX = Input(shape=(n_input,features))\n",
    "\n",
    "def add_deep_layers(input_layer):\n",
    "    x = Dense(100)(input_layer)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x_shorcut = x\n",
    "    x = Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(300)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(300)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = layers.add([x, x_shorcut])\n",
    "    return x\n",
    "\n",
    "x = add_deep_layers(LSTM(features*20)(inputX))\n",
    "x = add_deep_layers(x)\n",
    "x = add_deep_layers(x)\n",
    "x = add_deep_layers(x)\n",
    "x = Dense(100)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "x = Dense(100)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[inputX], outputs=x)\n",
    "\n",
    "\n",
    "filepath = \"stock.h5\"\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP3mVyjILNn"
   },
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "id": "WpKkcu78jHtY",
    "outputId": "3ee1433b-b4d3-4baa-bee0-7c15bccb25d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 15:15:51.396095 139961991391040 deprecation.py:323] From /home/samir/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/34 [====>.........................] - ETA: 2:28 - loss: 0.7006 - accuracy: 0.4375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ca8994bfda0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                               callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             load_weights_on_restart=True)\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data=val_generator, \n",
    "                              validation_steps=len(val_generator)-1,\n",
    "                              steps_per_epoch=len(train_generator)-1, \n",
    "                              epochs=1, verbose=1, \n",
    "                              callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Py04DHTvEqyD"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'], history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkEcOQ1yHRdu"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['accuracy'], history.history['val_accuracy'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdVwTPStI27s"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print (datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stock_rnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
