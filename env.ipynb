{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503083,
     "status": "ok",
     "timestamp": 1568068274112,
     "user": {
      "displayName": "Samir Moreira Antônio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCsh3ldsSLN0VnFRYp341EzO_UyuRNKmLncUbMA3Q=s64",
      "userId": "14581632111443153742"
     },
     "user_tz": -60
    },
    "id": "fGVQczSlF-9o",
    "outputId": "e3a06798-f737-48d9-ec6e-d3784cec3115"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from state_util import StateUtil\n",
    "from tec_an import TecAn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = 10\n",
    "\n",
    "def get_tecs(raw_dir = \"stock_data/\"):\n",
    "    data_gen = DataGenerator(random=False, base_dir = raw_dir)\n",
    "    data_gen.rewind()\n",
    "    stateUtil = StateUtil(data_gen, future = future)\n",
    "    data = []\n",
    "    data_count = data_gen.max_steps()\n",
    "    tec = TecAn()\n",
    "    for i in tqdm(range(data_count)):\n",
    "        raw = data_gen.next()\n",
    "        price = raw[stateUtil.PRICE_KEY]\n",
    "        amount = raw[stateUtil.AMOUNT_KEY]\n",
    "        data.append([price, amount])\n",
    "    \n",
    "    def calcule_tecs():\n",
    "        tecs = []\n",
    "        print(\"Data {}\".format(len(data)))\n",
    "        df = pd.DataFrame(data, columns = ['Close', 'Volume'])\n",
    "        close = df['Close']\n",
    "        volume = df['Volume']\n",
    "        for ta in tec.tas:\n",
    "            value = ta(close, volume, 0.0, 0.0)\n",
    "            tecs.append(value)\n",
    "        return tecs\n",
    "    \n",
    "    return calcule_tecs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tacs(list, index, result):\n",
    "    list = []\n",
    "    print(len(result[-1]))\n",
    "    print(index)\n",
    "    for tec in result:\n",
    "        list.append(tec.iloc[index])\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 687284,
     "status": "ok",
     "timestamp": 1568068979529,
     "user": {
      "displayName": "Samir Moreira Antônio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCsh3ldsSLN0VnFRYp341EzO_UyuRNKmLncUbMA3Q=s64",
      "userId": "14581632111443153742"
     },
     "user_tz": -60
    },
    "id": "eO4im0aG2zql",
    "outputId": "e3d3b69a-c7ce-4779-c6e3-673b4bd7ba9a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing btcusd\n",
      "Recovering TECs\n",
      "Loading 514388 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc94c71fc5ec4de5a2ed397c5ccf3b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512844 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52439c2a5a11415cbeb9bda7b0cf3780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (512844, 21) (512844,) (1543, 21) (1543,)\n",
      "Total to be added 514387\n",
      "./btcusdtrainX.npy\n",
      "Processing ethusd\n",
      "Recovering TECs\n",
      "Loading 258219 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd6eebb01f54bfa926d3bac43fa5f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/257444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c71074a68d4daa8132caaf7f3afe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (257444, 21) (257444,) (774, 21) (774,)\n",
      "Total to be added 258218\n",
      "./ethusdtrainX.npy\n",
      "Processing btcusd17\n",
      "Recovering TECs\n",
      "Loading 224065 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9824844d424ee9b0c01005a7b02f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5531019b7f46d18fb2bfc34a789692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (223392, 21) (223392,) (672, 21) (672,)\n",
      "Total to be added 224064\n",
      "./btcusd17trainX.npy\n",
      "Processing btcusdAug19\n",
      "Recovering TECs\n",
      "Loading 888156 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce62e233c8c841c5b7f393e6028ee04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/885491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073396b6be6d48108793c0442542ac6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (885491, 21) (885491,) (2664, 21) (2664,)\n",
      "Total to be added 888155\n",
      "./btcusdAug19trainX.npy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6d8812aa173c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mbtcusdAug19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"btcusdAug19\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconc_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sets' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"./\" \n",
    "\n",
    "\n",
    "import data_util\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "def save(data_set, prefix = \"\"):\n",
    "  trainX = data_set[0]\n",
    "  trainY = data_set[1]\n",
    "  valX = data_set[2]\n",
    "  valY = data_set[3]\n",
    "  train_path = \"{}{}trainX.npy\".format(path, prefix)\n",
    "  np.save(train_path, trainX)\n",
    "  np.save(\"{}{}trainY.npy\".format(path, prefix), trainY)\n",
    "  np.save(\"{}{}valX.npy\".format(path, prefix), valX)\n",
    "  np.save(\"{}{}valY.npy\".format(path, prefix), valY)\n",
    "  print(train_path)\n",
    "\n",
    "def load_datasets(dirs):\n",
    "    sets = []  \n",
    "    for raw_dir in dirs:\n",
    "        data_gen = DataGenerator(random = False, base_dir = raw_dir + \"/\")\n",
    "        data_gen.rewind()\n",
    "        full = data_gen.steps\n",
    "        print(\"Processing {}\".format(raw_dir))\n",
    "        print(\"Recovering TECs\")\n",
    "        #result = get_tecs(raw_dir)\n",
    "        #print(\"TECs recovered {}\".format((result[-1].size)))\n",
    "        parsed = lambda list, price, amount, index: list#add_tacs(list, index, result)\n",
    "        print(\"Loading {} states\".format(full))\n",
    "        final_data = data_util.get_sets(data_gen, full, val_percentage = 0.003, path = path, use_cache=False, on_state_parsed = parsed)\n",
    "        count = len(final_data[0]) + len(final_data[-1])\n",
    "        print(\"Total to be added {}\".format(count))\n",
    "        save(final_data, raw_dir)\n",
    "        sets.append(final_data)\n",
    "    return sets\n",
    "\n",
    "def conc_sets(sets):\n",
    "  trainX = sets[0][0]\n",
    "  trainY = sets[0][1]\n",
    "  valX = sets[0][2]\n",
    "  valY = sets[0][3]\n",
    "  for i in range(1,  len(sets)):\n",
    "    data_set = sets[i]\n",
    "    trainX = np.append(data_set[0], trainX, axis = 0)\n",
    "    trainY = np.append(data_set[1], trainY, axis = 0)\n",
    "    valX = np.append(data_set[2], valX, axis = 0)\n",
    "    valY = np.append(data_set[3], valY, axis = 0)\n",
    "  return trainX, trainY, valX, valY\n",
    "\n",
    "\n",
    "btcusd = load_datasets([\"btcusd\"])\n",
    "ethusd = load_datasets([\"ethusd\"])\n",
    "ethusd = load_datasets([\"btcusd17\"])\n",
    "ethusd = load_datasets([\"btcusdAug19\"])\n",
    "\n",
    "#sets = load_datasets([\"btcusd17\", \"btcusdAug19\", \"ethusd\"])\n",
    "\n",
    "data_set = conc_sets(sets)\n",
    "save(data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c3ab63c0b4cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtcusd17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtcusdAug19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconc_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6d8812aa173c>\u001b[0m in \u001b[0;36mconc_sets\u001b[0;34m(sets)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconc_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mvalX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mvalY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sets = []\n",
    "sets.append(ethusd)\n",
    "sets.append(btcusd17)\n",
    "sets.append(btcusdAug19)\n",
    "data_set = conc_sets(sets)\n",
    "save(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from state_util import StateUtil\n",
    "from tec_an import TecAn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "raw_dir = \"ethusdMar/\"\n",
    "data_gen = DataGenerator(random=False, first_index=0, base_dir = raw_dir)\n",
    "stateUtil = StateUtil(data_gen, future = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = data_gen.next()\n",
    "print(state['timestamp'])\n",
    "state = data_gen.next()\n",
    "print(state['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = data_gen.next()\n",
    "print(state['timestamp'])\n",
    "x, y, raw_state, furure_state = stateUtil.get_state(state, data_gen.index)\n",
    "\n",
    "current = int(raw_state['timestamp'])\n",
    "microcurrent = int(raw_state['microtimestamp'])\n",
    "\n",
    "future = int(furure_state['timestamp'])\n",
    "microfuture = int(furure_state['microtimestamp'])\n",
    "print(\"{} - {} \".format(current, microcurrent))\n",
    "print(\"{} - {} \".format(future, microfuture))\n",
    "print(\"Diff: {}\".format(future - current))\n",
    "print(\"Y: {}\".format(y))\n",
    "\n",
    "ask = float(raw_state[stateUtil.ASKS_KEY][0][0]) \n",
    "print(\"Ask: {}\".format(ask))\n",
    "future_bid = float(furure_state[stateUtil.BIDS_KEY][0][0])\n",
    "print(\"Bid: {}\".format(future_bid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = get_tecs(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataGenerator steps {}\".format(data_gen.steps))\n",
    "print(\"DataGenerator max_steps {}\".format(data_gen.max_steps()))\n",
    "print(\"TACS {}\".format(result[0].size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = DataGenerator(random = False, base_dir = raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.59.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "enviroment",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
