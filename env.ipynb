{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503083,
     "status": "ok",
     "timestamp": 1568068274112,
     "user": {
      "displayName": "Samir Moreira Antônio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCsh3ldsSLN0VnFRYp341EzO_UyuRNKmLncUbMA3Q=s64",
      "userId": "14581632111443153742"
     },
     "user_tz": -60
    },
    "id": "fGVQczSlF-9o",
    "outputId": "e3a06798-f737-48d9-ec6e-d3784cec3115"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from state_util import StateUtil\n",
    "from tec_an import TecAn\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "import threading\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = 10\n",
    "\n",
    "def get_tecs(raw_dir = \"stock_data/\"):\n",
    "    data_gen = DataGenerator(random=False, base_dir = raw_dir)\n",
    "    data_gen.rewind()\n",
    "    stateUtil = StateUtil(data_gen, future = future)\n",
    "    data = []\n",
    "    data_count = data_gen.max_steps()\n",
    "    tec = TecAn()\n",
    "    for i in tqdm(range(data_count)):\n",
    "        raw = data_gen.next()\n",
    "        price = raw[stateUtil.PRICE_KEY]\n",
    "        amount = raw[stateUtil.AMOUNT_KEY]\n",
    "        data.append([price, amount])\n",
    "    \n",
    "    def calcule_tecs():\n",
    "        tecs = []\n",
    "        print(\"Data {}\".format(len(data)))\n",
    "        df = pd.DataFrame(data, columns = ['Close', 'Volume'])\n",
    "        close = df['Close']\n",
    "        volume = df['Volume']\n",
    "        for ta in tec.tas:\n",
    "            value = ta(close, volume, 0.0, 0.0)\n",
    "            tecs.append(value)\n",
    "        return tecs\n",
    "    \n",
    "    return calcule_tecs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tacs(list, index, result):\n",
    "    list = []\n",
    "    #print(len(result[-1]))\n",
    "    #print(index)\n",
    "    for tec in result:\n",
    "        list.append(tec.iloc[index])\n",
    "    return list\n",
    "\n",
    "def add_tacs_realtime(list, price, amount, tec):\n",
    "    list = []\n",
    "    list.extend(tec.add_ta(price, amount))\n",
    "    #inds = np.array(tec.add_ta(price, amount))\n",
    "    #list.extend(inds)\n",
    "    #print(len(inds))\n",
    "    #return np.array((np.array(list), inds), dtype=object)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data_set, prefix = \"\", base_dir = \"data/\"):\n",
    "    trainX = data_set[0]\n",
    "    trainY = data_set[1]\n",
    "    valX = data_set[2]\n",
    "    valY = data_set[3]\n",
    "    final_path = path + base_dir\n",
    "    train_path = \"{}{}trainX.npy\".format(final_path, prefix)\n",
    "    np.save(train_path, trainX)\n",
    "    np.save(\"{}{}trainY.npy\".format(final_path, prefix), trainY)\n",
    "    np.save(\"{}{}valX.npy\".format(final_path, prefix), valX)\n",
    "    np.save(\"{}{}valY.npy\".format(final_path, prefix), valY)\n",
    "    print(\"Saving {} with {}\".format(train_path, trainX.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 687284,
     "status": "ok",
     "timestamp": 1568068979529,
     "user": {
      "displayName": "Samir Moreira Antônio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCsh3ldsSLN0VnFRYp341EzO_UyuRNKmLncUbMA3Q=s64",
      "userId": "14581632111443153742"
     },
     "user_tz": -60
    },
    "id": "eO4im0aG2zql",
    "outputId": "e3d3b69a-c7ce-4779-c6e3-673b4bd7ba9a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"./\" \n",
    "\n",
    "windows = 30\n",
    "\n",
    "import data_util\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "def load_dataset(dir):\n",
    "    load_datasets([dir])\n",
    "\n",
    "def load_datasets(dirs, base_dir = \"data/\"):\n",
    "    print(dirs)\n",
    "    sets = []  \n",
    "    for raw_dir in dirs:\n",
    "        full_data = base_dir + raw_dir + \"/\"\n",
    "        data_gen = DataGenerator(random = False, base_dir = full_data)\n",
    "        data_gen.rewind()\n",
    "        full = data_gen.steps\n",
    "        tec = TecAn(windows = 20, windows_limit = 50)\n",
    "        print(\"Processing {}\".format(raw_dir))\n",
    "        #print(\"Recovering TECs\")\n",
    "        #result = get_tecs(full_data)\n",
    "        #print(\"TECs recovered {}\".format((result[-1].size)))\n",
    "        parsed = lambda list, price, amount, index: add_tacs_realtime(list, price, amount, tec)\n",
    "        #parsed = lambda list, price, amount, index: add_tacs(list, index, result)\n",
    "        print(\"Loading {} states\".format(full))\n",
    "        final_data = data_util.get_sets(data_gen,\n",
    "                                        full, \n",
    "                                        val_percentage = 0.006, \n",
    "                                        path = full_data, \n",
    "                                        use_cache=False,\n",
    "                                        on_state_parsed = parsed\n",
    "                                       )\n",
    "        count = len(final_data[0]) + len(final_data[-1])\n",
    "        print(\"Total to be added {}\".format(count))\n",
    "        save(final_data, raw_dir)\n",
    "        sets.append(final_data)\n",
    "    return sets\n",
    "\n",
    "def conc_sets(sets):\n",
    "    trainX = sets[0][0]\n",
    "    trainY = sets[0][1]\n",
    "    valX = sets[0][2]\n",
    "    valY = sets[0][3]\n",
    "    for i in range(1,  len(sets)):\n",
    "        data_set = sets[i]\n",
    "        trainX = np.append(data_set[0], trainX, axis = 0)\n",
    "        trainY = np.append(data_set[1], trainY, axis = 0)\n",
    "        valX = np.append(data_set[2], valX, axis = 0)\n",
    "        valY = np.append(data_set[3], valY, axis = 0)\n",
    "    return trainX, trainY, valX, valY\n",
    "\n",
    "\n",
    "#btcusd = load_datasets([\"btcusd\"])\n",
    "#btcusd17 = load_datasets([\"btcusd17\"])\n",
    "#btcusdAug19 = load_datasets([\"btcusdAug19\"])\n",
    "#daiusd = load_datasets([\"daiusd\", \"ethusd\"])\n",
    "#sets = load_datasets([\"data/btceur\", \"data/btcusd\", \"data/daiusd\", \"data/ethusd\", \"data/ltcusd\", \"data/omgusd\"])\n",
    "#save(conc_sets(daiusd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['btceur', 'btcusd', 'daiusd', 'ethusd', 'ltcusd', 'omgusd']\n",
      "Processing btceur\n",
      "Loading 656864 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf92697e6c945b1b79a3ea0ff82ff21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/652922 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f7c27d09644d50aed6740c62b3722b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (652922, 6) (652922, 2) (3941, 6) (3941, 2)\n",
      "Total to be added 656863\n",
      "Saving ./data/btceurtrainX.npy with (652922, 6)\n",
      "Processing btcusd\n",
      "Loading 388203 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d5621177a8429a8677dc62270bdcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/385873 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0f8dfdb8f04253bb31c5d6e10e80b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (385873, 6) (385873, 2) (2329, 6) (2329, 2)\n",
      "Total to be added 388202\n",
      "Saving ./data/btcusdtrainX.npy with (385873, 6)\n",
      "Processing daiusd\n",
      "Loading 53159 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be599b8c26cb4e55a29f10977f488c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be8e90a725c486e907f8b261ee3ea05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/318 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (52840, 6) (52840, 2) (318, 6) (318, 2)\n",
      "Total to be added 53158\n",
      "Saving ./data/daiusdtrainX.npy with (52840, 6)\n",
      "Processing ethusd\n",
      "Loading 639640 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21064194b1a4cb197df435bd9779c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/635802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b724aa41d0f409ca16d8fe19c687590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (635802, 6) (635802, 2) (3837, 6) (3837, 2)\n",
      "Total to be added 639639\n",
      "Saving ./data/ethusdtrainX.npy with (635802, 6)\n",
      "Processing ltcusd\n",
      "Loading 543246 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d73c7a1b0b4859ba7012aa5ae87832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016df3096ce74b8a9701e542bf35a55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (539986, 6) (539986, 2) (3259, 6) (3259, 2)\n",
      "Total to be added 543245\n",
      "Saving ./data/ltcusdtrainX.npy with (539986, 6)\n",
      "Processing omgusd\n",
      "Loading 213410 states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94523e9bea0f4aaa9767aaff2cfefbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/212129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f595260d05a408cb917386c59a80622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: (212129, 6) (212129, 2) (1280, 6) (1280, 2)\n",
      "Total to be added 213409\n",
      "Saving ./data/omgusdtrainX.npy with (212129, 6)\n",
      "Saving ./data/trainX.npy with (2479552, 6)\n"
     ]
    }
   ],
   "source": [
    "dirs = [\"btceur\", \"btcusd\", \"daiusd\", \"ethusd\", \"ltcusd\", \"omgusd\"]\n",
    "\n",
    "sets = load_datasets(dirs)\n",
    "save(conc_sets(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ethusd/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a5fcc5d182e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mraw_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ethusd/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mstateUtil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateUtil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/YaStockRnn/data_generator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, random, first_index, base_dir)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"stock_data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ethusd/'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from state_util import StateUtil\n",
    "from tec_an import TecAn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "raw_dir = \"ethusd/\"\n",
    "data_gen = DataGenerator(random=False, first_index=0, base_dir = raw_dir)\n",
    "stateUtil = StateUtil(data_gen, future = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = data_gen.next()\n",
    "print(state['timestamp'])\n",
    "state = data_gen.next()\n",
    "print(state['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = data_gen.next()\n",
    "print(state['timestamp'])\n",
    "x, y, raw_state, furure_state = stateUtil.get_state(state, data_gen.index)\n",
    "\n",
    "current = int(raw_state['timestamp'])\n",
    "microcurrent = int(raw_state['microtimestamp'])\n",
    "\n",
    "future = int(furure_state['timestamp'])\n",
    "microfuture = int(furure_state['microtimestamp'])\n",
    "print(\"{} - {} \".format(current, microcurrent))\n",
    "print(\"{} - {} \".format(future, microfuture))\n",
    "print(\"Diff: {}\".format(future - current))\n",
    "print(\"Y: {}\".format(y))\n",
    "\n",
    "ask = float(raw_state[stateUtil.ASKS_KEY][0][0]) \n",
    "print(\"Ask: {}\".format(ask))\n",
    "future_bid = float(furure_state[stateUtil.BIDS_KEY][0][0])\n",
    "print(\"Bid: {}\".format(future_bid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateUtil.onehot_encoded(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/\"\n",
    "\n",
    "trainX, trainY, positiveX, positiveY, negativeX, negativeY = load_data(\"ethusd\", \"train\", path, balanced = True)\n",
    "\n",
    "print(\"Loaded: {} {} \".format(trainX.shape, trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gen(trainX, trainY, shuffle=False, time_steps = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_y(list):\n",
    "    empty = np.array([[0, 0]])\n",
    "    list = np.concatenate((empty, list), axis=0)\n",
    "    list = np.delete(list , -1, 0)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_y(trainY).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def foo(bar, result, index):\n",
    "    #print(\"hello {}\".format(bar))\n",
    "    if (index == 5):\n",
    "        time.sleep(2.4)\n",
    "    result[index] = \"foo {}\".format(index)\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "threads = [None] * 10\n",
    "results = [None] * 10\n",
    "\n",
    "for i in range(len(threads)):\n",
    "    threads[i] = Thread(target=foo, args=('world!', results, i))\n",
    "    threads[i].start()\n",
    "\n",
    "# do some other stuff\n",
    "\n",
    "for i in range(len(threads)):\n",
    "    threads[i].join()\n",
    "\n",
    "print(\" \".join(results) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [None] * 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rx\n",
    "from rx import operators as ops\n",
    "from rx import of, operators as op\n",
    "\n",
    "test = of(1,2,3,4,5,6)\n",
    "test1 = of(4,8,12,16,20)\n",
    "test2 = of(5,10,15,20,25)\n",
    "sub1 = test.pipe(\n",
    "    op.zip(test1, test2)\n",
    ")\n",
    "\n",
    "test = sub1.run()\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rx\n",
    "from rx import operators as ops\n",
    "from rx import of, operators as op\n",
    "\n",
    "test = of(1,2,3,4,5,6)\n",
    "test1 = of(4,8,12,16,20)\n",
    "test2 = of(5,10,15,20,25)\n",
    "\n",
    "arrys = [test, test1, test2]\n",
    "\n",
    "rxTest = of(arrys)\n",
    "\n",
    "test = rx.zip(rxTest).run()\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "enviroment",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
