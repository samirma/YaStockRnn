{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706264fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from tec_an import *\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "from sklearn_model_hyper import *\n",
    "from joblib import dump, load\n",
    "from data_generator import *\n",
    "from data_agent import *\n",
    "from stock_agent import *\n",
    "from backtest import *\n",
    "from bitstamp import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import scikitplot as skplt\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import random\n",
    "from catboost import CatBoost\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997362d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_start_list = [1622502000, 1590966000, 1559343600, 1580515200, 1612137600]\n",
    "train_start_list = [1622502000, 1590966000, 1559343600, 1527807600, 1517443200, 1548979200, 1580515200, 1612137600]\n",
    "#train_start_list = [1612137600]\n",
    "train_keys = [\"btcusd\", \"ethusd\", \"bchbtc\"]\n",
    "#train_keys = [\"bchbtc\"]\n",
    "val_start = 1626340500\n",
    "val_end = 1626369600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d708f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_disk = True\n",
    "\n",
    "# '2Min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c80e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_data(minutes, source_data_generator, load_from_disk, file_prefix = \"\"):\n",
    "    \n",
    "    online = OnLineDataProvider(\n",
    "                 source_data_generator = source_data_generator,\n",
    "                 minutes = minutes,\n",
    "                 train_keys = train_keys,\n",
    "                 train_limit = 1000,\n",
    "                 val_limit = 1000,\n",
    "                 val_keys = [\"btcusd\"],\n",
    "                 val_start = val_start,\n",
    "                 val_end = val_end,\n",
    "                 train_start_list = train_start_list\n",
    "    )\n",
    "\n",
    "    online_path = f'data/online{file_prefix}_{minutes}'\n",
    "    \n",
    "    if (load_from_disk):\n",
    "        online = load(online_path)    \n",
    "    else:\n",
    "        #online.load_train_cache()\n",
    "        online.load_cache()\n",
    "        online.sourceDataGenerator = None\n",
    "        dump(online, online_path)\n",
    "        \n",
    "    \n",
    "    return online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1553254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getModel():\n",
    "    param = {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 30, 'random_state': 42}\n",
    "    #param = {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 3, 'random_state': 42}\n",
    "    coModel = RandomForestClassifier(**param)\n",
    "    return coModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df13d546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1 µs, total: 11 µs\n",
      "Wall time: 13.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_classifiers():\n",
    "    clss = classifiers = [\n",
    "        #lambda : MLPClassifier(alpha=1,\n",
    "        #                       solver = 'lbfgs', \n",
    "        #                       max_iter=1000000, \n",
    "        #                       random_state = 42),\n",
    "        #lambda : MLPClassifier(alpha=1, max_iter=10000, random_state = 42),\n",
    "        \n",
    "        \n",
    "        lambda : make_pipeline( StandardScaler(),\n",
    "        MLPClassifier(\n",
    "            solver='lbfgs', alpha=1, random_state=1, max_iter=2000,\n",
    "            early_stopping=True)\n",
    "        ),\n",
    "        \n",
    "        lambda : xgb.XGBClassifier(random_state=1,\n",
    "                                   objective = \"binary:logistic\",\n",
    "                                   eval_metric='mlogloss',\n",
    "                                   learning_rate=0.01, \n",
    "                                   use_label_encoder = True),\n",
    "        \n",
    "        #lambda : GaussianNB(),\n",
    "        #lambda : QuadraticDiscriminantAnalysis(),\n",
    "        #lambda : AdaBoostClassifier(random_state = 42),\n",
    "        #lambda : CatBoostClassifier(logging_level = 'Silent'),\n",
    "        \n",
    "        \n",
    "        #lambda : LogisticRegression(),\n",
    "        #lambda : KNeighborsClassifier(3),\n",
    "        #lambda : GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "        \n",
    "        \n",
    "        #lambda : DecisionTreeClassifier(random_state = 42),\n",
    "        #lambda : RandomForestClassifier(max_depth=50, n_estimators=100, max_features=1),\n",
    "        \n",
    "        #lambda : SVC(gamma=2, C=1, random_state = 42),\n",
    "    ]\n",
    "    \n",
    "    def rand():\n",
    "        ##print(\"rand created\")\n",
    "        param = {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 30, 'random_state': 42}\n",
    "        return RandomForestClassifier(**param)\n",
    "    \n",
    "\n",
    "    #clss = []\n",
    "    clss.append(lambda : rand())\n",
    "    return clss\n",
    "\n",
    "\n",
    "estimators = [\n",
    "                #RFE(estimator=DecisionTreeClassifier(random_state=10), n_features_to_select=6),\n",
    "                lambda : RFE(estimator=RandomForestClassifier(random_state=10), n_features_to_select=10),\n",
    "                lambda : RFE(estimator=DecisionTreeClassifier(random_state=10), n_features_to_select=8),\n",
    "                lambda : RFECV(estimator=DecisionTreeClassifier(random_state=10)),\n",
    "                lambda : RFECV(estimator=RandomForestClassifier(random_state=10))\n",
    "                ]\n",
    "\n",
    "\n",
    "def get_all_models():\n",
    "    models = []\n",
    "    classifiers = get_classifiers()\n",
    "    for cls in classifiers:\n",
    "        models.append(cls())\n",
    "        #models.append(MockModel(cls()))\n",
    "        #models.append(MockCoPilotModel(cls(), getModel()))\n",
    "        \n",
    "        for est in estimators:\n",
    "            tmp = lambda : Pipeline(\n",
    "                steps=[\n",
    "                ('s',est()),\n",
    "                ('m',cls())\n",
    "            ])\n",
    "            models.append(tmp())\n",
    "            #models.append(MockModel(tmp()))\n",
    "            #models.append(MockCoPilotModel(tmp(), getModel()))\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64dde41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_models_factory = lambda : get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd02b269",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def test_models(provider, get_all_models_factory, steps = [1]):\n",
    "    \n",
    "    score_board_by_step = {}\n",
    "\n",
    "    for step in steps:\n",
    "        print(f\"Step {step}\")\n",
    "        models_list = get_all_models_factory()\n",
    "        model_result = []\n",
    "        for idx in tqdm(range(len(models_list))):\n",
    "            model_creator = models_list[idx]\n",
    "            model = model_creator\n",
    "            #print(f\"Trainning {model}\")\n",
    "            result = run_trial(model_creator, provider, step)\n",
    "\n",
    "            result['step'] = step\n",
    "\n",
    "            model_result.append(result)\n",
    "        \n",
    "        score_board_by_step[step] = model_result\n",
    "        \n",
    "    best_models = []\n",
    "\n",
    "    best_model = []\n",
    "\n",
    "    best_score = -1\n",
    "    \n",
    "    best_step = -1\n",
    "    \n",
    "    model_rank = []\n",
    "    \n",
    "    def myFunc(e):\n",
    "        return e['profit']\n",
    "\n",
    "    for step_idx in score_board_by_step:\n",
    "        step_board = score_board_by_step[step_idx]\n",
    "        for result in step_board:\n",
    "            if (result['profit'] > 0):\n",
    "                model_rank.append(result)\n",
    "            \n",
    "    model_rank.sort(key=myFunc, reverse = True)\n",
    "    \n",
    "    return model_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecc3cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps = [1, 5]\n",
    "\n",
    "windows = [5, 10, 20, 30, 40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3570e420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_windows(minutes, steps = steps):\n",
    "    results = []\n",
    "    for win in tqdm(windows):\n",
    "        tec = TecAn(windows = win, windows_limit = 100)\n",
    "        sourceDataGenerator = SourceDataGenerator(tec = tec)\n",
    "        online = get_online_data(minutes, sourceDataGenerator, load_from_disk, win)\n",
    "        result = test_models(\n",
    "            online, \n",
    "            get_all_models_factory,\n",
    "            steps = steps\n",
    "        )\n",
    "        for rank in result:\n",
    "            rank['window'] = win\n",
    "            rank['minutes'] = minutes\n",
    "            \n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60c00693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 15 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaf3643745d4b4faba06e14cafad6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3003e2e569634935a864d8a977b1164c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:53:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:53:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:53:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:56:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde9492ced73413087c7ebc55598ee61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:04:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:07:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55deb14c20e4178a0720772f69d9aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de6df40fa1543cc97badeea84d5e56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:29:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:29:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:29:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:29:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:32:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30376ddb4c4145a1b28ce0882e6eba3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:41:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:41:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:41:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:41:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:44:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c0cc1fda294865a23d7f289ae8f934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:53:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:54:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:54:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:54:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:56:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc5bc22a56b44b69c17117d458b00d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:06:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:06:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:06:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:09:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642f87a330944487bd11ae26e4396522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:18:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:18:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:18:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:19:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:21:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9f00aa3c26418895ea223641444c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:30:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:31:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:31:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:31:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:34:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c383b631dc2041f2995d6ada0869fafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:43:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:43:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:43:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:46:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Evaluating 5 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a75a60ce2ae48dabcbf59453559127b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2fd4bd68f54ff5b7f419533b1efeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:55:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:55:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:55:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:55:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:58:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188ae013d6d2470ca230d3c99085b1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:07:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:07:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:08:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:10:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f00985fd704c1f8ae26b159c3e482c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:19:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:19:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:19:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:19:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:22:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0d23ed71bb48a1ae2a61e20b8614f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:32:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:32:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:32:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:34:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3acf7bdf5a42e8bd7277e0983632fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:43:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:44:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:44:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:44:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:47:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2615fe7b7994c04a9eecab146483520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:56:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:56:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:56:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:56:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:59:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b9c298d4374b8f8f37245218a98709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:07:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:08:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:08:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:08:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:11:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b1a415281944769615011f59857cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:20:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:20:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:21:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:23:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e214708eef3459ba32df6dce5abdabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:32:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:32:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:33:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:33:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:36:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f788ed4c7743f398754fd82316091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:45:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:45:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:45:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:45:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:48:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Evaluating 3 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40137331f464d55b105be437a6bea5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59676e67fed1480085447954f1c2651f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:57:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:57:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:57:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:01:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be585078e7fb4e4c858aac1feaa3eec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:10:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:10:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:10:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:11:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:13:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef05ca2ad74e4431a6c33ec80ea7603a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:22:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:23:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:23:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:23:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:26:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5056d4d799044f0a5caafbce177b6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:35:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:35:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:35:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:36:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:38:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0904c937468c4f18a1b157119f0b9983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:47:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:48:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:48:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:48:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:51:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6142204079ed4f399581cb98bce5cc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:01:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:01:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:01:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:01:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:04:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5e0fcac6ec4f7686a14d5b09a57604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:13:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:13:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:13:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:14:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:17:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b01c24156564a4c83db53146a03f7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:26:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:27:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:27:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:29:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e291d8f3194f98af0f5b5bb92b8195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:38:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:39:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:39:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:39:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:42:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0423457f99784a98b4b96b876afc62c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:55:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Evaluating 1 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb5a38a6ea74fcd9c23f69a0ebb840e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d471a4d08bb45d2897b3e0da7bb2739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:04:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:04:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:04:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:07:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9169465c5fac459dabab1ad9df0779cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:18:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:18:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:18:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:21:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a32d4bbf5fb4d9fbd83168a27cecb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:30:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:31:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:31:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:31:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:35:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b1c99284794c888f3ab2a2528fe311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:45:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:46:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:46:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:46:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:49:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91801267c0ae41d890ad1eadf31b7ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:58:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:58:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:58:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:58:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:02:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efe41e46a904dbca5e532a144ff4a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:13:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:13:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:13:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:16:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cda2442daf4fb1a968071f924d4a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:26:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:26:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:26:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:30:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049ebb45691745b89721a668e2b3076e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:41:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:44:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb57c3be26e04c83bb45077157d77652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:54:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:54:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:54:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:58:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Step 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966094846dd849e4b7f5bf5931925d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:08:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:08:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:08:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:09:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:11:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "CPU times: user 11h 53min 49s, sys: 45min 38s, total: 12h 39min 28s\n",
      "Wall time: 8h 28min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "minutes = [15, 5, 3, 1]\n",
    "\n",
    "min_results = []\n",
    "\n",
    "for minu in minutes:\n",
    "    print(f\"Evaluating {minu} min\")\n",
    "    results = test_windows(minu, steps)\n",
    "    min_results.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02f7e97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/results']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9c2dddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes=15 Window=5 Step=1 | 104.68849807238843\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 102.4341663386477\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 102.42165922706481\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 101.89360913438114\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "              max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "              num_parallel_tree=1, random_state=1, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=True, validate_parameters=1, verbosity=None)\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 101.54906141074287\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 101.30572370010182\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=10 Step=1 | 104.07010049803651\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=20 Step=1 | 110.257327069269\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=20 Step=1 | 103.86445954200045\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=20 Step=1 | 101.12714647457791\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 108.95965211072469\n",
      "RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=30,\n",
      "                       random_state=42)\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 105.88279599087541\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 104.22767566484525\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 103.63290346368404\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 103.24176009534911\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 103.01908993357324\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "              max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "              num_parallel_tree=1, random_state=1, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=True, validate_parameters=1, verbosity=None)\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 102.67620007020379\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 101.98110909669072\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 101.29457091820967\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 101.12761903530297\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 110.57540259137214\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 104.22673584837084\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 103.90746614678706\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 103.43532307816722\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 103.34258091369581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 102.15028907102514\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 101.17250239487848\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "27 selected\n"
     ]
    }
   ],
   "source": [
    "best_results = []\n",
    "for results in min_results:\n",
    "    for r in results:\n",
    "        if (len(r) > 0):\n",
    "            for win_result in r:\n",
    "                profit = win_result['profit']\n",
    "                model = win_result['model']\n",
    "                window = win_result['window']\n",
    "                minutes = win_result['minutes']\n",
    "                step = win_result['step']\n",
    "                profit = win_result['profit']\n",
    "                if (profit > 101 and minutes == 15):\n",
    "                    print(f\"Minutes={minutes} Window={window} Step={step} | {profit}\")\n",
    "                    print(f\"{win_result['model']}\")\n",
    "                    print(f\"\")\n",
    "                    best_results.append(win_result)\n",
    "        else:\n",
    "            print(\"Not found\")\n",
    "\n",
    "print(f\"{len(best_results)} selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b93b5fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/results']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = f'model/results'\n",
    "dump(best_results, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5eb0e35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes=15 Window=20 Step=1 | 101.12714647457791\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 101.12761903530297\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 101.17250239487848\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 101.29457091820967\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 101.30572370010182\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 101.54906141074287\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 101.89360913438114\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "              max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "              num_parallel_tree=1, random_state=1, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=True, validate_parameters=1, verbosity=None)\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 101.98110909669072\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 102.15028907102514\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 102.42165922706481\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 102.4341663386477\n",
      "Pipeline(steps=[('s', RFECV(estimator=RandomForestClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 102.67620007020379\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 103.01908993357324\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "              max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "              num_parallel_tree=1, random_state=1, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=True, validate_parameters=1, verbosity=None)\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 103.24176009534911\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=100,\n",
      "                                        n_estimators=30, random_state=42))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minutes=15 Window=40 Step=1 | 103.34258091369581\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 103.43532307816722\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 103.63290346368404\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=20 Step=1 | 103.86445954200045\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 103.90746614678706\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=10 Step=1 | 104.07010049803651\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 104.22673584837084\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 104.22767566484525\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                 ('mlpclassifier',\n",
      "                                  MLPClassifier(alpha=1, early_stopping=True,\n",
      "                                                max_iter=2000, random_state=1,\n",
      "                                                solver='lbfgs'))]))])\n",
      "\n",
      "Minutes=15 Window=5 Step=1 | 104.68849807238843\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=10),\n",
      "                     n_features_to_select=10)),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 105.88279599087541\n",
      "Pipeline(steps=[('s',\n",
      "                 RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
      "                     n_features_to_select=8)),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n",
      "Minutes=15 Window=30 Step=1 | 108.95965211072469\n",
      "RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=30,\n",
      "                       random_state=42)\n",
      "\n",
      "Minutes=15 Window=20 Step=1 | 110.257327069269\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=1, early_stopping=True, max_iter=2000,\n",
      "                               random_state=1, solver='lbfgs'))])\n",
      "\n",
      "Minutes=15 Window=40 Step=1 | 110.57540259137214\n",
      "Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
      "                ('m',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='mlogloss',\n",
      "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               use_label_encoder=True, validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def myFunc(e):\n",
    "    return e['profit']\n",
    "\n",
    "best_results.sort(key=myFunc, reverse = False)\n",
    "\n",
    "for best in best_results:\n",
    "    model = best['model']\n",
    "    window = best['window']\n",
    "    minutes = best['minutes']\n",
    "    step = best['step']\n",
    "    profit = best['profit']\n",
    "    print(f\"Minutes={minutes} Window={window} Step={step} | {profit}\")\n",
    "    print(f\"{model}\")\n",
    "    model_path = f'model/result_{window}_{minutes}_{step}'\n",
    "    dump(best, model_path)\n",
    "    print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51c9b2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'profit': 110.57540259137214,\n",
       " 'model': Pipeline(steps=[('s', RFECV(estimator=DecisionTreeClassifier(random_state=10))),\n",
       "                 ('m',\n",
       "                  XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                colsample_bylevel=1, colsample_bynode=1,\n",
       "                                colsample_bytree=1, eval_metric='mlogloss',\n",
       "                                gamma=0, gpu_id=-1, importance_type='gain',\n",
       "                                interaction_constraints='', learning_rate=0.01,\n",
       "                                max_delta_step=0, max_depth=6,\n",
       "                                min_child_weight=1, missing=nan,\n",
       "                                monotone_constraints='()', n_estimators=100,\n",
       "                                n_jobs=0, num_parallel_tree=1, random_state=1,\n",
       "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                                subsample=1, tree_method='exact',\n",
       "                                use_label_encoder=True, validate_parameters=1,\n",
       "                                verbosity=None))]),\n",
       " 'models_profit': {'btcusd': 10.5754},\n",
       " 'models_score': {'btcusd': (0.545816733067729,\n",
       "   0.5513078470824949,\n",
       "   0.5485485485485485,\n",
       "   0.5485485485485485)},\n",
       " 'models_profit_metric': {'btcusd': 0.10116650372221256},\n",
       " 'step': 1,\n",
       " 'window': 40,\n",
       " 'minutes': 15}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def myFunc(e):\n",
    "    return e['profit']\n",
    "\n",
    "best_results.sort(key=myFunc, reverse = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3b377b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'profit': 105.88279599087541,\n",
       " 'model': Pipeline(steps=[('s',\n",
       "                  RFE(estimator=DecisionTreeClassifier(random_state=10),\n",
       "                      n_features_to_select=8)),\n",
       "                 ('m',\n",
       "                  XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                colsample_bylevel=1, colsample_bynode=1,\n",
       "                                colsample_bytree=1, eval_metric='mlogloss',\n",
       "                                gamma=0, gpu_id=-1, importance_type='gain',\n",
       "                                interaction_constraints='', learning_rate=0.01,\n",
       "                                max_delta_step=0, max_depth=6,\n",
       "                                min_child_weight=1, missing=nan,\n",
       "                                monotone_constraints='()', n_estimators=100,\n",
       "                                n_jobs=0, num_parallel_tree=1, random_state=1,\n",
       "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                                subsample=1, tree_method='exact',\n",
       "                                use_label_encoder=True, validate_parameters=1,\n",
       "                                verbosity=None))]),\n",
       " 'models_profit': {'btcusd': 5.8828},\n",
       " 'models_score': {'btcusd': (0.5286624203821656,\n",
       "   0.5010060362173038,\n",
       "   0.5144628099173554,\n",
       "   0.5295295295295295)},\n",
       " 'models_profit_metric': {'btcusd': 0.05627610379721164},\n",
       " 'step': 1,\n",
       " 'window': 30,\n",
       " 'minutes': 15}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e948f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec402a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88485088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba9fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40921c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e654e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b413a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_online(minutes, window, val_end = 1626388860, currency = \"btcusd\"):\n",
    "    tec = TecAn(windows = window, windows_limit = 100)\n",
    "    source_data_generator = SourceDataGenerator(tec = tec)\n",
    "\n",
    "\n",
    "    online = OnLineDataProvider(\n",
    "                 source_data_generator = source_data_generator,\n",
    "                 minutes = minutes,\n",
    "                 train_keys = [\"btcusd\"],\n",
    "                 train_limit = 40,\n",
    "                 val_limit = 999,\n",
    "                 val_keys = [currency],\n",
    "                 #val_start = val_start,\n",
    "                 val_end = val_end,\n",
    "                 train_start_list = [1626386301]\n",
    "    )\n",
    "\n",
    "    online.load_cache()\n",
    "    return online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35dd65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_model(model, x, closed_prices, back):\n",
    "    \n",
    "    for idx in range(len(x)):\n",
    "        xx = [x[idx]]\n",
    "        yy = model.predict(xx)[0]\n",
    "        price = closed_prices[idx]\n",
    "        #print(f'{idx} {yy} {price}')\n",
    "        back.on_state(0, price)\n",
    "        if(yy == 1):\n",
    "            back.request_buy(price)\n",
    "        else:\n",
    "            back.request_sell(price)\n",
    "    \n",
    "    print(f\"Closing backtest_model {price} {back.current}\")\n",
    "    back.sell(price)\n",
    "    print(f\"Closed backtest_model {back.current}\")\n",
    "    #back.request_sell(31744.62)\n",
    "    \n",
    "    return back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb2346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be8578b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, set_key, provider, step, verbose = True):\n",
    "    valX, valY = provider.load_val_data(set_key)\n",
    "\n",
    "    x, y, closed_prices = get_sequencial_data(valX, valY, step)\n",
    "    \n",
    "    #print(len(x))\n",
    "\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    recall = recall_score(y, preds)\n",
    "    precision = precision_score(y, preds)\n",
    "    f1 = f1_score(y, preds)\n",
    "    accuracy = accuracy_score(y, preds)\n",
    "\n",
    "    back = BackTest(value = 100, \n",
    "                    verbose = verbose, \n",
    "                    sell_on_profit = True,\n",
    "                    pending_sell_steps = step)\n",
    "    back = backtest_model(model, x, closed_prices, back)\n",
    "    return back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "34ec71c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp = int(datetime.timestamp((datetime.now())))\n",
    "\n",
    "\n",
    "#timestamp = 1610959352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "62c7bc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes=15 Window=40 Step=1 | 110.57540259137214\n",
      "Not found 15-40\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:45:00 to 2021-07-16 08:30:00 31673.68\n",
      "Resample 15Min - TecAn ( windows 40, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59cd4c19dd149cd9c349e773e0e2bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-08 01:30:00 to 2021-07-18 11:00:00 31755.48\n",
      "Resample 15Min - TecAn ( windows 40, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ef372554324e9e8dcd4c9741801395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31755.48 11.17842080668656\n",
      "Closed backtest_model 111.17842080668656\n",
      "Minutes=15 Window=20 Step=1 | 110.257327069269\n",
      "Not found 15-20\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:45:00 to 2021-07-16 08:30:00 31673.68\n",
      "Resample 15Min - TecAn ( windows 20, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199e00802eda4af8a11b7ef2e9b67fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-08 01:30:00 to 2021-07-18 11:00:00 31755.48\n",
      "Resample 15Min - TecAn ( windows 20, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b056ea1eeb4945a8f206c7469846cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31755.48 9.031406413228353\n",
      "Closed backtest_model 108.99278233692455\n",
      "Minutes=15 Window=30 Step=1 | 108.95965211072469\n",
      "Not found 15-30\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:45:00 to 2021-07-16 08:30:00 31673.68\n",
      "Resample 15Min - TecAn ( windows 30, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1647e54f618c47888f256cab69c522d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-08 01:30:00 to 2021-07-18 11:00:00 31755.48\n",
      "Resample 15Min - TecAn ( windows 30, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2064246a30014b5a84bfb189ae24819a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31755.48 101.98657480066932\n",
      "Closed backtest_model 101.98657480066932\n",
      "Minutes=15 Window=30 Step=1 | 105.88279599087541\n",
      "Closing backtest_model 31755.48 104.84877635326086\n",
      "Closed backtest_model 104.84877635326086\n",
      "Minutes=3 Window=5 Step=1 | 105.18576222785777\n",
      "Not found 3-5\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:57:00 to 2021-07-16 00:54:00 31644.19\n",
      "Resample 3Min - TecAn ( windows 5, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd7ba807ea440cabb15ff0f4a06b5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-16 09:09:00 to 2021-07-18 11:03:00 31700.00\n",
      "Resample 3Min - TecAn ( windows 5, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b6df1da80e4c64a0f36360e1f4212a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31700.0 2.1153947178964643\n",
      "Closed backtest_model 101.93961591577452\n",
      "Minutes=15 Window=5 Step=1 | 104.68849807238843\n",
      "Not found 15-5\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:45:00 to 2021-07-16 08:30:00 31673.68\n",
      "Resample 15Min - TecAn ( windows 5, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a87a25e6ea49d98225b0c0c37e1a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-08 01:30:00 to 2021-07-18 11:00:00 31755.48\n",
      "Resample 15Min - TecAn ( windows 5, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f5b83f0f484af28419d3f338c7048a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31755.48 1.7900061302500632\n",
      "Closed backtest_model 101.88806954332966\n",
      "Minutes=15 Window=30 Step=1 | 104.22767566484525\n",
      "Closing backtest_model 31755.48 2.641507340998217\n",
      "Closed backtest_model 101.51140921982487\n",
      "Minutes=15 Window=40 Step=1 | 104.22673584837084\n",
      "Closing backtest_model 31755.48 4.6832606243227985\n",
      "Closed backtest_model 104.69324414993085\n",
      "Minutes=15 Window=10 Step=1 | 104.07010049803651\n",
      "Not found 15-10\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:45:00 to 2021-07-16 08:30:00 31673.68\n",
      "Resample 15Min - TecAn ( windows 10, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bcbe403dca4e098f3fe95c53bc528b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 900, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-08 01:30:00 to 2021-07-18 11:00:00 31755.48\n",
      "Resample 15Min - TecAn ( windows 10, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154a5f1600f346bebbb5c6a5f83cd995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31755.48 0.39979754223121233\n",
      "Closed backtest_model 100.39979754223121\n",
      "Minutes=15 Window=40 Step=1 | 103.90746614678706\n",
      "Closing backtest_model 31755.48 6.948435857036941\n",
      "Closed backtest_model 106.28886666045754\n",
      "Minutes=15 Window=20 Step=1 | 103.86445954200045\n",
      "Closing backtest_model 31755.48 1.0988315646273463\n",
      "Closed backtest_model 100.43926236804795\n",
      "Minutes=15 Window=30 Step=1 | 103.63290346368404\n",
      "Closing backtest_model 31755.48 1.8169107645956615\n",
      "Closed backtest_model 101.81691076459566\n",
      "Minutes=3 Window=5 Step=1 | 103.48093736544496\n",
      "Closing backtest_model 31700.0 1.1020118971911472\n",
      "Closed backtest_model 101.10201189719115\n",
      "Minutes=15 Window=40 Step=1 | 103.43532307816722\n",
      "Closing backtest_model 31755.48 0.17221585403846973\n",
      "Closed backtest_model 100.19190137082107\n",
      "Minutes=3 Window=10 Step=1 | 103.3784188394426\n",
      "Not found 3-10\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:57:00 to 2021-07-16 00:54:00 31644.19\n",
      "Resample 3Min - TecAn ( windows 10, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9ba15a0ae141c1aec2190059e52a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-16 09:09:00 to 2021-07-18 11:03:00 31700.00\n",
      "Resample 3Min - TecAn ( windows 10, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94076f8acd8d423d876eec10e12bdb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31700.0 2.9585372842911966\n",
      "Closed backtest_model 102.78275848216926\n",
      "Minutes=3 Window=10 Step=1 | 103.3784188394426\n",
      "Closing backtest_model 31700.0 2.9585372842911966\n",
      "Closed backtest_model 102.78275848216926\n",
      "Minutes=15 Window=40 Step=1 | 103.34258091369581\n",
      "Closing backtest_model 31755.48 3.410240619497827\n",
      "Closed backtest_model 103.37161654319402\n",
      "Minutes=15 Window=30 Step=1 | 103.24176009534911\n",
      "Closing backtest_model 31755.48 3.5838735061023073\n",
      "Closed backtest_model 103.58387350610231\n",
      "Minutes=3 Window=30 Step=1 | 103.12075438352257\n",
      "Not found 3-30\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:57:00 to 2021-07-16 00:54:00 31644.19\n",
      "Resample 3Min - TecAn ( windows 30, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8278df2be9e942b583013885e64e787e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-16 09:09:00 to 2021-07-18 11:03:00 31700.00\n",
      "Resample 3Min - TecAn ( windows 30, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10206e0c9bad4c5fbeccc5c47bafaaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31700.0 100.42888680926772\n",
      "Closed backtest_model 100.42888680926772\n",
      "Minutes=15 Window=30 Step=1 | 103.01908993357324\n",
      "Minutes=3 Window=30 Step=1 | 102.78940555421738\n",
      "Closing backtest_model 31700.0 2.6824296975879776\n",
      "Closed backtest_model 102.68242969758798\n",
      "Minutes=3 Window=10 Step=1 | 102.68116318113009\n",
      "Closing backtest_model 31700.0 4.253374384887977\n",
      "Closed backtest_model 104.07759558276604\n",
      "Minutes=15 Window=30 Step=1 | 102.67620007020379\n",
      "Closing backtest_model 31755.48 -1.7376344436191005\n",
      "Closed backtest_model 98.2820510731635\n",
      "Minutes=3 Window=40 Step=1 | 102.55417400400806\n",
      "Not found 3-40\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:57:00 to 2021-07-16 00:54:00 31644.19\n",
      "Resample 3Min - TecAn ( windows 40, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705bdfb8b4024ea7849124940590c578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-16 09:09:00 to 2021-07-18 11:03:00 31700.00\n",
      "Resample 3Min - TecAn ( windows 40, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e01a2e25ab14fed93436524d2551c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31700.0 -1.1500472282129977\n",
      "Closed backtest_model 98.849952771787\n",
      "Minutes=3 Window=5 Step=1 | 102.4708642796859\n",
      "Minutes=15 Window=5 Step=1 | 102.4341663386477\n",
      "Closing backtest_model 31755.48 4.834182340639657\n",
      "Closed backtest_model 104.79555826433585\n",
      "Minutes=5 Window=40 Step=1 | 102.4319405570016\n",
      "Not found 5-40\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 300, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:55:00 to 2021-07-16 02:10:00 31744.78\n",
      "Resample 5Min - TecAn ( windows 40, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d448b5ce87e34834921e82a37c6b18eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 300, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-14 23:50:00 to 2021-07-18 11:00:00 31755.48\n",
      "Resample 5Min - TecAn ( windows 40, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9778e4b4213d4dcfa00028353a26f320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31755.48 103.54280879045122\n",
      "Closed backtest_model 103.54280879045122\n",
      "Minutes=15 Window=5 Step=1 | 102.42165922706481\n",
      "Closing backtest_model 31755.48 100.42258897800441\n",
      "Closed backtest_model 100.42258897800441\n",
      "Minutes=3 Window=40 Step=1 | 102.25686511947032\n",
      "Closing backtest_model 31700.0 2.6997173068872087\n",
      "Closed backtest_model 102.44899105665436\n",
      "Minutes=15 Window=40 Step=1 | 102.15028907102514\n",
      "Closing backtest_model 31755.48 2.652289377782793\n",
      "Closed backtest_model 101.9927201812034\n",
      "Minutes=3 Window=5 Step=1 | 102.05902251206264\n",
      "Closing backtest_model 31700.0 3.8166238976948677\n",
      "Closed backtest_model 103.56589764746202\n",
      "Minutes=3 Window=5 Step=1 | 101.98446936648803\n",
      "Closing backtest_model 31700.0 1.6789662382072095\n",
      "Closed backtest_model 101.50425623539824\n",
      "Minutes=15 Window=30 Step=1 | 101.98110909669072\n",
      "Closing backtest_model 31755.48 99.43848269855486\n",
      "Closed backtest_model 99.43848269855486\n",
      "Minutes=3 Window=10 Step=1 | 101.96896663040587\n",
      "Closing backtest_model 31700.0 3.912725512647299\n",
      "Closed backtest_model 103.9127255126473\n",
      "Minutes=3 Window=10 Step=1 | 101.95738977474062\n",
      "Closing backtest_model 31700.0 102.32574410378834\n",
      "Closed backtest_model 102.32574410378834\n",
      "Minutes=3 Window=10 Step=1 | 101.95738977474062\n",
      "Closing backtest_model 31700.0 102.32574410378834\n",
      "Closed backtest_model 102.32574410378834\n",
      "Minutes=15 Window=5 Step=1 | 101.89360913438114\n",
      "Minutes=3 Window=5 Step=1 | 101.71814050233517\n",
      "Closing backtest_model 31700.0 2.645168566385294\n",
      "Closed backtest_model 102.46938976426335\n",
      "Minutes=3 Window=10 Step=1 | 101.71051267886955\n",
      "Closing backtest_model 31700.0 -0.4645447795204518\n",
      "Closed backtest_model 99.2847289702467\n",
      "Minutes=3 Window=10 Step=1 | 101.71051267886955\n",
      "Closing backtest_model 31700.0 -0.4645447795204518\n",
      "Closed backtest_model 99.2847289702467\n",
      "Minutes=15 Window=5 Step=1 | 101.54906141074287\n",
      "Closing backtest_model 31755.48 -1.4759688078146382\n",
      "Closed backtest_model 98.48540711588156\n",
      "Minutes=3 Window=10 Step=1 | 101.50194201650156\n",
      "Closing backtest_model 31700.0 2.18905240502761\n",
      "Closed backtest_model 102.01327360290567\n",
      "Minutes=1 Window=20 Step=1 | 101.39256903264423\n",
      "Not found 1-20\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 60, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:58:00 to 2021-07-15 23:37:00 31800.00\n",
      "Resample 1Min - TecAn ( windows 20, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0a16781d9942cc9b1b2f14bd1139b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 60, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-17 18:25:00 to 2021-07-18 11:03:00 31700.00\n",
      "Resample 1Min - TecAn ( windows 20, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff10300aa53d4796b9b111a7dfa70ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31700.0 100.17680230592043\n",
      "Closed backtest_model 100.17680230592043\n",
      "Minutes=3 Window=30 Step=1 | 101.38733831131175\n",
      "Closing backtest_model 31700.0 98.58873973040787\n",
      "Closed backtest_model 98.58873973040787\n",
      "Minutes=3 Window=20 Step=1 | 101.3389369755817\n",
      "Not found 3-20\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:57:00 to 2021-07-16 00:54:00 31644.19\n",
      "Resample 3Min - TecAn ( windows 20, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80248b46fc9344cb9bd2dd1d025cb9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 180, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-16 09:09:00 to 2021-07-18 11:03:00 31700.00\n",
      "Resample 3Min - TecAn ( windows 20, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb1ea4d62de466191299e0c318cb79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31700.0 2.084652937031109\n",
      "Closed backtest_model 101.71376236279345\n",
      "Minutes=15 Window=5 Step=1 | 101.30572370010182\n",
      "Closing backtest_model 31755.48 2.787619914474888\n",
      "Closed backtest_model 101.80028324158683\n",
      "Minutes=15 Window=30 Step=1 | 101.29457091820967\n",
      "Closing backtest_model 31755.48 -4.093221932820285\n",
      "Closed backtest_model 95.90677806717972\n",
      "Minutes=3 Window=5 Step=1 | 101.28497898436324\n",
      "Closing backtest_model 31700.0 -0.23596915921035588\n",
      "Closed backtest_model 99.5882520386677\n",
      "Minutes=3 Window=10 Step=1 | 101.24857800526418\n",
      "Closing backtest_model 31700.0 2.0334895850382964\n",
      "Closed backtest_model 101.78276333480545\n",
      "Minutes=15 Window=40 Step=1 | 101.17250239487848\n",
      "Closing backtest_model 31755.48 5.384296754892034\n",
      "Closed backtest_model 104.39696008200397\n",
      "Minutes=5 Window=40 Step=1 | 101.15555838673109\n",
      "Closing backtest_model 31755.48 -4.7518145388341395\n",
      "Closed backtest_model 95.14522275895645\n",
      "Minutes=15 Window=30 Step=1 | 101.12761903530297\n",
      "Closing backtest_model 31755.48 4.398378085265492\n",
      "Closed backtest_model 104.39837808526549\n",
      "Minutes=15 Window=20 Step=1 | 101.12714647457791\n",
      "Closing backtest_model 31755.48 8.79634664195612\n",
      "Closed backtest_model 107.80900996906806\n",
      "Minutes=1 Window=5 Step=1 | 101.12246967873749\n",
      "Not found 1-5\n",
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 60, 'limit': 40, 'start': 1626386301}\n",
      "Downloaded from 2021-07-15 22:58:00 to 2021-07-15 23:37:00 31800.00\n",
      "Resample 1Min - TecAn ( windows 5, windows_limit 100 )\n",
      "Processing 39 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3922cb2001da4deb92cbc72bb1ca0648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bitstamp.net/api/v2/ohlc/btcusd/ -> {'currency_pair': 'btcusd', 'step': 60, 'limit': 999, 'start': 1623435037, 'end': 1626602605}\n",
      "Downloaded from 2021-07-17 18:25:00 to 2021-07-18 11:03:00 31700.00\n",
      "Resample 1Min - TecAn ( windows 5, windows_limit 100 )\n",
      "Processing 998 of btcusd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54fc7944e53423f88dc84cd8edd987c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing backtest_model 31700.0 1.4170784939159091\n",
      "Closed backtest_model 101.29498798940644\n",
      "Minutes=3 Window=10 Step=1 | 101.03981296091241\n",
      "Minutes=3 Window=10 Step=1 | 101.03981296091241\n",
      "Closing backtest_model 31700.0 3.8660778065078034\n",
      "Closed backtest_model 103.69029900438586\n"
     ]
    }
   ],
   "source": [
    "backs = []\n",
    "fails = []\n",
    "\n",
    "currency = \"btcusd\"\n",
    "\n",
    "online_cache = {}\n",
    "\n",
    "for best in best_results:\n",
    "    model = best['model']\n",
    "    window = best['window']\n",
    "    minutes = best['minutes']\n",
    "    step = best['step']\n",
    "    profit = best['profit']\n",
    "    print(f\"Minutes={minutes} Window={window} Step={step} | {profit}\")\n",
    "    cache_key = f\"{minutes}-{window}\"\n",
    "    try:\n",
    "        online = online_cache[cache_key]\n",
    "    except :\n",
    "        print(f\"Not found {cache_key}\")\n",
    "        online = load_online(minutes = minutes, window = window, val_end = timestamp, currency = currency)\n",
    "        online_cache[cache_key] = online\n",
    "        \n",
    "    try:\n",
    "        back = test_model(model, currency, online, step, False)\n",
    "        backs.append(back)\n",
    "    except :\n",
    "        fails.append(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "03034fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1784  111.17842080668656\n",
      "8.9928  108.99278233692455\n",
      "1.9866  101.98657480066932\n",
      "4.8488  104.84877635326086\n",
      "1.9396  101.93961591577452\n",
      "1.8881  101.88806954332966\n",
      "1.5114  101.51140921982487\n",
      "4.6932  104.69324414993085\n",
      "0.3998  100.39979754223121\n",
      "6.2889  106.28886666045754\n",
      "0.4393  100.43926236804795\n",
      "1.8169  101.81691076459566\n",
      "1.102  101.10201189719115\n",
      "0.1919  100.19190137082107\n",
      "2.7828  102.78275848216926\n",
      "2.7828  102.78275848216926\n",
      "3.3716  103.37161654319402\n",
      "3.5839  103.58387350610231\n",
      "0.4289  100.42888680926772\n",
      "2.6824  102.68242969758798\n",
      "4.0776  104.07759558276604\n",
      "-1.7179  98.2820510731635\n",
      "-1.15  98.849952771787\n",
      "4.7956  104.79555826433585\n",
      "3.5428  103.54280879045122\n",
      "0.4226  100.42258897800441\n",
      "2.449  102.44899105665436\n",
      "1.9927  101.9927201812034\n",
      "3.5659  103.56589764746202\n",
      "1.5043  101.50425623539824\n",
      "-0.5615  99.43848269855486\n",
      "3.9127  103.9127255126473\n",
      "2.3257  102.32574410378834\n",
      "2.3257  102.32574410378834\n",
      "2.4694  102.46938976426335\n",
      "-0.7153  99.2847289702467\n",
      "-0.7153  99.2847289702467\n",
      "-1.5146  98.48540711588156\n",
      "2.0133  102.01327360290567\n",
      "0.1768  100.17680230592043\n",
      "-1.4113  98.58873973040787\n",
      "1.7138  101.71376236279345\n",
      "1.8003  101.80028324158683\n",
      "-4.0932  95.90677806717972\n",
      "-0.4117  99.5882520386677\n",
      "1.7828  101.78276333480545\n",
      "4.397  104.39696008200397\n",
      "-4.8548  95.14522275895645\n",
      "4.3984  104.39837808526549\n",
      "7.809  107.80900996906806\n",
      "1.295  101.29498798940644\n",
      "3.6903  103.69029900438586\n",
      "\n",
      "2.081253846153846  102.08124714700449\n"
     ]
    }
   ],
   "source": [
    "profs = []\n",
    "current = []\n",
    "for back in backs:\n",
    "    profs.append(back.get_profit())\n",
    "    current.append(back.current)\n",
    "    print(f\"{back.get_profit()}  {back.current}\")\n",
    "\n",
    "    \n",
    "print()\n",
    "print(f\"{np.average(profs)}  {np.average(current)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc4712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
