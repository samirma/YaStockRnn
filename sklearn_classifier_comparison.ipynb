{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706264fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from state_util import StateUtil\n",
    "from tec_an import TecAn\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "from sklearn_model_hyper import *\n",
    "from joblib import dump, load\n",
    "from data_generator import DataGenerator\n",
    "from data_agent import DataAgent, TacProcess\n",
    "from stock_agent import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import scikitplot as skplt\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow.keras as keras\n",
    "import random\n",
    "from catboost import CatBoost\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a4b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_data(ohlc, shift = -1):\n",
    "    combined_data = ohlc.copy()\n",
    "    #combined_data['return'] = np.log(combined_data / combined_data.shift(1))\n",
    "    returns = (ohlc / ohlc.shift(shift))\n",
    "    combined_data['return'] = returns\n",
    "    combined_data['direction'] = np.where(combined_data['return'] < 1, 1, 0)\n",
    "    #print(combined_data)\n",
    "    #combined_data.dropna(inplace=True)\n",
    "    #print(combined_data[20:40])\n",
    "    #\n",
    "    return combined_data['direction'].to_numpy()\n",
    "\n",
    "\n",
    "def get_sequencial_data(trainX, trainY, step):\n",
    "    y = get_y_data(\n",
    "        pd.DataFrame(trainY, columns = ['Close']), \n",
    "        (-1 * step)\n",
    "    )\n",
    "    x, y, closed_prices = trainX, y, trainY\n",
    "    return x, y, closed_prices\n",
    "\n",
    "def prepare_train_data(trainX, trainY, step):\n",
    "    y = get_y_data(\n",
    "        pd.DataFrame(trainY, columns = ['Close']), \n",
    "        (-1 * step)\n",
    "    )\n",
    "    x, y, closed_prices = trainX, y, trainY\n",
    "    return shuffle(x, y, closed_prices, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224a1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(array):\n",
    "    if (len(array) == 0):\n",
    "        return 0\n",
    "    return sum(array)/len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997362d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 193 µs, sys: 18 µs, total: 211 µs\n",
      "Wall time: 215 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(3),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(max_depth=50, n_estimators=100, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    CatBoostClassifier(logging_level = 'Silent'),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91fb4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_model(model, x, y, closed_prices):\n",
    "    back = BackTest(value = 100, \n",
    "                    verbose = False, \n",
    "                    sell_on_profit = True,\n",
    "                    pending_sell_steps = step)\n",
    "    \n",
    "    for idx in range(len(x)):\n",
    "        xx = [x[idx]]\n",
    "        yy = model.predict(xx)[0]\n",
    "        price = closed_prices[idx]\n",
    "        #print(f'{idx} {yy} {price}')\n",
    "        back.on_state(0, price)\n",
    "        if(yy == 1):\n",
    "            back.request_buy(price)\n",
    "        else:\n",
    "            back.request_sell(price)\n",
    "    return back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5cea570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "#normalizer = tf.keras.layers.experimental.preprocessing.Normalization(input_shape=(features,))\n",
    "\n",
    "\n",
    "def train_by_step(model, step):\n",
    "    trainX_raw, trainY_raw = load_data(\"simple_full_\", \"train\", path)\n",
    "    x, y, closed_prices = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "    #print(f\"{trainX_raw.shape}\")\n",
    "    #print(closed_prices)\n",
    "    model.fit(x, y)\n",
    "\n",
    "def eval_step(model, train_set, step):\n",
    "\n",
    "    valX, valY = load_data(f\"simple_{train_set}\", \"train\", path)\n",
    "    \n",
    "    x, y, closed_prices = get_sequencial_data(valX, valY, step)\n",
    "    \n",
    "    preds = model.predict(x)\n",
    "\n",
    "    recall = recall_score(y, preds)\n",
    "    precision = precision_score(y, preds)\n",
    "    f1 = f1_score(y, preds)\n",
    "    \n",
    "    back = backtest_model(model, x, y, closed_prices)\n",
    "    return back, (precision, recall, f1)\n",
    "\n",
    "    \n",
    "param = {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 30, 'random_state': 42}\n",
    "model = make_pipeline(StandardScaler(), RandomForestClassifier(**param))\n",
    "#model = RandomForestClassifier(**param)\n",
    "\n",
    "\n",
    "param = {'depth': 10, 'eval_metric': 'Precision', 'iterations': 500, 'l2_leaf_reg': 1e-19, 'logging_level': 'Silent', 'random_seed': 42}\n",
    "#model = make_pipeline(StandardScaler(),CatBoostClassifier(**param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04dc475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockModel():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model\n",
    "                ):\n",
    "        self.model = model\n",
    "        self.normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "        \n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.normalizer.adapt(x)\n",
    "        norm_x = self.normalizer(x).numpy()\n",
    "        self.model.fit(norm_x, y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        norm_x = self.normalizer(x).numpy()\n",
    "        return self.model.predict(norm_x)\n",
    "        \n",
    "model = MockModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db20aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_profit(x, y, closed_prices, step):\n",
    "\n",
    "    back = BackTest(value = 100, \n",
    "                    verbose = False, \n",
    "                    sell_on_profit = True,\n",
    "                    pending_sell_steps = step)\n",
    "    \n",
    "    for idx in range(len(x)):\n",
    "        yy = y[idx]\n",
    "        price = closed_prices[idx]\n",
    "        #print(f'{idx} {yy} {price}')\n",
    "        back.on_state(0, price)\n",
    "        #print(yy)\n",
    "        if(yy == 1):\n",
    "            back.request_buy(price)\n",
    "        else:\n",
    "            back.request_sell(price)\n",
    "    return back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba51d2e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adf2883506c446196f6fb7574205ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "CPU times: user 18.4 s, sys: 247 ms, total: 18.7 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trains_sets = [\"4jul21\"]\n",
    "#trains_sets = [\"backtest\"]\n",
    "trains_sets = [\"backtest\", \"4jul21\"]\n",
    "dirs = [\"omgusd\", \"btceur\", \"btcusd17\", \"btcusd\", \"ethusd\", \"ltcusd\", \"btcusdAug19\"]\n",
    "\n",
    "#trains_sets = dirs\n",
    "\n",
    "reference_profit = {}\n",
    "models_profit = {}\n",
    "\n",
    "models_profit_metric = {}\n",
    "\n",
    "models_score = {}\n",
    "\n",
    "keys = []\n",
    "\n",
    "steps = 1\n",
    "\n",
    "for step in tqdm(range(1, steps + 1)):\n",
    "    train_by_step(model, step)\n",
    "    print(f\"Step: {step}\")\n",
    "    for train_set in trains_sets:\n",
    "        trainX_raw, trainY_raw = load_data(f\"simple_{train_set}\", \"train\", path)\n",
    "        x, y, closed_prices = get_sequencial_data(trainX_raw, trainY_raw, step)\n",
    "        reference = get_max_profit(x, y, closed_prices, step)\n",
    "        \n",
    "        key = f\"{train_set}_{step}\"\n",
    "        keys.append(key)\n",
    "        \n",
    "        reference_profit[key] = reference.get_profit()\n",
    "        \n",
    "        back, score = eval_step(model, train_set, step)\n",
    "        #models_profit[key] = f\"{back.get_profit()}\"\n",
    "        models_profit[key] = back.get_profit()\n",
    "        models_score[key] = score\n",
    "        models_profit_metric[key] = back.get_profit() / reference.get_profit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "584af500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backtest_1: 135.1525 | 0.014793659014816597 | 1.9994 (0.48417350527549824, 0.4134134134134134, 0.44600431965442766)\n",
      "4jul21_1: 11.0982 | 0.00876718747184228 | 0.0973 (0.5133333333333333, 0.5460992907801419, 0.529209621993127)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for train_set in trains_sets:\n",
    "    for step in range(1, steps + 1):\n",
    "        key = f\"{train_set}_{step}\"\n",
    "        print(f\"{key}: {reference_profit[key]} | {models_profit_metric[key]} | {models_profit[key]} {models_score[key]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a36c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ae405",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_raw, trainY_raw = load_data(\"simple_full_\", \"train\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030462f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
