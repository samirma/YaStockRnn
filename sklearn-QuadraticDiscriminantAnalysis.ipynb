{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503083,
     "status": "ok",
     "timestamp": 1568068274112,
     "user": {
      "displayName": "Samir Moreira Ant√¥nio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCsh3ldsSLN0VnFRYp341EzO_UyuRNKmLncUbMA3Q=s64",
      "userId": "14581632111443153742"
     },
     "user_tz": -60
    },
    "id": "fGVQczSlF-9o",
    "outputId": "e3a06798-f737-48d9-ec6e-d3784cec3115"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from state_util import StateUtil\n",
    "from tec_an import TecAn\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "from sklearn_model_hyper import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import scikitplot as skplt\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, GlobalMaxPool1D, Bidirectional, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow.keras as keras\n",
    "import random\n",
    "from catboost import CatBoost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from state_util import StateUtil\n",
    "from tec_an import TecAn\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4127, 16)\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/\"\n",
    "trainX_raw, trainY_raw = load_data(\"\", \"train\", path)\n",
    "valX_raw, valY_raw = load_data(\"backtest\", \"train\", path)\n",
    "\n",
    "trainX_balanced, trainY_balanced = get_balanced_set(trainX_raw, trainY_raw)\n",
    "\n",
    "X_train, Y_train = trainX_balanced, trainY_balanced\n",
    "\n",
    "valX, valY = valX_raw, valY_raw\n",
    "\n",
    "features = trainX_raw.shape[-1]\n",
    "\n",
    "print(\"{}\".format(trainX_raw.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0.7815141844355995\n",
      "CPU times: user 450 ms, sys: 4.61 ms, total: 455 ms\n",
      "Wall time: 454 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [10, 30, 500],\n",
    "    'max_features': [1,4,5,6,7,8],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "clf =  DecisionTreeClassifier()\n",
    "\n",
    "clf_grid = gridSearch(X_train, Y_train, clf, {}, make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00      2569\n",
      "     class 1       1.00      1.00      1.00      2569\n",
      "\n",
      "    accuracy                           1.00      5138\n",
      "   macro avg       1.00      1.00      1.00      5138\n",
      "weighted avg       1.00      1.00      1.00      5138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = clf_grid.best_estimator_\n",
    "eval_data(model, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.54      0.56      0.55       985\n",
      "     class 1       0.47      0.45      0.46       840\n",
      "\n",
      "    accuracy                           0.51      1825\n",
      "   macro avg       0.50      0.50      0.50      1825\n",
      "weighted avg       0.51      0.51      0.51      1825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#val_x_norm = normalizer(valX).numpy()\n",
    "\n",
    "eval_data(model, valX, valY)\n",
    "\n",
    "#0.4957874270900843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/QuadraticDiscriminantAnalysis']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'model/QuadraticDiscriminantAnalysis') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1825, 16)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.58      0.39      0.46       985\n",
      "     class 1       0.48      0.67      0.56       840\n",
      "\n",
      "    accuracy                           0.52      1825\n",
      "   macro avg       0.53      0.53      0.51      1825\n",
      "weighted avg       0.53      0.52      0.51      1825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valX_raw, valY_raw = load_data(\"backtest\", \"train\", path)\n",
    "\n",
    "print(\"{}\".format(valX_raw.shape))\n",
    "\n",
    "eval_data(model, valX_raw, valY_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "enviroment",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
