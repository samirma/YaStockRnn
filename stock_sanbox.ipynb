{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "from data_util import *\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import model as model_util\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, GlobalMaxPool1D, Bidirectional, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import autokeras as ak\n",
    "import kerastuner\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed():\n",
    "    seed_value= 100\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "reset_seed()\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "path = \"./data/\"\n",
    "model_path = path + \"stock.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39066, 26) (3683, 26)\n"
     ]
    }
   ],
   "source": [
    "trainX_raw, trainY_raw = load_data(\"btceur\", \"train\", path)\n",
    "valX_raw, valY_raw = load_data(\"btceur\", \"Val\", path)\n",
    "\n",
    "trainX_balanced, trainY_balanced = get_balanced_set(trainX_raw, trainY_raw)\n",
    "\n",
    "valX, valY = valX_raw, valY_raw\n",
    "\n",
    "normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "normalizer.adapt(trainX_raw)\n",
    "\n",
    "\n",
    "print(\"{} {}\".format(trainX_balanced.shape, valX.shape))\n",
    "\n",
    "features = trainX_raw.shape[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "def show_feature_importances(tree):\n",
    "    title = 'Feature Importance:'\n",
    "    figsize = (15, 5)\n",
    "\n",
    "    feat_imp = pd.DataFrame({'Importance':tree.feature_importances_})    \n",
    "    feat_imp['feature'] = [i for i in range(features[-1])]\n",
    "    feat_imp.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    feat_imp = feat_imp\n",
    "\n",
    "    feat_imp.sort_values(by='Importance', inplace=True)\n",
    "    feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "    feat_imp.plot.barh(title=title, figsize=figsize)\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(tree, trainX, trainY):\n",
    "    tree.fit(trainX, trainY)\n",
    "    print(f'Train Accuracy: {tree.score(trainX, trainY)}')\n",
    "    print(f'Val Accuracy: {tree.score(valX, valY)}')\n",
    "    y_pred = tree.predict(valX)\n",
    "    print(confusion_matrix(valY, y_pred))\n",
    "    print(f1_score(valY, y_pred))\n",
    "\n",
    "def eval_tree(tree, trainX, trainY, valX, valY):\n",
    "    print(tree)\n",
    "\n",
    "    param_grid = [\n",
    "        {'n_estimators': [10,40, 50, 60, 100],\n",
    "        'max_depth': [4, 5, 6, 10],\n",
    "        'max_features': [4,6,8,10]\n",
    "        }\n",
    "    ]\n",
    "    grid_search = GridSearchCV(tree, param_grid, cv = 5, scoring = 'accuracy', verbose = 1)\n",
    "    grid_search.fit(trainX, trainY)\n",
    "    \n",
    "    show_confusion_matrix(tree, trainX, trainY)\n",
    "    show_feature_importances(tree)\n",
    "    \n",
    "    \n",
    "\n",
    "estimators = 300\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "tress = [\n",
    "        RandomForestClassifier(random_state=5)\n",
    "        ,DecisionTreeClassifier(min_samples_leaf=600)\n",
    "        ,ExtraTreesClassifier(n_estimators=estimators)\n",
    "        ,GradientBoostingClassifier(n_estimators=estimators, learning_rate=1.0,  max_depth=1000, random_state=0)\n",
    "        ,GaussianNB()\n",
    "        ,linear_model.Ridge(alpha=.5)\n",
    "        ,RidgeClassifier(alpha=.5)\n",
    "        ,AdaBoostClassifier(n_estimators=estimators)\n",
    "        ]\n",
    "\n",
    "def fit_model(model, trainX, trainY, valX, valY):\n",
    "    print(\"Fiting: {}\".format(model))\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        #monitor='val_precision', \n",
    "        monitor='val_prc', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "    callbacks_list = [early_stopping]\n",
    "    \n",
    "    epochs = 1000\n",
    "    \n",
    "    #compile_model(model)\n",
    "    \n",
    "    model.fit(\n",
    "            x=trainX,\n",
    "            y=trainY,\n",
    "            validation_data=(valX, valY),\n",
    "            epochs=epochs,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=0,\n",
    "            callbacks=callbacks_list\n",
    "        )\n",
    "\n",
    "    print(confusion_matrix(valY, model.predict(valX) > 0.5))\n",
    "    model.evaluate(valX, valY, verbose=1)\n",
    "\n",
    "    \n",
    "def fit_model_autokeras(model, trainX, trainY, valX, valY):\n",
    "    print(\"Fiting: {}\".format(model))\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        #monitor='val_precision', \n",
    "        monitor='val_prc', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "    callbacks_list = [early_stopping]\n",
    "    \n",
    "    epochs = 1000\n",
    "    \n",
    "    model.fit(\n",
    "            x=trainX,\n",
    "            y=trainY,\n",
    "            validation_data=(valX, valY),\n",
    "            epochs=epochs,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=0,\n",
    "            callbacks=callbacks_list\n",
    "        )\n",
    "\n",
    "    print(confusion_matrix(valY, model.predict(valX) > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "{'max_depth': 10, 'max_features': 8, 'n_estimators': 100}\n",
      "0.9230840773809523\n",
      "0.8251425468368178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit(x, y):\n",
    "    param_grid = [\n",
    "        {\n",
    "        'n_estimators': [10,40, 50, 60, 100],\n",
    "        'max_depth': [4, 5, 6, 10],\n",
    "        'max_features': [4,6,8,10]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    clf2 = RandomForestClassifier(random_state=5)\n",
    "\n",
    "    grid_search = GridSearchCV(clf2, param_grid, cv = 5, scoring = 'accuracy', verbose = 1)\n",
    "\n",
    "    grid_search.fit(x, y)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(best_params)\n",
    "\n",
    "    clf_opt = RandomForestClassifier(**best_params)\n",
    "\n",
    "    clf_opt.fit(x, y)\n",
    "    \n",
    "    return clf_opt\n",
    "\n",
    "clf_opt = fit(trainX_balanced, trainY_balanced)\n",
    "\n",
    "\n",
    "#clf_opt = linear_model.LogisticRegression(C=1e7, solver='lbfgs',\n",
    "#                                     multi_class='auto',\n",
    "#                                     max_iter=910000)\n",
    "\n",
    "\n",
    "#clf_opt.fit(trainX_balanced, trainY_balanced)\n",
    "#clf_opt.fit(trainX_raw, trainY_raw)\n",
    "\n",
    "print(clf_opt.score(trainX_raw, trainY_raw))\n",
    "print(clf_opt.score(valX, valY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      3317\n",
      "           1       0.07      0.06      0.06       366\n",
      "\n",
      "    accuracy                           0.83      3683\n",
      "   macro avg       0.48      0.48      0.48      3683\n",
      "weighted avg       0.81      0.83      0.82      3683\n",
      "\n",
      "Confusion Matrix Train\n",
      "[[3018  299]\n",
      " [ 345   21]]\n",
      "\n",
      "Accuracy Test\n",
      "0.8251425468368178\n",
      "0.065625\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx8ElEQVR4nO3de5yOdf748dfbIBQ2h8p5kNMYrdopKxE5pSWpFWk7bOO8zqlVSmVbpZAIOaZyiGyKzdbut5L9WSlFckgmDOMQJodQmPH+/XFd93Qbc7jNzHXfc9/3+/l4zMN9Xdfnuq7PFd3v+Ryu90dUFWOMMdGrSKgrYIwxJrQsEBhjTJSzQGCMMVHOAoExxkQ5CwTGGBPlLBAYY0yUs0BgjDFRzgKBiTgisktEfhaREyJyQETmishlmcrcKCIfi8hPInJMRJaLSFymMmVEZKKI7Hav9b27XSG4T2SMtywQmEjVSVUvAxoD1wKP+Q6ISFPg38B7QGWgJvA1sFpEarlligMfAQ2BW4EyQFMgFbjBq0qLSFGvrm1MdiwQmIimqgeAD3ECgs8LwBuq+rKq/qSqP6rqE8BnwNNumfuB6kAXVd2iqudU9aCq/k1VV2R1LxFpKCL/EZEfReQHEXnc3T9XRJ71K9dSRFL8tneJyF9FZCNw0v28JNO1XxaRSe7nsiIyW0T2i8heEXlWRGLy91/KRDMLBCaiiUhVoAOQ5G6XAm4E3s6i+GKgrfu5DfCBqp4I8D6lgf8DPsBpZVyN06II1D3AH4DfAG8Bt7nXxP2SvxtY4JadC6S597gWaAf0vIh7GXMeCwQmUr0rIj8Be4CDwFPu/nI4/+73Z3HOfsDX/18+mzLZ6QgcUNXxqvqL29JYexHnT1LVPar6s6omA18BXdxjtwCnVPUzEbkSuA0YoqonVfUg8BLQ/SLuZcx5LBCYSHWHqpYGWgL1+fUL/ghwDqiUxTmVgMPu59RsymSnGvB9nmrq2JNpewFOKwGgB7+2BmoAxYD9InJURI4C04Er8nFvE+UsEJiIpqqf4nSljHO3TwJrgK5ZFL+bX7tz/g9oLyKXBnirPUCtbI6dBEr5bV+VVVUzbb8NtHS7trrwayDYA5wGKqjqb9yfMqraMMB6GnMBCwQmGkwE2orIb93tEcADIjJIREqLyOXuYG5T4Bm3zJs4X7r/EJH6IlJERMqLyOMiclsW9/gnUElEhojIJe51m7jHNuD0+ZcTkauAIblVWFUPASuB14CdqrrV3b8fZ8bTeHd6axERqS0iN1/sfxRjfCwQmIjnfqm+AYxyt/8f0B64E2ccIBln0PUmVd3uljmNM2D8LfAf4DjwOU4X0wV9/6r6E85AcyfgALAdaOUefhNneuounC/xRQFWfYFbhwWZ9t8PFAe24HR1LeHiurGMOY/YwjTGGBPdrEVgjDFRzgKBMcZEOQsExhgT5SwQGGNMlAu7BFcVKlTQ2NjYUFfDGGPCypdffnlYVStmdSzsAkFsbCzr1q0LdTWMMSasiEhydsesa8gYY6KcBQJjjIlyFgiMMSbKhd0YQVbOnj1LSkoKv/zyS6irkiclSpSgatWqFCtWLNRVMcZEoYgIBCkpKZQuXZrY2FhEJNTVuSiqSmpqKikpKdSsWTPU1THGRCHPuoZEZI6IHBSRTdkcFxGZJCJJIrJRRK7L671++eUXypcvH3ZBAEBEKF++fNi2Zowx4c/LMYK5OIt+Z6cDUMf96Q1My8/NwjEI+IRz3Y0x4c+zQKCqq4AfcyjSGWcBcVXVz4DfiIil0jXGmExOnjzJw/PX8MzyzZ5cP5Szhqpw/vJ8Ke6+C4hIbxFZJyLrDh06FJTKXayYmBgaN25MfHw8nTp14ujRowDs2rWLkiVL0rhx44yfM2fOhLayxpiw8fHHHxPfuS//+OZHtuw77sk9wmL6qKrOUNUEVU2oWDHLN6RDrmTJkmzYsIFNmzZRrlw5pkyZknGsdu3abNiwIeOnePHiIaypMSYcHD16lF69etG6dWuokQBA58ZZ/q6cb6GcNbQXZ8Fvn6ruvrDXtGlTNm7cGOpqGGPCVHp6OjfeeCPbtm3j0UcfZUdsAkWKFKFHk+qe3C+UgWAZMEBE3gKaAMfc9Vjz5Znlmwu8+RRXuQxPdQpsbfD09HQ++ugjEhMTM/Z9//33NG7cGIBmzZqd11owxhif1NRUypUrR0xMDH//+9+pVq0aCQkJdJu+xtP7ejl9dCGwBqgnIikikigifUWkr1tkBbADSAJmAv29qksw/PzzzzRu3JirrrqKH374gbZt22Yc8+8asiBgjMlMVZk3bx5169Zl1qxZAHTp0oXv0q+g2/Q1bNnvzdiAj2ctAlW9J5fjCvyloO8b6G/uBc03RnDq1Cnat2/PlClTGDRoUEjqYowJH3v27KFv376sWLGC3//+9xyv2CijBbB2pzPxsknNcp6ND0CEvFlcmJQqVYpJkyZxxx130L9/WDdyjDEeW7hwIX369CE9PZ2HxszhRLl6TP4sFXC+/H0BwKuxAR8LBB649tprueaaa1i4cCHNmzcPdXWMMYXU5ZdfTpMmTeg0ZCwT/rsfjh0J2pe/PwsEBeTEiRPnbS9fvjzj86ZNWWbZMMZEmbS0NF566SXOnDnDyJEj+fHyOMr9cbQTBIAxXRoFNQD4WCAwxpgg+Prrr0lMTOTLL7/k7rvvRlV5b8Netuw/HpJWgD8LBMYY46HTp0/z7LPP8vzzz1OuXDkenvoOe4pcRfcZn7Fl/3HiKpVhUZ+mIa1jWLxZHAhnElJ4Cue6G2Nytn37dsaOHUuPHj3YsmULe4pclTEdNK5SGU9nAwUqIloEJUqUIDU1NSxTUfvWIyhRokSoq2KMKSAnTpzgvffe49577yU+Pp5vv/2WWrVqZRwvDK0AfxERCKpWrUpKSgqFNSFdbnwrlBljwt9//vMfevfuTXJyMtdddx0NGjTICAIL1u5m7c4faVKzXIhreb6ICATFihWz1b2MMSF15MgRhg8fzpw5c6hbty6ffvopDRo0yDi+YO1uHl/6DeBd8ri8iohAYIwxoZSenk6zZs347rvveOyxxxg1alRGd++Ctbt5b8PejLeEQzVFNCcWCIwxJo8OHz6ckSRuzJgxVK9eneuu+3XVXf9WQKiniOYkYmYNGWNMsKgqb7zxxnlJ4u64445sg8CYLo1Y1KdpoQwCYIHAGGMuSnJyMh06dOCBBx6gQYMGtGjR4oIymYNAYQ0APtY1ZIwxAZo3bx79+vVDVZk8eTL9+/enSBHn92nfWABQqMcDsmKBwBhjAlSxYkWaNWvG9OnTqVGjBnDhYHAws4YWFAsExhiTjbNnzzJ+/HjOnj3Lk08+Sfv27WnXrl3Gi6vhMhicGwsExhiThfXr15OYmMj69evp3r07qoqInJe9wNcVFC5dQNmxwWJjjPHzyy+/8Pjjj3P99dezb98+/vGPf7Bw4cLzAsCCtbszlpBsUrNcWAcBsEBgjDHnSUpKYty4cdx///1s3bqVO++884IyvvTRhSVpXH5Z15AxJuqdOHGCpUuXct999xEfH8+2bduyTVvjny+oMCWOyw9rERhjotqHH35Iw4YNeeCBB9i6dStAjkGgsOYLyg9rERhjolJqairDhg3jjTfeoH79+vz3v/89L0mcTzi/HxAoCwTGmKjjSxKXlJTEyJEjeeKJJ7JcEyTz9NBwniKaEwsExpiocejQIcqXL09MTAxjx46lRo0aNG7cONvykTI9NDc2RmCMiXiqymuvvUbdunWZOXMmAJ07d84xCPhEwvTQ3FggMMZEtF27dtG+fXseeughGjVqRKtWrQI6zzc7KBpYIDDGRKw333yT+Ph41qxZw9SpU1m5ciV169bN9bxInR2UHRsjMMZErCuvvJIWLVrw6quvUr16YN074ZZCuiBYIDDGRIyzZ8/ywgsvkJ6ezqhRo2jXrh3t2rXL9bxomCKaEwsExpiI8NVXX/HQQw/x9ddf06NHj4wkcTmJhBTSBcECgTEmrP38888888wzjBs3jooVK7J06VLuuOOOgM715QyKxi9/f54OFovIrSKyTUSSRGREFseri8gnIrJeRDaKyG1e1scYE3l27NjBhAkTePDBB9myZUvAQcA3KyiuUplCvZ5wMHgWCEQkBpgCdADigHtEJC5TsSeAxap6LdAdmOpVfYwxkeP48ePMnTsXgIYNG7J9+3ZmzZrF5ZdfHvA1fGMC0TArKDdetghuAJJUdYeqngHeAjpnKqNAGfdzWWCfh/UxxkSAFStWEB8fT2JiYkaSON+ykYHyzyAazS0BHy/HCKoAe/y2U4Ammco8DfxbRAYClwJtsrqQiPQGegMBTwEzxkSWw4cPM3ToUObNm0dcXByrV6/OMklcTjIPDltrwBHqweJ7gLmqOl5EmgJviki8qp7zL6SqM4AZAAkJCRqCehpjQsiXJG7Hjh2MGjWKxx9/nEsuueSirhEp6wt7wctAsBeo5rdd1d3nLxG4FUBV14hICaACcNDDehljwsQPP/xAxYoViYmJYdy4cdSoUYNrrrnmoq8TjS+JXQwvxwi+AOqISE0RKY4zGLwsU5ndQGsAEWkAlAAOeVgnY0wYUFVmz55NvXr1mDFjBgCdOnWyIOARzwKBqqYBA4APga04s4M2i8hoEbndLfYw0EtEvgYWAg+qqnX9GBPFduzYQZs2bejZsyeNGzemTZsshw4DYkEgMJ6OEajqCmBFpn2j/D5vAZp5WQdjTPh4/fXX6d+/PzExMbz66qv06tWLIkXy/vtqtKwnkF+hHiw2xpgMlStX5pZbbmHatGlUrVr1os/3zxkEZLw1bEEgZxYIjDEhc+bMGZ5//nnOnTvH008/Tdu2bWnbtm2er+dLGRFXyXk9Ka5SGZsiGgALBMaYkPjiiy946KGH2LRpE/fdd19ASeKy42sJ+ILAoj5NC7i2kc0CgTEmqE6dOsWoUaN46aWXqFSpEsuWLaNTp055ulZW2UOtBXDxLBAYY4Jq586dTJ48mV69ejF27FjKli2b52tZ9tCCYYHAGOO5Y8eO8c477/DnP/+Zhg0bkpSURLVq1XI/MQDWFZR/tmaxMcZT77//Pg0bNqRnz558++23APkOAgvW7qbb9DVs2X+8IKoY9axFYIzxxKFDhxgyZAgLFiwgPj6ed955h/r16+frmjYm4A0LBMaYApeens5NN93Ezp07eeaZZxgxYgTFixfP8/WyCwA2JlAwLBAYYwrMgQMHuOKKK4iJiWH8+PHExsYSHx+f5+tZAAgOGyMwxuTbuXPnmD59OnXr1mX69OkAdOzYMV9BAM6fFTSmS6OoX1LSKwG1CESkJFBdVbd5XB9jTJhJSkqiV69erFy5kltuuYX27dvn63r+aSLsBbHgyDUQiEgnYBxQHKgpIo2B0ap6e44nGmMi3muvvUb//v0pXrw4M2fOJDExMd9vB/t3A1mKiOAIpEXwNM76wysBVHWDiNT0sE7GmDBRvXp12rdvz5QpU6hSJfAv7MzJ4QAbBwihQALBWVU9linK25oBxkSh06dP89xzz3Hu3DlGjx5N69atad26dUDn+n/5+3/p+1gACJ1AAsFmEekBxIhIHWAQ8D9vq2WMKWzWrl1LYmIimzdv5oEHHrjoJHH+SeHsS79wCSQQDARGAqeBBTgrjv3Ny0oZYwqPkydP8uSTTzJx4kSqVKnCP//5T/7whz/k6Vo28Fs4BTJ99A+qOlJVr3d/ngBsoNiYKJGcnMzUqVPp27cvmzdvzlMQWLB2d0Z3kCl8AmkRPAa8HcA+Y0yEOHr0KEuWLKFnz57ExcWRlJSUrxXDfEHAZgAVTtkGAhHpANwGVBGRSX6HygBpXlfMGBMa7733Hv369ePgwYPcdNNN1K9fP89BwLdwvI0JFG45tQj2AetwuoG+9Nv/EzDUy0oZY4Lv4MGDDBo0iEWLFnHNNdewbNmyPCeJ8w8CtnB84ZdtIFDVr4GvRWSBqp4NYp2MMUGWnp5Os2bN2L17N88++yyPPvooxYoVy9O1LAiEn0DGCGJF5DkgDijh26mqtTyrlTEmKPbt28dVV11FTEwML7/8MrGxscTFxeX5ehYEwlMgs4ZeA6bhjAu0At4A5nlZKWOMt86dO8e0adOoX78+r776KgC33XabBYEoFUiLoKSqfiQioqrJwNMi8iUwyuO6GWM88N1339GrVy9WrVpFmzZt6NChQ76ul3lmkAWB8BNIIDgtIkWA7SIyANgLXOZttYwxXpg9ezYDBgygRIkSzJkzhwcffLBAk8TZzKDwFEggGAyUwkkt8Tec7qEHvKyUMcYbsbGxdOjQgSlTplCpUqU8X8emhkYWUc0+f5yIxABjVXV48KqUs4SEBF23bl2oq2FMWDh9+jR/+5uTEebZZ5/N9/WsGyh8iciXqpqQ1bEcWwSqmi4iN3lTLWOMl/73v/+RmJjIt99+y0MPPXTRSeL8WTdQZAuka2i9iCzDSSlx0rdTVd/xrFbGmDw7ceIEI0eOZPLkyVSrVo0PPvgg36uG+S8ZaQEg8gQSCEoAqcAtfvsUyDUQiMitwMtADDBLVZ/PoszdOIvfKPC1qvYIoE7GmGzs3r2b6dOn85e//IUxY8ZQunTpfF3PlzCuSc1yljk0QuUaCFT1z3m5sDu+MAVoC6QAX4jIMlXd4lemDk4Cu2aqekRErsjLvYyJdkeOHOHtt9+md+/exMXFsWPHDipXrpyva1rCuOgR0OL1eXQDkKSqOwBE5C2gM7DFr0wvYIqqHgFQ1YMe1seYiLR06VL69+/PoUOHuPnmm6lXr16BBAGbFRQ9AnmzOK+qAHv8tlPcff7qAnVFZLWIfOZ2JV1ARHqLyDoRWXfo0CGPqmtMeDlw4ABdu3blzjvv5KqrruLzzz+nXr16+b5u5jeEF/VpakEgwnnZIgj0/nWAlkBVYJWINFLVo/6FVHUGMAOc6aNBrqMxhU56ejrNmzdnz549jBkzhuHDh+c5SZw/SxMRnXINBCJyJTAGqKyqHUQkDmiqqrNzOXUvUM1vu6q7z18KsNbNbrpTRL7DCQxfBPoAxkSTlJQUKleuTExMDJMmTaJmzZp5ThWdFd/i8hYEoksgXUNzcdYp9nU6fgcMCeC8L4A6IlJTRIoD3YFlmcq8i9MaQEQq4HQV7Qjg2sZElXPnzjF58mTq16/PtGnTAOjQoUOBBgH/2UEWBKJLIIGggqouBs4BqGoakJ7bSW65AThBZCuwWFU3i8hoEfGtefwhkCoiW4BPgEdUNTUPz2FMxPr2229p0aIFgwYN4qabbqJjx46e3MfXGrDZQdEnkDGCkyJSHmeePyLye+BYIBdX1RXAikz7Rvl9VmCY+2OMyWTWrFkMGDCAUqVK8frrr3Pffffl+e3gQFhrIDoFEggexunSqS0iq4GKwB89rZUxBoDatWvTqVMnXnnlFa688krP7uPfLWSiTyAvlH0pIjcD9QABttnSlcZ445dffmH06NEAjBkzhlatWtGqVStP7+k/U8i6haJTrmMEIrIReBT4RVU3WRAwxhurV6+mcePGPPfccxw6dIicMgMXFJsuaiCwweJOOMtULhaRL0RkuIjYvxZjCshPP/3EwIEDad68OadPn+bDDz9k5syZno4FgAUB86tcA4GqJqvqC6r6O6AHcA2w0/OaGRMlUlJSmDVrFgMHDuSbb76hXbt2QbmvvTNgfAJ6s1hEagDd3J90nK4iY0wepaamsnjxYvr160eDBg3YsWNHvlYMyyubJWQgsDGCtcBSnFTSXVX1BlUd73nNjIlAqsqSJUuIi4tj0KBBbNu2DSDoQcA3S8gYCGyM4H5VvU5Vn/NlEjXGXLz9+/dz11130bVrV6pVq8a6desKJEncxbJZQiazbLuGRORPqjoP+IOI/CHzcVWd4GnNjIkgviRxe/fu5YUXXmDo0KEULRq8nI++tQUAW2/YXCCnf4mXun9mtbyRZQA1JgB79uyhSpUqxMTEMGXKFGrWrEndunWDXg/fUpNxlcrY+gLmAtkGAlWd7n78P1Vd7X9MRJp5Witjwlx6ejpTpkzhscce44UXXuAvf/lLvtcNzgtfS8AXBGypSZOVQMYIJge4zxgDbN26lebNmzN48GBuvvlmOnXqFJJ6+MYC1u78kbhKZWw8wGQrpzGCpsCNQEUR8U8KVwZnBpExJpMZM2YwcOBASpcuzZtvvsm9997r+YthmWVea9jGAkxuchojKA5c5pbxHyc4jiWdMyZLderUoUuXLkyaNIkrrrgi6Pe3tYZNXuQ0RvAp8KmIzFXV5CDWyZiw8fPPP/P0008jIjz//PNBSRKXE3tb2ORFTl1DE1V1CPCKiFwwS0hVb7/wLGOix6pVq+jZsyfbt2+nb9++qGrQu4F8/AeF7W1hc7Fy6hp60/1zXDAqYky4OH78OCNGjGDatGnUqlWLjz76iFtuuSVk9cmqO8iYi5FT19CX7p+f+vaJyOVANVXdGIS6GVMo7du3j7lz5zJs2DBGjx7NpZdemvtJHrEMoqYg5Ppqo4isBG53y34JHBSR1apqy0uaqHH48GEWL15M//79qV+/Pjt37vR0xbDc2MwgU5ACece9rKoeF5GewBuq+pS7WI0xEU9VWbx4MQMHDuTo0aO0adOGunXrhjwI2MwgU5ACCQRFRaQScDcw0uP6GFNo7Nu3j379+rFs2TISEhL46KOPQpIewp91BRkvBBIIRgMfAqtV9QsRqQVs97ZaxoRWeno6LVq0YO/evYwbN47BgwcHNUlcViwIGK8Esnj928Dbfts7gLu8rJQxoZKcnEzVqlWJiYlh6tSp1KpVi6uvvjqkdbLxAOO1QBamqSoiS0XkoPvzDxGpGozKGRMs6enpTJgwgQYNGjBt2jQA2rVrF/IgAJz3foAFAeOFQNq6rwELgK7u9p/cfW29qpQxwbRp0yYSExP5/PPP6dixI3fccUeoq3Te+gGWOdR4LZBAUFFVX/PbnisiQzyqjzFB9eqrrzJo0CDKli3LggUL6N69e8jeDoYLu4Ga1CxnmUON5wIJBKki8idgobt9D5DqXZWM8Z4vHUSDBg3o2rUrEydOpGLFikGvh/9v/sB5AcCmhZpgEdWcFxsTkRo46w/42qWrgUGqutvjumUpISFB161bF4pbmwhw6tQpRo0aRUxMDGPHjg1JHbJaNrJJzXIZxy0AGC+IyJeqmpDVsUBmDSXjvFlsTFhbuXIlPXv25Pvvv6d///4hSRKX+WUw+83fFAaBpJioBbwM/B5nreI1wFB3Gqkxhd6xY8d49NFHmTFjBrVr1+bjjz8OeqpomwJqCrNAxggWAFOALu52d5zxgiZeVcqYgrR//37mzZvH8OHDeeaZZyhVqpTn97S+fxNOAgkEpVT1Tb/teSLySCAXF5FbcVoTMcAsVX0+m3J3AUuA61XVBgBMvh06dIi33nqLgQMHUr9+fXbt2hWUweCsZv34/rQAYAqrQALBv0RkBPAWTtdQN2CFiJQDUNUfszpJRGJwWhJtgRTgCxFZpqpbMpUrDQwG1ub5KYxxqSoLFy5k0KBBHD9+nPbt21O3bt2gzQjyf/nLvvhNuAgkENzt/tkn0/7uOIGhVjbn3QAk+cYSROQtoDOwJVO5vwFjgYBaGcZkZ8+ePfTr14/333+fJk2aMHv27HwnicvcxZMbe/nLhKNAZg3VzOO1qwB7/LZTyDSuICLX4Sx0835O3U0i0hvoDVC9uv2GZS6UlpZGy5YtOXDgAC+99BIDBw4kJiYmX9fMPMMnEPbylwlHIUunKCJFgAnAg7mVVdUZwAxw3iPwtmYmnOzatYtq1apRtGhRpk+fTq1atahVK7tGauAs06eJJrkmncuHvUA1v+2q7j6f0kA8sFJEduFMT10mIlm+8GCMv7S0NMaNG0eDBg2YOnUqAG3atLEgYEweeNki+AKoIyI1cQJAd6CH76CqHgMq+LbdJTGH26whk5uNGzeSmJjIunXr6Ny5M3fdVbBZ0X1jAhYETLQIJA21iMifRGSUu11dRG7I7TxVTQMG4CxqsxVYrKqbRWS0iNibyiZPpk6dyu9+9zuSk5NZtGgRS5cupXLlygV2/QVrd7N25480qVnOgoCJGoG0CKYC54BbcFYr+wn4B3B9bieq6gpgRaZ9o7Ip2zKAupgo5UsHER8fT/fu3XnppZeoUKFC7ideJF9rwAZ8TTQJJBA0UdXrRGQ9gKoeEZHiHtfLGABOnjzJE088QdGiRXnxxRdp0aIFLVq0KLDrZ54e6nsHwFoDJpoEMlh81n05TAFEpCJOC8EYT3300Uc0atSIiRMncvr0aXLLlHsxFqzdTbfpa3h86TcZbwGDTf800SmQFsEkYClwhYj8Hfgj8ISntTJR7ejRowwfPpzZs2dTp04dVq1aRfPmzQv0HvYGsDG/CuSFsvki8iXQGhDgDlXd6nnNTNT64YcfeOutt/jrX//KU089RcmSJQv0+v4DwvYGsDGBpaGuDpwClvvvC9XCNCYy+b78Bw8eTL169di1a1e+B4OzSw/h6wqyLiBjHIF0Db2PMz4gQAmgJrANaOhhvUyUUFXmz5/P4MGDOXHiBLfddht16tTJVxDILgOoj3UHGXO+QLqGGvlvu/mB+ntWIxM1du/eTd++ffnXv/5F06ZNM8YE8iNzfiD7wjcmdxf9ZrGqfiUitiiNyRdfkriDBw8yadIk+vfvX6BJ4uytYGMCF8gYwTC/zSLAdcA+z2pkItqOHTuoUaMGRYsWZebMmdSuXZvY2NgCubalhjAmbwJ5j6C0388lOGMGnb2slIk8aWlpjB07lri4OKZMmQJA69at8x0EfO8DdJu+xl4GMyaPcmwRuC+SlVbV4UGqj4lAGzZsIDExka+++oouXbrQtWvXizo/p8Vh/AeE7WUwY/Im20AgIkVVNU1EmgWzQiayvPLKKwwdOpTy5cuzZMmSbDOFBvpln5kNCBuTfzm1CD7HGQ/YICLLgLeBk76DqvqOx3UzYcyXJO6aa67h3nvvZcKECZQrd/4Xuf+Xv33ZGxM6gcwaKgGk4mQf9b1PoIAFAnOBEydOMHLkSIoVK8a4ceMuSBKX3Ze/fdkbEzo5BYIr3BlDm/g1APjYcpHmAv/+97/p3bs3u3fvZuDAgRmtAsj6JS/78jemcMgpEMQAl3F+APCxQGAyHDlyhGHDhjF37lzq1avHqlWruOmmmzKO20texhRuOQWC/ao6Omg1MWHr4MGDLFmyhMcee4xRo0ZRokSJjGP2kpcxhV9OgSCrloAxABw4cICFCxcydOjQjCRx5cuXv6CcveRlTOGXUyBoHbRamLChqrzxxhsMHTqUU6dO0bFjR+rUqXNeEPAfELaXvIwp/LINBKr6Y3bHTHTatWsXffr04d///jfNmjVj1qxZ5yWJy2pA2F7yMqbwu+ikcyY6paWl0apVKw4fPsyUKVPo27cvRYo4GUqyCgA2IGxM+LBAYHKUlJREzZo1KVq0KHPmzKFWrVrUqFEj47jNCDIm/AWSdM5EobNnzzJmzBgaNmyYkSSuVatWGUHAf/F3cAaDF/VpakHAmDBkLQJzga+++orExEQ2bNhA165d6dat23nHrRVgTGSxQGDOM2nSJIYNG0bFihV555136NKlS8axzGMBNiXUmMhggcAAvyaJu/baa7n//vsZP348l19++Xll3tuwN2M6qLUCjIkcFgii3E8//cRjjz3GJZdcwvjx42nevDnNmzfPtnxcpTIs6tM0iDU0xnjNBouj2AcffEB8fDxTp05FVVHNPoXUgrW7M7qEjDGRxQJBFEpNTeWBBx6gQ4cOXHrppaxevZoJEyZkZArNzH9w2F4OMybyWCCIQqmpqSxdupQnn3yS9evX07Rp9l09ljTOmMjn6RiBiNwKvIyT0nqWqj6f6fgwoCeQBhwCHlLVZC/rFK3279/P/Pnzefjhh6lbty7JyckXDAb7sxlCxkQPz1oE7sL3U4AOQBxwj4jEZSq2HkhQ1WuAJcALXtUnWqkqc+bMoUGDBjz55JMkJSUB5BoEHl/6DWt3/kiTmuUsCBgT4bzsGroBSFLVHap6BngL6OxfQFU/UdVT7uZnQFUP6xN1du7cSbt27UhMTOS3v/0tX3/99XlJ4rLjnzra3hY2JvJ52TVUBdjjt50CNMmhfCLwr6wOiEhvoDdA9er2pRSItLQ0brnlFlJTU5k2bRq9e/fOSBKXFUsdbUz0KhTvEYjIn4AE4OasjqvqDGAGQEJCgi2TmYPt27dTq1YtihYtymuvvUbt2rWpVq1aruf5XhaLq1TGUkcbE2W87BraC/h/A1V1951HRNoAI4HbVfW0h/WJaGfPnuXZZ58lPj6eV155BYCWLVsGFAR8fC+LWXeQMdHFyxbBF0AdEamJEwC6Az38C4jItcB04FZVPehhXSLaunXrSExMZOPGjXTv3p177rknoPMydwfFVSrjZTWNMYWUZy0CVU0DBgAfAluBxaq6WURGi8jtbrEXgcuAt0Vkg4gs86o+kerll1+mSZMmHD58mPfee4+FCxdyxRVXBHSurzsIsO4gY6KYp2MEqroCWJFp3yi/z228vH8k8yWJS0hIIDExkRdeeIHf/OY3uZ6XVSvAcgcZE90KxWCxCdzx48f561//SokSJXjppZdo1qwZzZo1C+jczOsIWCvAGAMWCMLKihUr6NOnD/v27WPYsGEZrYLs+P/2D9hbwsaYLFkgCAOHDx9myJAhzJ8/n4YNG7JkyRKaNMnplYwLf/v3/WnrCBhjMrNAEAaOHDnC8uXLeeqpp3j88ccpXrx4tmUtR5Ax5mJZICik9u7dy/z583nkkUeoU6cOycnJAQ0G2ypixpiLZYGgkFFVZs2axfDhwzl79ix33nknV199dY5BwGYCGWPywwJBIfL999/Tq1cvPvnkE1q2bMnMmTO5+uqrsy2fuRvIZgIZY/LCAkEhkZaWRuvWrfnxxx+ZPn06PXv2zDVJnP9gsHUDGWPyygJBiG3bto3atWtTtGhRXn/9dWrXrk3Vqlln4/bvArLBYGNMQbFAECJnzpzhueee4+9//zsvvvgigwcP5uabL0y+mtWXf5Oa5awVYIwpMBYIQuDzzz8nMTGRTZs20aNHD+69995sy/qnh7Yvf2OMFywQBNnEiRN5+OGHqVSpEsuXL6djx465nmOzgIwxXrJAECS+dBA33HADvXr1YuzYsZQtW/aCcpnTQlh6aGOM1ywQeOzYsWM8+uijlCxZkokTJ3LjjTdy4403Zlk2q7QQNh3UGOM1CwQeWr58OX379uXAgQMMHz48xyRx/kHAZgIZY4LJAoEHDh06xODBg1m4cCGNGjXi3Xff5frrr8+yrOUGMsaEmgUCDxw7dowVK1bwzDPPMGLEiGyTxNlLYcaYwsACQQHZs2cP8+bNY8SIEVx99dUkJyfnOhhsrQBjTGHg2ZrF0eLcuXO8+uqrNGzYkGeffZbvv/8eIMsgAOevE9ykZjkLAsaYkLMWQT5s376dXr168emnn9K6dWtmzJhBrVq1ziuT3XRQey/AGFNYWCDIo7S0NNq2bcvRo0eZPXs2f/7zn7OcEeT/ZjDYdFBjTOFjgeAibd26lTp16lC0aFHefPNNateuTeXKlS8o52sJWAvAGFPYWSAI0OnTpxkzZgxjxozhxRdfZMiQITRv3hy4sPsHzk8QZy0AY0xhZoEgAJ999hmJiYls2bKF++67j/vuuw/IemEYH5sOaowJFxYIcjF+/HgeeeQRqlatyooVK+jQoQNg7wAYYyKHBYJsnDt3jiJFitC0aVP69u1LQrfBzP32R+ZOXwPYOwDGmMhhgSCTo0eP8vDDD1OqVCkmT57MrpiqpP72Pkb/Kwn4tfvHWgHGmEhhgcDPu+++S//+/Tl48CCPPvoo89cmM3LpJsC++I0xkcsCAXDw4EEGDBjA22+/TYOOPbm25d18f9llLHCDgHX/GGMimQUC4Pjx46xMSeP3j7/F/vTL2HzoDE0us1aAMSY6RGUgWLB2N4vX7uCHH36genXnS75Ui0T2p9uXvzEm+ngaCETkVuBlIAaYparPZzp+CfAG8DsgFeimqru8rNP8z3Yx8t3NAJxJSaZixYqULFnSAoAxJmp5FghEJAaYArQFUoAvRGSZqm7xK5YIHFHVq0WkOzAW6OZVnV5a9jkv/+8QAFckf8Ti5wYRGxvr1e2MMSYseJmG+gYgSVV3qOoZ4C2gc6YynYHX3c9LgNaS3VqO+fT0e99kBIGOV/3E2gXjLQgYYwzedg1VAfb4bacATbIro6ppInIMKA8c9i8kIr2B3kBGn/7FkiJFqF8uhs6Nq9CvXaM8XcMYYyJRWAwWq+oMYAZAQkKC5uUaT3VqCJ0aFmi9jDEmEnjZNbQXqOa3XdXdl2UZESkKlMUZNDbGGBMkXgaCL4A6IlJTRIoD3YFlmcosAx5wP/8R+FhV8/QbvzHGmLzxrGvI7fMfAHyIM310jqpuFpHRwDpVXQbMBt4UkSTgR5xgYYwxJog8HSNQ1RXAikz7Rvl9/gXo6mUdjDHG5MzLriFjjDFhwAKBMcZEOQsExhgT5SwQGGNMlJNwm60pIoeA5DyeXoFMby1HAXvm6GDPHB3y88w1VLViVgfCLhDkh4isU9WEUNcjmOyZo4M9c3Tw6pmta8gYY6KcBQJjjIly0RYIZoS6AiFgzxwd7JmjgyfPHFVjBMYYYy4UbS0CY4wxmVggMMaYKBeRgUBEbhWRbSKSJCIjsjh+iYgsco+vFZHYEFSzQAXwzMNEZIuIbBSRj0SkRijqWZBye2a/cneJiIpI2E81DOSZReRu9+96s4gsCHYdC1oA/7ari8gnIrLe/fd9WyjqWVBEZI6IHBSRTdkcFxGZ5P732Cgi1+X7pqoaUT84Ka+/B2oBxYGvgbhMZfoDr7qfuwOLQl3vIDxzK6CU+7lfNDyzW640sAr4DEgIdb2D8PdcB1gPXO5uXxHqegfhmWcA/dzPccCuUNc7n8/cArgO2JTN8duAfwEC/B5Ym997RmKL4AYgSVV3qOoZ4C2gc6YynYHX3c9LgNYiIkGsY0HL9ZlV9RNVPeVufoazYlw4C+TvGeBvwFjgl2BWziOBPHMvYIqqHgFQ1YNBrmNBC+SZFSjjfi4L7Ati/Qqcqq7CWZ8lO52BN9TxGfAbEamUn3tGYiCoAuzx205x92VZRlXTgGNA+aDUzhuBPLO/RJzfKMJZrs/sNpmrqer7wayYhwL5e64L1BWR1SLymYjcGrTaeSOQZ34a+JOIpOCsfzIwOFULmYv9/z1XYbF4vSk4IvInIAG4OdR18ZKIFAEmAA+GuCrBVhSne6glTqtvlYg0UtWjoayUx+4B5qrqeBFpirPqYbyqngt1xcJFJLYI9gLV/LaruvuyLCMiRXGak6lBqZ03AnlmRKQNMBK4XVVPB6luXsntmUsD8cBKEdmF05e6LMwHjAP5e04BlqnqWVXdCXyHExjCVSDPnAgsBlDVNUAJnORskSqg/98vRiQGgi+AOiJSU0SK4wwGL8tUZhnwgPv5j8DH6o7ChKlcn1lErgWm4wSBcO83hlyeWVWPqWoFVY1V1ViccZHbVXVdaKpbIAL5t/0uTmsAEamA01W0I4h1LGiBPPNuoDWAiDTACQSHglrL4FoG3O/OHvo9cExV9+fnghHXNaSqaSIyAPgQZ8bBHFXdLCKjgXWqugyYjdN8TMIZlOkeuhrnX4DP/CJwGfC2Oy6+W1VvD1ml8ynAZ44oAT7zh0A7EdkCpAOPqGrYtnYDfOaHgZkiMhRn4PjBcP7FTkQW4gTzCu64x1NAMQBVfRVnHOQ2IAk4Bfw53/cM4/9exhhjCkAkdg0ZY4y5CBYIjDEmylkgMMaYKGeBwBhjopwFAmOMiXIWCEyhJSLpIrLB7yc2h7Ingli1bIlIZRFZ4n5u7J8JU0RuzylLqgd1iRWRHsG6nwlfNn3UFFoickJVLyvossEiIg/iZDwd4OE9irr5srI61hIYrqodvbq/iQzWIjBhQ0Quc9dS+EpEvhGRC7KNikglEVnltiA2iUhzd387EVnjnvu2iFwQNERkpYi87HfuDe7+ciLyrpv7/TMRucbdf7Nfa2W9iJR2fwvf5L4FOxro5h7vJiIPisgrIlJWRJLdfEiIyKUiskdEiolIbRH5QES+FJH/ikj9LOr5tIi8KSKrcV6MjHXLfuX+3OgWfR5o7t5/qIjEiMiLIvKF+yx9CuivxoS7UOfeth/7ye4H583YDe7PUpw34cu4xyrgvFnpa9WecP98GBjpfo7ByTlUAWdNgkvd/X8FRmVxv5XATPdzC9x88MBk4Cn38y3ABvfzcqCZ+/kyt36xfuc9CLzid/2MbeA9oJX7uRswy/38EVDH/dwEJ/1J5no+DXwJlHS3SwEl3M91cN64Beft1H/6ndcbeML9fAmwDqgZ6r9n+wn9T8SlmDAR5WdVbezbEJFiwBgRaQGcw0m9eyVwwO+cL4A5btl3VXWDiNyMs2DJaje9RnFgTTb3XAhOTngRKSMivwFuAu5y938sIuVFpAywGpggIvOBd1Q1RQJf1mIRTgD4BCfFyVS3lXIjv6YBAecLOyvLVPVn93Mx4BURaYwTPOtmc0474BoR+aO7XRYncOwMtNImMlkgMOHkXqAi8DtVPStOVtES/gXcL/AWwB+AuSIyATgC/EdV7wngHpkHzbIdRFPV50XkfZy8L6tFpD2BL4CzDCeolQN+B3wMXAoc9Q9+OTjp93ko8APwW5zu3uzqIMBAVf0wwDqaKGFjBCaclAUOukGgFXDBusvirMX8g6rOBGbhLPn3GdBMRK52y1wqItn91tzNLXMTTlbHY8B/cYKQbwD2sKoeF5HaqvqNqo7FaYlk7s//Cadr6gKqesI952Wc7pt0VT0O7BSRru69RER+G+B/l/3q5N+/D6dLLKv7fwj0c1tLiEhdEbk0gOubCGctAhNO5gPLReQbnP7tb7Mo0xJ4RETOAieA+1X1kDuDZ6GI+LpansDJ1Z/ZLyKyHqe75SF339M43U0bcbI9+lKYD3ED0jlgM86qb/5LBn4CjBCRDcBzWdxrEfC2W2efe4FpIvKEW4e3cNbpzclU4B8icj/wAb+2FjYC6SLyNTAXJ+jEAl+J0/d0CLgjl2ubKGDTR41xichKnOmW4bxmgTEXzbqGjDEmylmLwBhjopy1CIwxJspZIDDGmChngcAYY6KcBQJjjIlyFgiMMSbK/X/00QjQsB3JFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(clf_opt, x, y):\n",
    "    \n",
    "    preds = clf_opt.predict(x)\n",
    "    \n",
    "    report = classification_report(y, preds)\n",
    "    print(report)\n",
    "\n",
    "    # Performance Metrics\n",
    "    y_pred_rf = clf_opt.predict_proba(x)[:, 1]\n",
    "\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y, y_pred_rf)\n",
    "\n",
    "    print(\"Confusion Matrix Train\")\n",
    "    print(confusion_matrix(y, preds))\n",
    "\n",
    "    print('')\n",
    "    print(\"Accuracy Test\")\n",
    "    print(accuracy_score(y, preds))\n",
    "    print(precision_score(y, preds))\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "#evaluate(clf_opt, trainX_raw, trainY_raw)\n",
    "evaluate(clf_opt, valX, valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### GridSearchCV\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def get_model_test(features = features, \n",
    "              layers = 1, \n",
    "              units = 5, \n",
    "              optimizer=\"Adam\",\n",
    "              init='glorot_uniform'):\n",
    "    \n",
    "    reset_seed()\n",
    "    inputX = Input(shape=features)\n",
    "    \n",
    "    x = normalizer(inputX)\n",
    "    \n",
    "    for lay in range(int(layers)):\n",
    "        x = Dense(units, kernel_initializer=init, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer=init, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(1, kernel_initializer=init, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inputX], outputs=x)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=get_model_test, verbose=0,\n",
    "                    validation_data=(valX, valY))\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = [\n",
    "              \"Adadelta\", \n",
    "              \"Nadam\",\n",
    "              \"Ftrl\",\n",
    "]\n",
    "\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50]\n",
    "batches = [64]\n",
    "features = features\n",
    "layers = [20, 10]\n",
    "units = [10, 64]\n",
    "\n",
    "#get_simple_model(features[0]).summary()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        #monitor='val_precision', \n",
    "        monitor='val_prc', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "param_grid = dict(\n",
    "                    optimizer=optimizers, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batches,\n",
    "                    layers = layers,\n",
    "                    units = units,\n",
    "                    features = features,\n",
    "                    init=init\n",
    "                  )\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1, n_jobs=1)\n",
    "\n",
    "grid_result = grid.fit(trainX_balanced, trainY_balanced, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_result.best_params_)\n",
    "best_final_param = grid_result.best_params_\n",
    "del best_final_param['batch_size']\n",
    "del best_final_param['epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = get_model_test(**best_final_param)\n",
    "print(best_final_param)\n",
    "fit_model(best_model, trainX_balanced, trainY_balanced, valX, valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model_test(**{'features': 9, \n",
    "                               'init': 'glorot_uniform', \n",
    "                               'layers': 5, \n",
    "                               'optimizer': 'Nadam', \n",
    "                               'units': 10})\n",
    "fit_model(model, trainX_balanced, trainY_balanced, valX, valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metric(history, metric): \n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_{}\".format(metric)])\n",
    "    plt.title(metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "#show_metric(history, \"loss\")\n",
    "#show_metric(history, \"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('True Negatives: ', cm[0][0])\n",
    "    print('True Positives: ', cm[1][1])\n",
    "\n",
    "    print('False Positives: ', cm[0][1])\n",
    "    print('False Negatives: ', cm[1][0])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "baseline_results = model.evaluate(valX, valY, verbose=1)\n",
    "\n",
    "\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(valY, model.predict(valX))\n",
    "print(test_predictions_baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model \n",
    "\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, GlobalMaxPool1D, Bidirectional, Dense, Flatten, Conv2D, LeakyReLU, Dropout, LSTM, GRU, Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    " \n",
    "#Model \n",
    "\n",
    "dim = 100\n",
    "\n",
    "def add_deep_layers(x, dropout, units):\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(units, kernel_initializer=init, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    #x = Dense(units, activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def get_model(features, layers, units):\n",
    "    reset_seed()\n",
    "    inputX = Input(shape=features)\n",
    "    \n",
    "    x = normalizer(inputX)\n",
    "    \n",
    "    for lay in range(int(layers)):\n",
    "        x = add_deep_layers(x, 0.2, units)\n",
    "    \n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inputX], outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_model_rnn(seqs, \n",
    "                       features,\n",
    "                       units, \n",
    "                       dropout, \n",
    "                       lays, \n",
    "                       lays_seq, \n",
    "                       init):\n",
    "    inputX = Input(shape=(seqs, features))\n",
    "    \n",
    "    x = inputX\n",
    "    x = normalizer(inputX)\n",
    "    \n",
    "    for lay in range(int(lays_seq)):\n",
    "        x = LSTM(units=units, kernel_initializer=init, return_sequences=True)(x)\n",
    "    \n",
    "    #x = Bidirectional(LSTM(dim, return_sequences=False))(x)\n",
    "    x = LSTM(dim, kernel_initializer=init, return_sequences=False)(x)\n",
    "    \n",
    "    for lay in range(int(lays)):\n",
    "        x = add_deep_layers(x, dropout, units)\n",
    "        \n",
    "    x = Dense(20, kernel_initializer=init, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=[inputX], outputs=x)\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        #optimizer=ranger,\n",
    "        optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.00001, rho=0.95, epsilon=1e-07),\n",
    "        #optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model = load_model(filepath = \"drive/My Drive/model/stock.h5\")\n",
    "\n",
    "#!rm \"drive/My Drive/model/encoder.h5\"\n",
    "\n",
    "def get_simple():\n",
    "    model = Sequential()\n",
    "    reset_seed()\n",
    "    model.add(InputLayer(input_shape=features))\n",
    "    model.add(normalizer)\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def autokeras_class(max_trials = 30):\n",
    "    clf = ak.StructuredDataClassifier(overwrite=True, \n",
    "                                  max_trials=max_trials,\n",
    "                                  metrics=METRICS,\n",
    "                                  objective=kerastuner.Objective(\"val_prc\", direction=\"max\"),\n",
    "                                  project_name = \"AutoKeras\",\n",
    "                                  #tuner='random',\n",
    "                                 )\n",
    "    return clf\n",
    "\n",
    "def autokeras_time_class(max_trials = 30):\n",
    "    predict_from = 1\n",
    "    predict_until = 10\n",
    "    lookback = 0\n",
    "\n",
    "    return ak.TimeseriesForecaster(\n",
    "                              max_trials=max_trials,\n",
    "                              metrics=METRICS,\n",
    "                                  objective=kerastuner.Objective(\"val_prc\", direction=\"max\"),\n",
    "                              project_name = \"AutoKeras Time\",\n",
    "                              #tuner='random',\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 40\n",
    "a = [[i, i] for i in range(max)]\n",
    "\n",
    "\n",
    "def gen_y(i):\n",
    "    if (i > 35):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "b = [gen_y(i) for i in range(max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = create_dataset(a, b, time_steps=3, null_value = 0)\n",
    "\n",
    "print(xx.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "counter = Counter(yy)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))\n",
    "\n",
    "x_balanced, y_balanced = get_balanced_set_seq(xx, yy)\n",
    "\n",
    "print(x_balanced.shape)\n",
    "print(y_balanced.shape)\n",
    "\n",
    "counter = Counter(y_balanced)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_balanced) \n",
    "\n",
    "index = -4\n",
    "#print(x_balanced[index][-1][-1]) \n",
    "#print(y_balanced[index])\n",
    "\n",
    "for i in range(len(x_balanced)):\n",
    "    xx = x_balanced[i][-1][-1]\n",
    "    if (xx < 35):\n",
    "        print(\"{}) {} - {}\".format(i, xx, y_balanced[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "x_, y_ = create_dataset(trainX, trainY, time_steps=20, null_value = 0)\n",
    "\n",
    "print(x_.shape)\n",
    "print(y_.shape)\n",
    "\n",
    "counter = Counter(y_)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))\n",
    "\n",
    "x_balanced, y_balanced = get_balanced_set_seq(x_, y_)\n",
    "\n",
    "print(x_balanced.shape)\n",
    "print(y_balanced.shape)\n",
    "\n",
    "counter = Counter(y_balanced)\n",
    "print(\"{} - {}\".format(counter, (counter[0] - counter[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def get_data(trainX_raw, trainY_raw, valX_raw, valY_raw, time_steps=10)\n",
    "    x_balanced, y_balanced = get_balanced_set_seq(trainX_raw, trainY_raw, time_steps=time_steps)\n",
    "    val_x_balanced, val_y_balanced = get_balanced_set_seq(valX_raw, valY_raw, time_steps=time_steps)\n",
    "\n",
    "\n",
    "    counter = Counter(y_balanced)\n",
    "    print(\"{} - {}\".format(counter, (counter[0] - counter[1])))\n",
    "\n",
    "    return x_balanced, y_balanced, val_x_balanced, val_y_balanced\n",
    "\n",
    "seqs = 10\n",
    "\n",
    "trainX_balanced, trainY_balanced, valX, valY = get_data(trainX_raw,\n",
    "                                                        trainY_raw, \n",
    "                                                        valX_raw, \n",
    "                                                        valY_raw, \n",
    "                                                        seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=generate_model_rnn, verbose=0,\n",
    "                    validation_data=(valX, valY))\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = [\n",
    "              \"Adadelta\", \n",
    "              \"Nadam\",\n",
    "              \"Adam\",\n",
    "]\n",
    "\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50]\n",
    "batches = [64]\n",
    "features = [features]\n",
    "layers = [20, 10]\n",
    "lays_seq = [2, 5]\n",
    "units = [10, 64]\n",
    "seqs = [seqs]\n",
    "\n",
    "\n",
    "#get_simple_model(features[0]).summary()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        #monitor='val_precision', \n",
    "        monitor='val_prc', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "param_grid = dict(\n",
    "    optimizer=optimizers, \n",
    "    epochs=epochs, \n",
    "    batch_size = batches,\n",
    "    seqs = seqs, \n",
    "    features = features, \n",
    "    units = units, \n",
    "    dropout = [0.2],\n",
    "    lays = lays,\n",
    "    lays_seq = lays_seq \n",
    ")\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1, n_jobs=1)\n",
    "\n",
    "grid_result = grid.fit(trainX_balanced, trainY_balanced, callbacks=[early_stopping])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
