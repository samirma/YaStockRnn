{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import *\n",
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from tec_an import *\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "from sklearn_model_hyper import *\n",
    "from joblib import dump, load\n",
    "from data_generator import *\n",
    "from data_agent import *\n",
    "from stock_agent import *\n",
    "from backtest import *\n",
    "from bitstamp import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import scikitplot as skplt\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import random\n",
    "from catboost import CatBoost\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_start_list = [1622502000, 1590966000, 1559343600, 1580515200, 1612137600]\n",
    "train_start_list = [1622502000, 1590966000, 1559343600, 1527807600, 1517443200, 1548979200, 1580515200, 1612137600]\n",
    "#train_start_list = [1612137600]\n",
    "train_keys = [\"btcusd\", \"ethusd\", \"bchbtc\"]\n",
    "#train_keys = [\"bchbtc\"]\n",
    "val_start = 1626340500\n",
    "val_end = 1626369600\n",
    "\n",
    "step = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_data(minutes, source_data_generator, load_from_disk, file_prefix = \"\"):\n",
    "    \n",
    "    online = OnLineDataProvider(\n",
    "                 source_data_generator = source_data_generator,\n",
    "                 minutes = minutes,\n",
    "                 train_keys = train_keys,\n",
    "                 train_limit = 1000,\n",
    "                 val_limit = 1000,\n",
    "                 val_keys = [\"btcusd\"],\n",
    "                 val_start = val_start,\n",
    "                 val_end = val_end,\n",
    "                 train_start_list = train_start_list\n",
    "    )\n",
    "\n",
    "    online_path = f'data/online{file_prefix}_{minutes}'\n",
    "    \n",
    "    if (load_from_disk):\n",
    "        online = load(online_path)    \n",
    "    else:\n",
    "        #online.load_train_cache()\n",
    "        online.load_cache()\n",
    "        online.sourceDataGenerator = None\n",
    "        dump(online, online_path)\n",
    "        \n",
    "    \n",
    "    return online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_disk = True\n",
    "tec = TecAn(windows = 10, windows_limit = 100)\n",
    "sourceDataGenerator = SourceDataGenerator(tec = tec)\n",
    "online = get_online_data(3, sourceDataGenerator, load_from_disk, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 6325, 1: 1667})\n"
     ]
    }
   ],
   "source": [
    "trainX_raw, trainY_raw = online.load_train_data()\n",
    "x, y, closed_prices = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 838, 1: 161})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainX_raw, trainY_raw = online.load_val_data(\"btcusd\")\n",
    "val_x, val_y, closed_prices = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "print(Counter(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "7 pipelines ready for search.\n",
      "Ensembling is set to True, but max_batches is too small, so ensembling will not run. Set max_batches >= 9 to run ensembling.\n",
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for F1. \n",
      "Greater score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 4 batches for a total of 23 pipelines. \n",
      "Allowed model families: linear_model, catboost, random_forest, decision_tree, xgboost, extra_trees\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f3368645274c1b98d980c3c6a927ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Mode Baseline Binary Classification Pipeline:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.000\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 1 *\n",
      "*****************************\n",
      "\n",
      "Elastic Net Classifier w/ Imputer + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.346\n",
      "Decision Tree Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.441\n",
      "Random Forest Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.474\n",
      "CatBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.345\n",
      "Extra Trees Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.429\n",
      "Logistic Regression Classifier w/ Imputer + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.344\n",
      "XGBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.474\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 2 *\n",
      "*****************************\n",
      "\n",
      "XGBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.414\n",
      "XGBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.428\n",
      "XGBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.419\n",
      "XGBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.464\n",
      "XGBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.463\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 3 *\n",
      "*****************************\n",
      "\n",
      "Random Forest Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.469\n",
      "Random Forest Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.451\n",
      "Random Forest Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.476\n",
      "Random Forest Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.436\n",
      "Random Forest Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.474\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 4 *\n",
      "*****************************\n",
      "\n",
      "Decision Tree Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.419\n",
      "Decision Tree Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.458\n",
      "Decision Tree Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.431\n",
      "Decision Tree Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.413\n",
      "Decision Tree Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.432\n",
      "\n",
      "Search finished after 01:44            \n",
      "Best pipeline: Random Forest Classifier w/ Imputer\n",
      "Best pipeline F1: 0.475810\n"
     ]
    }
   ],
   "source": [
    "automl = AutoMLSearch(X_train=x, y_train=y, problem_type='binary', \n",
    "                      max_batches=4,\n",
    "                      objective='f1',\n",
    "                      #additional_objectives=['auc', 'f1', 'precision'],\n",
    "                      #additional_objectives=[ 'precision'],\n",
    "                      ensembling=True)\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.88      0.44      0.59       838\n",
      "     class 1       0.19      0.70      0.30       161\n",
      "\n",
      "    accuracy                           0.48       999\n",
      "   macro avg       0.54      0.57      0.45       999\n",
      "weighted avg       0.77      0.48      0.54       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "\n",
    "#pipeline.graph()\n",
    "\n",
    "eval_data(pipeline, val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 838, 1: 161})\n",
      "Counter({1: 583, 0: 416})\n"
     ]
    }
   ],
   "source": [
    "preds = pipeline.predict(val_x)\n",
    "\n",
    "print(Counter(val_y))\n",
    "print(Counter(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expvariance',\n",
       " 'maxerror',\n",
       " 'medianae',\n",
       " 'mse',\n",
       " 'mae',\n",
       " 'r2',\n",
       " 'root mean squared error',\n",
       " 'mcc multiclass',\n",
       " 'log loss multiclass',\n",
       " 'auc weighted',\n",
       " 'auc macro',\n",
       " 'auc micro',\n",
       " 'precision weighted',\n",
       " 'precision macro',\n",
       " 'precision micro',\n",
       " 'f1 weighted',\n",
       " 'f1 macro',\n",
       " 'f1 micro',\n",
       " 'balanced accuracy multiclass',\n",
       " 'accuracy multiclass',\n",
       " 'mcc binary',\n",
       " 'log loss binary',\n",
       " 'auc',\n",
       " 'precision',\n",
       " 'f1',\n",
       " 'balanced accuracy binary',\n",
       " 'accuracy binary']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.objectives.utils.get_core_objective_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
