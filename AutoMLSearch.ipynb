{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import *\n",
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from agents.tec_an import *\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "from sklearn_model_hyper import *\n",
    "from joblib import dump, load\n",
    "from data_generator import *\n",
    "from agents.data_agent import *\n",
    "from agents.stock_agent import *\n",
    "from backtest import *\n",
    "from bitstamp import *\n",
    "from model_winner_select import *\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import scikitplot as skplt\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import random\n",
    "from catboost import CatBoost\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_start_list = [1622502000, 1590966000, 1559343600, 1580515200, 1612137600]\n",
    "train_start_list = [1622502000, 1590966000, 1559343600, 1527807600, 1517443200, 1548979200, 1580515200, 1612137600]\n",
    "#train_start_list = [1612137600]\n",
    "train_keys = [\"ethusd\", \"bchbtc\"]\n",
    "#train_keys = [\"bchbtc\"]\n",
    "val_start = 1626340500\n",
    "val_end = 1626369600\n",
    "\n",
    "step = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_data(minutes, source_data_generator, load_from_disk, file_prefix = \"\"):\n",
    "    \n",
    "    online = OnLineDataProvider(\n",
    "                 source_data_generator = source_data_generator,\n",
    "                 minutes = minutes,\n",
    "                 train_keys = train_keys,\n",
    "                 train_limit = 1000,\n",
    "                 val_limit = 1000,\n",
    "                 val_keys = train_keys,\n",
    "                 val_start = val_start,\n",
    "                 val_end = val_end,\n",
    "                 train_start_list = train_start_list,\n",
    "                 verbose = False\n",
    "    )\n",
    "\n",
    "    online_path = f'data/online{file_prefix}_{minutes}'\n",
    "    \n",
    "    if (load_from_disk):\n",
    "        online = load(online_path)    \n",
    "    else:\n",
    "        #online.load_train_cache()\n",
    "        online.load_cache()\n",
    "        online.sourceDataGenerator = None\n",
    "        dump(online, online_path)\n",
    "        \n",
    "    \n",
    "    return online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_disk = True\n",
    "tec = TecAn(windows = 20, windows_limit = 100)\n",
    "sourceDataGenerator = SourceDataGenerator(tec = tec)\n",
    "online = get_online_data(3, sourceDataGenerator, load_from_disk, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 25444, 1: 3356})\n"
     ]
    }
   ],
   "source": [
    "trainX_raw, trainY_raw = online.load_train_data()\n",
    "\n",
    "\n",
    "x, y = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 12323, 1: 2078})\n"
     ]
    }
   ],
   "source": [
    "currency = \"ethusd\"\n",
    "\n",
    "trainX_raw, trainY_raw, prices = online.load_val_data(currency)\n",
    "val_x, val_y = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "print(Counter(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot.config import classifier_config_dict\n",
    "# add FeatureSetSelector into tpot configuration\n",
    "classifier_config_dict['tpot.builtins.FeatureSetSelector'] = {\n",
    "    'subset_list': ['https://raw.githubusercontent.com/EpistasisLab/tpot/master/tests/subset_test.csv'],\n",
    "    'sel_subset': [0,1] # select only one feature set, a list of index of subset in the list above\n",
    "    #'sel_subset': list(combinations(range(3), 2)) # select two feature sets\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 5 µs, total: 29 µs\n",
      "Wall time: 36 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "model = TPOTClassifier(#generations=30, \n",
    "                       #population_size=50,\n",
    "                       max_time_mins=24*60,\n",
    "                       scoring='balanced_accuracy', \n",
    "                       verbosity=2, \n",
    "                       #template='Selector-Transformer-Classifier',\n",
    "                       #config_dict=classifier_config_dict,\n",
    "                       random_state=1,\n",
    "                       config_dict='TPOT NN',\n",
    "                       n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.6412857188301825\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.6412857188301825\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.6435163297107105\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.6435163297107105\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.6435163297107105\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.6435163297107105\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.6435163297107105\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.6435163297107105\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.6436229962970461\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.6437278707204819\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.6439398772452746\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.6440182551734815\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.6450305493036866\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.6460362401183682\n",
      "\n",
      "Generation 15 - Current best internal CV score: 0.6466020684377851\n",
      "\n",
      "Generation 16 - Current best internal CV score: 0.6466020684377851\n",
      "\n",
      "Generation 17 - Current best internal CV score: 0.6466020684377851\n",
      "\n",
      "Generation 18 - Current best internal CV score: 0.6471683988496776\n",
      "\n",
      "Generation 19 - Current best internal CV score: 0.6471683988496776\n",
      "\n",
      "Generation 20 - Current best internal CV score: 0.6471683988496776\n",
      "\n",
      "Generation 21 - Current best internal CV score: 0.6477733145451451\n",
      "\n",
      "Generation 22 - Current best internal CV score: 0.6477733145451451\n",
      "\n",
      "Generation 23 - Current best internal CV score: 0.6477733145451451\n",
      "\n",
      "Generation 24 - Current best internal CV score: 0.6479075569235075\n",
      "\n",
      "Generation 25 - Current best internal CV score: 0.6479075569235075\n",
      "\n",
      "Generation 26 - Current best internal CV score: 0.6493518143497763\n",
      "\n",
      "Generation 27 - Current best internal CV score: 0.6493518143497763\n",
      "\n",
      "Generation 28 - Current best internal CV score: 0.6493518143497763\n",
      "\n",
      "Generation 29 - Current best internal CV score: 0.6493518143497763\n",
      "\n",
      "Generation 30 - Current best internal CV score: 0.6493518143497763\n",
      "\n",
      "Generation 31 - Current best internal CV score: 0.649422283541592\n",
      "\n",
      "Generation 32 - Current best internal CV score: 0.6494533746831449\n",
      "\n",
      "Generation 33 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 34 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 35 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 36 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 37 - Current best internal CV score: 0.6507831830321458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd078285a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1295, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 38 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 39 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 40 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 41 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 42 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 43 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 44 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 45 - Current best internal CV score: 0.6507831830321458\n",
      "\n",
      "Generation 46 - Current best internal CV score: 0.6508235005560583\n",
      "\n",
      "Generation 47 - Current best internal CV score: 0.6508235005560583\n",
      "\n",
      "Generation 48 - Current best internal CV score: 0.6508235005560583\n",
      "\n",
      "Generation 49 - Current best internal CV score: 0.6508235005560583\n",
      "\n",
      "Generation 50 - Current best internal CV score: 0.6508235005560583\n",
      "\n",
      "Generation 51 - Current best internal CV score: 0.6521442746018213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/multiprocessing/synchronize.py\", line 88, in _cleanup\n",
      "    unregister(name, \"semaphore\")\n",
      "  File \"/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/multiprocessing/resource_tracker.py\", line 151, in unregister\n",
      "    self._send('UNREGISTER', name, rtype)\n",
      "  File \"/Users/samirantonio/opt/miniconda3/envs/py3/lib/python3.9/multiprocessing/resource_tracker.py\", line 160, in _send\n",
      "    nbytes = os.write(self._fd, msg)\n",
      "stopit.utils.TimeoutException: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 52 - Current best internal CV score: 0.6521442746018213\n",
      "\n",
      "Generation 53 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "Generation 54 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "Generation 55 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "Generation 56 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "Generation 57 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "Generation 58 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "Generation 59 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "Generation 60 - Current best internal CV score: 0.6522738813072515\n",
      "\n",
      "1442.10 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: BernoulliNB(SGDClassifier(CombineDFs(RobustScaler(ZeroCount(SelectPercentile(GaussianNB(input_matrix), percentile=45))), PCA(input_matrix, iterated_power=8, svd_solver=randomized)), alpha=0.001, eta0=1.0, fit_intercept=True, l1_ratio=1.0, learning_rate=invscaling, loss=log, penalty=elasticnet, power_t=1.0), alpha=10.0, fit_prior=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict='TPOT NN', max_time_mins=1440, n_jobs=-1,\n",
       "               random_state=1, scoring='balanced_accuracy', verbosity=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export('tpot_boston_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5818098617130796\n"
     ]
    }
   ],
   "source": [
    "print(model.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = CacheProvider(\n",
    "        currency_list=[currency],\n",
    "        verbose = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethusd\n",
      "-11.53863% -> 88.46136529441762\n",
      "Positive: 195(0.14301025641025641) Negative: 83(-0.47500722891566266)\n",
      "{'recall': 0.6447368421052632, 'precision': 0.15076923076923077, 'f1': 0.24438902743142144, 'accuracy': 0.5455, 'roc_auc': 0.5887341095402163}\n"
     ]
    }
   ],
   "source": [
    "val_keys = [currency]\n",
    "for key in val_keys:\n",
    "    print(key)\n",
    "    back, metric = eval_model(model = model,\n",
    "                      hot_load_total = 100,\n",
    "                      currency = key, \n",
    "                      cache = cache,\n",
    "                      stop_loss = -1,\n",
    "                      provider = online, step = step, verbose = False)\n",
    "    back.report()\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(X_train=x, y_train=y, problem_type='binary', \n",
    "                      max_batches=4,\n",
    "                      objective='f1',\n",
    "                      #additional_objectives=['auc', 'f1', 'precision'],\n",
    "                      #additional_objectives=[ 'precision'],\n",
    "                      ensembling=False)\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "\n",
    "#pipeline.graph()\n",
    "\n",
    "eval_data(pipeline, val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict(val_x)\n",
    "\n",
    "print(Counter(val_y))\n",
    "print(Counter(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalml.objectives.utils.get_core_objective_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = test_model(pipeline, \"btcusd\", online, step, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
