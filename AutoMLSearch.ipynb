{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import *\n",
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from tec_an import *\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "from sklearn_model_hyper import *\n",
    "from joblib import dump, load\n",
    "from data_generator import *\n",
    "from data_agent import *\n",
    "from stock_agent import *\n",
    "from backtest import *\n",
    "from bitstamp import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import scikitplot as skplt\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import random\n",
    "from catboost import CatBoost\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_start_list = [1622502000, 1590966000, 1559343600, 1580515200, 1612137600]\n",
    "train_start_list = [1622502000, 1590966000, 1559343600, 1527807600, 1517443200, 1548979200, 1580515200, 1612137600]\n",
    "#train_start_list = [1612137600]\n",
    "train_keys = [\"btcusd\", \"ethusd\", \"bchbtc\"]\n",
    "#train_keys = [\"bchbtc\"]\n",
    "val_start = 1626340500\n",
    "val_end = 1626369600\n",
    "\n",
    "step = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_data(minutes, source_data_generator, load_from_disk, file_prefix = \"\"):\n",
    "    \n",
    "    online = OnLineDataProvider(\n",
    "                 source_data_generator = source_data_generator,\n",
    "                 minutes = minutes,\n",
    "                 train_keys = train_keys,\n",
    "                 train_limit = 1000,\n",
    "                 val_limit = 1000,\n",
    "                 val_keys = [\"btcusd\"],\n",
    "                 val_start = val_start,\n",
    "                 val_end = val_end,\n",
    "                 train_start_list = train_start_list\n",
    "    )\n",
    "\n",
    "    online_path = f'data/online{file_prefix}_{minutes}'\n",
    "    \n",
    "    if (load_from_disk):\n",
    "        online = load(online_path)    \n",
    "    else:\n",
    "        #online.load_train_cache()\n",
    "        online.load_cache()\n",
    "        online.sourceDataGenerator = None\n",
    "        dump(online, online_path)\n",
    "        \n",
    "    \n",
    "    return online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_disk = True\n",
    "tec = TecAn(windows = 10, windows_limit = 100)\n",
    "sourceDataGenerator = SourceDataGenerator(tec = tec)\n",
    "online = get_online_data(3, sourceDataGenerator, load_from_disk, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 14928, 1: 9048})\n"
     ]
    }
   ],
   "source": [
    "trainX_raw, trainY_raw = online.load_train_data()\n",
    "x, y, closed_prices = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 7758, 1: 6657})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainX_raw, trainY_raw = online.load_val_data(\"btcusd\")\n",
    "val_x, val_y, closed_prices = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "print(Counter(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "7 pipelines ready for search.\n",
      "Ensembling is set to True, but max_batches is too small, so ensembling will not run. Set max_batches >= 9 to run ensembling.\n",
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for AUC. \n",
      "Greater score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 4 batches for a total of 23 pipelines. \n",
      "Allowed model families: linear_model, decision_tree, xgboost, random_forest, extra_trees, catboost\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38403e7688a4437b94afafc6eec1576b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Mode Baseline Binary Classification Pipeline:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean AUC: 0.500\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 1 *\n",
      "*****************************\n",
      "\n",
      "Elastic Net Classifier w/ Imputer + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean AUC: 0.586\n",
      "Decision Tree Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean AUC: 0.644\n",
      "Random Forest Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean AUC: 0.679\n",
      "CatBoost Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean AUC: 0.661\n",
      "Extra Trees Classifier w/ Imputer:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean AUC: 0.625\n",
      "Logistic Regression Classifier w/ Imputer + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean AUC: 0.586\n"
     ]
    }
   ],
   "source": [
    "automl = AutoMLSearch(X_train=x, y_train=y, problem_type='binary', \n",
    "                      max_batches=4,\n",
    "                      objective='auc',\n",
    "                      #additional_objectives=['auc', 'f1', 'precision'],\n",
    "                      #additional_objectives=[ 'precision'],\n",
    "                      ensembling=True)\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "\n",
    "#pipeline.graph()\n",
    "\n",
    "eval_data(pipeline, val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict(val_x)\n",
    "\n",
    "print(Counter(val_y))\n",
    "print(Counter(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalml.objectives.utils.get_core_objective_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
