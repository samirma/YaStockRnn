{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import *\n",
    "import pandas as pd\n",
    "import data_util\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from data_generator import DataGenerator\n",
    "from agents.tec_an import *\n",
    "import numpy as np\n",
    "from data_util import *\n",
    "from sklearn_model_hyper import *\n",
    "from joblib import dump, load\n",
    "from data_generator import *\n",
    "from agents.data_agent import *\n",
    "from agents.stock_agent import *\n",
    "from backtest import *\n",
    "from bitstamp import *\n",
    "from model_winner_select import *\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import scikitplot as skplt\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import random\n",
    "from catboost import CatBoost\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_start_list = [1622502000, 1590966000, 1559343600, 1580515200, 1612137600]\n",
    "train_start_list = [1622502000, 1590966000, 1559343600, 1527807600, 1517443200, 1548979200, 1580515200, 1612137600]\n",
    "#train_start_list = [1612137600]\n",
    "train_keys = [\"btcusd\", \"ethusd\", \"bchbtc\"]\n",
    "#train_keys = [\"bchbtc\"]\n",
    "val_start = 1626340500\n",
    "val_end = 1626369600\n",
    "\n",
    "step = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_data(minutes, source_data_generator, load_from_disk, file_prefix = \"\"):\n",
    "    \n",
    "    online = OnLineDataProvider(\n",
    "                 source_data_generator = source_data_generator,\n",
    "                 minutes = minutes,\n",
    "                 train_keys = train_keys,\n",
    "                 train_limit = 1000,\n",
    "                 val_limit = 1000,\n",
    "                 val_keys = train_keys,\n",
    "                 val_start = val_start,\n",
    "                 val_end = val_end,\n",
    "                 train_start_list = train_start_list,\n",
    "                 verbose = False\n",
    "    )\n",
    "\n",
    "    online_path = f'data/online{file_prefix}_{minutes}'\n",
    "    \n",
    "    if (load_from_disk):\n",
    "        online = load(online_path)    \n",
    "    else:\n",
    "        #online.load_train_cache()\n",
    "        online.load_cache()\n",
    "        online.sourceDataGenerator = None\n",
    "        dump(online, online_path)\n",
    "        \n",
    "    \n",
    "    return online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_disk = True\n",
    "tec = TecAn(windows = 20, windows_limit = 100)\n",
    "sourceDataGenerator = SourceDataGenerator(tec = tec)\n",
    "online = get_online_data(3, sourceDataGenerator, load_from_disk, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 25444, 1: 3356})\n"
     ]
    }
   ],
   "source": [
    "trainX_raw, trainY_raw = online.load_train_data()\n",
    "\n",
    "\n",
    "x, y = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 12834, 1: 1567})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainX_raw, trainY_raw, prices = online.load_val_data(\"btcusd\")\n",
    "val_x, val_y = prepare_train_data(trainX_raw, trainY_raw, step)\n",
    "\n",
    "print(Counter(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot.config import classifier_config_dict\n",
    "# add FeatureSetSelector into tpot configuration\n",
    "classifier_config_dict['tpot.builtins.FeatureSetSelector'] = {\n",
    "    'subset_list': ['https://raw.githubusercontent.com/EpistasisLab/tpot/master/tests/subset_test.csv'],\n",
    "    'sel_subset': [0,1] # select only one feature set, a list of index of subset in the list above\n",
    "    #'sel_subset': list(combinations(range(3), 2)) # select two feature sets\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28799b481af3431e96dd70feac7c46a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.6400410189948851\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.6450652282014343\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.6450652282014343\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.6450652282014343\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.6450652282014343\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.6450652282014343\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.6450652282014343\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.6452418752403268\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.6452418752403268\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.6452418752403268\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.6452418752403268\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.6452418752403268\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.6452966608253616\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.6453699066690334\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "model = TPOTClassifier(#generations=30, \n",
    "                       #population_size=50,\n",
    "                       max_time_mins=15*60,\n",
    "                       scoring='balanced_accuracy', \n",
    "                       verbosity=2, \n",
    "                       template='Selector-Transformer-Classifier',\n",
    "                       #config_dict=classifier_config_dict,\n",
    "                       random_state=1,\n",
    "                       #config_dict='TPOT sparse',\n",
    "                       n_jobs=-1)\n",
    "# perform the search\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = CacheProvider(\n",
    "        currency_list=[\"btcusd\"],\n",
    "        verbose = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_keys = online.val_keys\n",
    "for key in val_keys:\n",
    "    print(key)\n",
    "    back, metric = eval_model(model = model,\n",
    "                      hot_load_total = 100,\n",
    "                      currency = key, \n",
    "                      cache = cache,\n",
    "                      provider = online, step = step, verbose = False)\n",
    "    back.report()\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export('tpot_boston_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(X_train=x, y_train=y, problem_type='binary', \n",
    "                      max_batches=4,\n",
    "                      objective='f1',\n",
    "                      #additional_objectives=['auc', 'f1', 'precision'],\n",
    "                      #additional_objectives=[ 'precision'],\n",
    "                      ensembling=False)\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "\n",
    "#pipeline.graph()\n",
    "\n",
    "eval_data(pipeline, val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict(val_x)\n",
    "\n",
    "print(Counter(val_y))\n",
    "print(Counter(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalml.objectives.utils.get_core_objective_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = test_model(pipeline, \"btcusd\", online, step, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
